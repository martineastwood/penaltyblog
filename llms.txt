# Table of Contents
- [Project Overview](#project-overview-and-summary)
- [Configuration](#key-configuration-and-dependencies)
- [High-Level Documentation](#high-level-documentation)
- [Tutorials](#tutorials)
- [Source Code Summary](#source-code-summary)
- [Test Summary](#test-summary)
================================================================================
## Project Overview and SummarySource: `README.md`
<img src="https://raw.githubusercontent.com/martineastwood/penaltyblog/refs/heads/master/logo.png" width="0" height="0" style="display:none;"/>

<meta property="og:image" content="https://raw.githubusercontent.com/martineastwood/penaltyblog/refs/heads/master/logo.png" />
<meta property="og:image:alt" content="penaltyblog python package for soccer modeling" />
<meta name="twitter:image" content="https://raw.githubusercontent.com/martineastwood/penaltyblog/refs/heads/master/logo.png">
<meta name="twitter:card" content="summary_large_image">

# Penalty Blog

<div align="center">

<a href="">[![Python Version](https://img.shields.io/pypi/pyversions/penaltyblog)](https://pypi.org/project/penaltyblog/)</a>
<a href="https://codecov.io/github/martineastwood/penaltyblog" >
<img src="https://codecov.io/github/martineastwood/penaltyblog/branch/master/graph/badge.svg?token=P0WDHRGIG2"/>
</a>
<a href="">[![PyPI](https://img.shields.io/pypi/v/penaltyblog.svg)](https://pypi.org/project/penaltyblog/)</a>
<a href="">[![Downloads](https://static.pepy.tech/badge/penaltyblog)](https://pepy.tech/project/penaltyblog)</a>
<a href="">[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)</a>
<a href="">[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)</a>
<a href="">[![Code style: pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)</a>

</div>

<div align="center">
  <img src="logo.png" alt="Penalty Blog Logo" width="200">
</div>

# penaltyblog: Football Data & Modelling Made Easy

**penaltyblog** is a production-ready Python package designed for football (soccer) analytics, providing powerful tools from [pena.lt/y/blog](https://pena.lt/y/blog) for data analysis, outcome modelling, and betting insights. Optimized with Cython, **penaltyblog** delivers high-performance modelling to power faster, efficient predictions.

## Features

- üîÑ **Streamline JSON Workflows with MatchFlow:** Process nested football data using a lazy, streaming pipeline built for JSON. Filter, select, flatten, join, group, and summarize large datasets without loading everything into memory.
- üîå **Connect to Professional APIs:** Seamlessly stream and filter data directly from industry leaders, like StatsBomb and Opta. Query matches, events, and stats using lazy loading without handling massive JSON dumps.
- üìä **Model Matches Efficiently:** High-performance implementations of Poisson, Bivariate Poisson, Dixon-Coles, and other advanced statistical models, optimized with Cython for rapid analysis.
- üß† **Advanced Bayesian Modelling:** Full posterior distributions for match outcomes using MCMC sampling. Includes Hierarchical Bayesian models to automatically learn league-wide variances and handle parameter uncertainty.
- ‚öΩ **Scrape Data:** Collect match statistics from sources like Understat, Club Elo, and Fantasy Premier League.
- üí∞ **Bet Smarter:** Precisely estimate probabilities for Asian handicaps, over/under totals, match outcomes, and more.
- üèÜ **Rank Teams:** Evaluate team strengths with sophisticated methods including Elo, Massey, Colley, and Pi ratings.
- üìà **Decode Bookmaker Odds:** Accurately extract implied probabilities by removing bookmaker margins (overrounds).
- üéØ **Fantasy Football Optimisation:** Mathematically optimize your fantasy football squad to maximize performance.
- üé® **Visualize with Style:** Create publication-ready pitch visualizations and data flow diagrams with customizable themes, supporting multiple data providers and flexible layouts.

Take your football analytics and betting strategy to the next level with **penaltyblog** üöÄ

## Installation

```bash
pip install penaltyblog
```

## üöÄ Quick Start - Try it Now!

Run these examples directly in your browser (no installation required):

| Example                               | Description                                                              | Colab                                                                                                                                                               |
| ------------------------------------- | ------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Predict Soccer Match Results**      | Build a match prediction model from scratch                              | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1GjrDG_iq_9_lxEQK_aBmr-jCCCnFt0v7?usp=sharing) |
| **Process Soccer Data the Easy Way**  | Lazy processing of football data using Matchflow                         | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1rRJV8mNOTLTXmn5cOGT4faxIwIP44pC-?usp=sharing) |
| **Calculate Massey Ratings**          | Calculate teams' attack and defense strengths                            | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1d_WPJwQgrogeSI9oIO9fY8s18CPPZ8nL?usp=sharing) |
| **Use Pi Ratings**                    | Like Elo ratings, but better                                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12qEDCNYG-FFHOJ_kURe0cm80sScandyh?usp=sharing) |
| **Create Interactive Charts**         | Create your own interactive football vizualisations                      | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1xFfIdvmbFcjHlS_2eHEu3NxD-xLNrbpY?usp=sharing) |
| **Work Directly With Statsbomb Data** | Connect directly to Statsbomb's API, including their free open data sets | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1xFfIdvmbFcjHlS_2eHEu3NxD-xLNrbpY?usp=sharing) |
| **Calculate Implied Probabilities**   | Calculate implied probabilities from bookmaker's odds                    | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1o-tOetyWmSY_1WczN8WhWsl62Uz5T65F?usp=sharing) |

## Documentation

Learn more about how to utilize `penaltyblog` by exploring the [official documentation](https://penaltyblog.readthedocs.io/en/latest/) and detailed examples:

- [Processing football event data with MatchFlow](https://penaltyblog.readthedocs.io/en/latest/matchflow/index.html)
- [Scraping football data](https://penaltyblog.readthedocs.io/en/latest/scrapers/index.html)
- [Predicting football matches and betting markets](https://penaltyblog.readthedocs.io/en/latest/models/index.html)
- [Estimating implied odds from bookmaker prices](https://penaltyblog.readthedocs.io/en/latest/implied/index.html)
- [Calculating Massey, Colley, Pi, and Elo ratings](https://penaltyblog.readthedocs.io/en/latest/ratings/index.html)
- [Calculating metrics such as Ranked Probability Scores](https://penaltyblog.readthedocs.io/en/latest/metrics/index.html)

## Why Penaltyblog?

Unlike many football analytics resources that are academic, one-off, or hard to scale, `penaltyblog` is designed from the ground up to be **production-ready**, **performance-optimized**, and **practically useful**.

It combines advanced statistical models (including **Bayesian** and **Hierarchical Bayesian** variants), efficient implementations (via **Cython**), and real-world workflows, from scraping public data to modelling outcomes and optimising fantasy teams.

The project is maintained by [Martin Eastwood](https://pena.lt/y/about), a data scientist focused on the intersection of high-performance computing and sports analytics. `penaltyblog` aims to provide the community with a robust, audited foundation for advanced modeling.

## Community & Contributions

I am always interested in seeing how `penaltyblog` is being applied in research and industry. If you have feedback, bug reports, or want to collaborate on new features, feel free to:

- Open an Issue [here](https://github.com/martineastwood/penaltyblog/issues)
- Get in touch [here](https://pena.lt/y/contact)

================================================================================
## Key Configuration and Dependencies
### pyproject.toml```toml[project]
name = "penaltyblog"
version = "1.8.0"
description = "Football (soccer) Data & Modelling Made Easy"
authors = [{ name = "Martin Eastwood", email = "martin.eastwood@gmx.com" }]
readme = "README.md"
license-files = ["LICENCE"]
keywords = [
    "football",
    "soccer",
    "goals",
    "modelling",
    "dixon coles",
    "poisson",
    "scraper",
    "scraping",
    "backtest",
    "matchflow",
]

requires-python = ">=3.10"

dependencies = [
    "beautifulsoup4",
    "cssselect",
    "cython",
    "fsspec",
    "html5lib",
    "ipywidgets",
    "kaleido",
    "lxml",
    "matplotlib",
    "networkx",
    "numpy",
    "orjson",
    "pandas",
    "plotly",
    "pulp",
    "requests",
    "scipy",
    "socks",
    "statsbombpy",
    "tabulate",
    "tqdm",
    "wrapper-tls-requests",
]

classifiers = [
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
]

[project.urls]
Homepage = "https://github.com/martineastwood/penaltyblog"
Repository = "https://github.com/martineastwood/penaltyblog"

[build-system]
requires = ["setuptools", "wheel", "numpy", "Cython"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
include-package-data = true

[tool.setuptools.package-data]
penaltyblog = [
    "models/*.so",
    "models/*.dll",
    "models/*.dylib",
    "metrics/*.so",
    "metrics/*.dll",
    "metrics/*.dylib",
]

[project.optional-dependencies]
dev = [
    "black>=22.6.0",
    "build",
    "coveralls>=3.3.1",
    "coverage>=6.4.2",
    "ipython>=8.4.0",
    "jupyterlab>=3.4.4",
    "jupyterlab-code-formatter>=1.5.2",
    "nbsphinx>=0.8.9",
    "numpydoc>=1.4.0",
    "pre-commit>=2.20.0",
    "Pygments>=2.12.0",
    "pytest>=7.1.2",
    "pytest-vcr",
    "setuptools>=75.6.0",
    "Sphinx>=5.1.1",
    "sphinx-rtd-theme>=1.0.0",
    "types-requests>=2.28.11",
    "vcrpy",
]

s3 = ["s3fs"]
gcs = ["gcsfs", "gcloud"]
azure = ["adlfs"]
cloud = ["s3fs", "gcsfs", "adlfs", "gcloud"]

[tool.coverage.paths]
source = ["penaltyblog", "*/site-packages"]

[tool.coverage.run]
branch = true
source = ["penaltyblog"]

[tool.coverage.report]
show_missing = true
ignore_errors = true

[tool.isort]
profile = "black"
src_paths = ["penaltyblog", "tests"]
include_trailing_comma = true
line_length = 79

[tool.ty.rules]
unresolved-import = "ignore"
```
================================================================================
## TutorialsDocs demonstrating library usage. This will be included in full.
### Tutorial: docs/conf.py
```rst# Configuration file for the Sphinx documentation builder.
#
# This file only contains a selection of the most common options. For a full
# list see the documentation:
# https://www.sphinx-doc.org/en/master/usage/configuration.html

# -- Path setup --------------------------------------------------------------

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#
import os
import sys

sys.path.insert(0, os.path.abspath(".."))
sys.path.insert(0, os.path.abspath("../penaltyblog"))
# sys.setrecursionlimit(1500)

html_baseurl = "/y"

# -- Project information -----------------------------------------------------

project = "penaltyblog"
copyright = "2025, Martin Eastwood"
author = "Martin Eastwood"

# source_suffix = ".rst"

# -- General configuration ---------------------------------------------------

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    "nbsphinx",
    "sphinx.ext.autodoc",
    "sphinx.ext.intersphinx",
    "sphinx.ext.napoleon",
    "sphinx.ext.viewcode",
    "sphinx.ext.autosummary",
    "sphinx.ext.githubpages",
]

autosummary_generate = True

templates_path = ["_templates"]
exclude_patterns = ["_build", "Thumbs.db", ".DS_Store", "**.ipynb_checkpoints"]

master_doc = "index"

html_logo = "_static/logo.png"

exclude_patterns = ["_build", "Thumbs.db", ".DS_Store", "**.ipynb_checkpoints"]

html_favicon = "_static/favicon.ico"

html_sidebars = {
    "**": [
        "globaltoc.html",
    ],
}

html_theme_options = {
    "pygments_light_style": "tango",
    "pygments_dark_style": "monokai",
    "icon_links": [
        {
            "name": "GitHub",
            "url": "https://github.com/martineastwood/penaltyblog",
            "icon": "fab fa-github-square",
            "type": "fontawesome",
        },
    ],
}

# autosummary_generate = ["api_reference.rst"]

html_static_path = ["_static"]

html_permalinks_icon = "<span>#</span>"
html_theme = "pydata_sphinx_theme"

pygments_style = "sphinx"

autodoc_typehints = "signature"
autosummary_generate = True
autodoc_default_options = {
    "members": True,
    "undoc-members": True,
    "show-inheritance": True,
    "inherited-members": True,  # Ensures base class functions appear
}
```### Tutorial: docs/requirements.txt
```rstSphinx
nbsphinx
Pygments
numpydoc
sphinx-rtd-theme
pydata-sphinx-theme
ipython
penaltyblog
```### Tutorial: docs/viz/index.rst
```rstVisualizations
==========================

.. raw:: html

   <a href="https://colab.research.google.com/drive/1xFfIdvmbFcjHlS_2eHEu3NxD-xLNrbpY?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

The visualization module offers a high-level interface for plotting football (soccer) data.

At its core is the ``Pitch`` class, which provides flexible tools for rendering scatter plots,
heatmaps, arrows, and more‚Äîmapped directly onto the field of play.
Whether you're exploring tracking data, event locations, or tactical movements, ``Pitch``
helps you visualize it clearly and beautifully.

Interactive Examples
--------------------

For a comprehensive, hands-on demonstration of the plotting using ``Pitch``, try the interactive Colab notebook.
The notebook walks you through all the different plotting methods, themes and customization options.

.. raw:: html

   <a href="https://colab.research.google.com/drive/1xFfIdvmbFcjHlS_2eHEu3NxD-xLNrbpY?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

.. toctree::
   :maxdepth: 1
   :caption: Examples:

   pitch
   pitch_examples
```### Tutorial: docs/viz/pitch.rst
```rst==================
Pitch Visualization
==================

.. raw:: html

   <a href="https://colab.research.google.com/drive/1xFfIdvmbFcjHlS_2eHEu3NxD-xLNrbpY?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

The ``Pitch`` class is a powerful and flexible interface for rendering football (soccer) pitch visualizations using ``plotly``. It supports multiple pitch dimensions (e.g., StatsBomb, Wyscout), configurable themes, and layered plotting of various visual elements (scatter, heatmap, arrows, comets, etc.).

üìê Initialization
=================

.. code-block:: python

   Pitch(
       provider="statsbomb",     # or "wyscout", "opta", "metrica", or a PitchDimensions instance
       width=800,
       height=600,
       theme="minimal",          # e.g., "classic", "night", "retro", "turf"
       orientation="horizontal", # or "vertical"
       view="full",              # or "left", "right", "top", "bottom", or (x0, x1), (x0, x1, y0, y1)
       title=None,
       subtitle=None,
       subnote=None,
       show_axis=False,
       show_legend=False,
       show_spots=True,
   )

Common Use
----------

.. code-block:: python

   from penaltyblog.viz import Pitch

   pitch = Pitch(provider="statsbomb", theme="night", orientation="horizontal")

üñº Base Features
================

- Draws pitch lines, boxes, center circle, and optional penalty spots.
- Automatically applies orientation (``horizontal`` vs ``vertical``).
- Supports custom zoom via view (e.g., ``"left"``, ``(30, 90)``, ``(0, 120, 18, 62)``).
- Built-in styling presets (``theme``) to suit different visual aesthetics.

üîÅ Layers
=========

Visual elements are grouped into named layers (e.g., ``"scatter"``, ``"heatmap"``, ``"arrows"``). This allows for flexible visibility control, ordering, and removal.

Layer methods
-------------

.. code-block:: python

   pitch.set_layer_visibility("arrows", visible=False)
   pitch.set_layer_order(["scatter", "arrows", "heatmap"])
   pitch.remove_layer("heatmap")

üß∞ Plotting Methods
===================

Each method adds visual elements to the figure. Use ``return_trace=True`` to get the underlying Plotly trace(s) instead of adding to the layer.

plot_scatter(...)
-----------------

Plots individual points.

.. code-block:: python

   pitch.plot_scatter(data, x="x", y="y", hover="player_name")

- ``hover``: field for hover text.
- ``size``: marker size.
- ``color``: marker color.

plot_heatmap(...)
-----------------

Creates a 2D histogram of point density.

.. code-block:: python

   pitch.plot_heatmap(data, x="x", y="y", bins=(20, 14), show_colorbar=True)

- ``bins``: (x, y) bin count.
- ``colorscale``: override theme colorscale.
- ``opacity``: override opacity.

plot_kde(...)
-------------

Smooth kernel density estimate over the pitch.

.. code-block:: python

   pitch.plot_kde(data, x="x", y="y", grid_size=100)

- Automatically falls back to histogram+blur if KDE fails.
- Output is a Plotly ``go.Heatmap``.

plot_comets(...)
----------------

Draws trails ("comets") from (x, y) to (x2, y2).

.. code-block:: python

   pitch.plot_comets(data, x="start_x", y="start_y", x_end="end_x", y_end="end_y")

- ``segments``: how many segments per trail.
- ``fade``: True to fade out the trail.
- ``hover``: shown only at trail head.

plot_arrows(...)
----------------

Draws arrows using Plotly annotations.

.. code-block:: python

   pitch.plot_arrows(data, x="start_x", y="start_y", x_end="end_x", y_end="end_y")

- ``arrowhead``: arrowhead shape.
- ``arrowsize``: arrowhead size.
- ``width``: arrow width.
- ``color``: arrow color.
- ``hover``: shown at arrow tip.

üñº Display & Export
===================

``pitch.show()``
----------------

Renders the figure in a browser or notebook.

``pitch.save(...)``
-------------------

Saves the pitch as an image (requires ``kaleido``).

.. code-block:: python

   pitch.save("output.svg")  # Format inferred
   pitch.save("output.pdf", scale=2.0)  # Higher resolution

Arguments:

- ``format``: 'png', 'svg', 'pdf', etc.
- ``scale``: output resolution multiplier.
- ``width`` / ``height``: override layout size.

üìè Supported Dimensions
=======================

The provider argument supports:

+--------------+-------------+--------------+------------+
| Provider     | Origin      | Native Units | Dimensions |
+==============+=============+==============+============+
| ``statsbomb``| Top-left    | 120 √ó 80     | meters     |
+--------------+-------------+--------------+------------+
| ``wyscout``  | Top-left    | 100 √ó 100    | percent    |
+--------------+-------------+--------------+------------+
| ``opta``     | Top-left    | 100 √ó 100    | percent    |
+--------------+-------------+--------------+------------+
| ``metrica``  | Bottom-left | 1.0 √ó 1.0    | normalized |
+--------------+-------------+--------------+------------+

All are automatically scaled to a consistent 105 √ó 68 drawing space.

üé® Themes
=========

Themes define color schemes, fonts, sizes, and line styles. Available themes:

- ``"classic"``: green pitch, white lines.
- ``"night"``: navy background, bright accents.
- ``"retro"``: cream + brown tones.
- ``"minimal"``: white pitch, dark lines.
- ``"turf"``: deep green, amber markers.

Custom themes
-------------

.. code-block:: python

   from penaltyblog.viz import Theme

   custom = Theme.from_dict({
       "pitch_color": "#ffffff",
       "line_color": "#444444",
       "marker_color": "#e07a5f",
       "heatmap_colorscale": "Inferno",
       "heatmap_opacity": 0.8,
       "font_family": "Helvetica Neue, Arial, sans-serif",
       "line_width": 1.0,
       "marker_size": 8,
       "spot_size": 6,
       "hover_bgcolor": "rgba(50,50,50,0.8)",
       "hover_font_color": "white",
       "hover_border_color": "rgba(255,255,255,0.2)",
       "hover_font_family": "Helvetica Neue, Arial, sans-serif",
       "hover_font_size": 16,
       "title_margin": 50,
       "subtitle_margin": 30,
       "subnote_margin": 50,
   })

   pitch = Pitch(theme=custom)

üß™ Advanced Usage
=================

- ``return_trace=True``: retrieve Plotly object instead of plotting.
- ``orientation="vertical"``: flips pitch orientation.
- ``view=(30, 90)``: zoom into a region.
- Plot multiple layers and toggle them interactively.

üí° Tips
=======

- Use ``.set_layer_visibility()`` for interactive toggling in notebooks or dashboards.
- Use ``.set_layer_order()`` to control stacking (e.g., heatmap behind scatter).
- Works seamlessly with ``Flow`` objects or Pandas DataFrames.

Interactive Examples
--------------------

For a comprehensive, hands-on demonstration of the plotting using ``Pitch``, try the interactive Colab notebook.
The notebook walks you through all the different plotting methods, themes and customization options.

.. raw:: html

   <a href="https://colab.research.google.com/drive/1xFfIdvmbFcjHlS_2eHEu3NxD-xLNrbpY?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>
```### Tutorial: docs/api/backtest.rst
```rstBacktest
=============

.. automodule:: penaltyblog.backtest
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
```### Tutorial: docs/api/betting.rst
```rstBetting
==================

.. automodule:: penaltyblog.betting
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
```### Tutorial: docs/api/implied.rst
```rstImplied Odds
=============

.. automodule:: penaltyblog.implied
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
```### Tutorial: docs/api/index.rst
```rstAPI Reference
=================================

.. toctree::
   :maxdepth: 1
   :caption: Examples:

   backtest
   implied
   kelly
   metrics
   matchflow
   models
   ratings
   scrapers
   viz
```### Tutorial: docs/api/matchflow.rst
```rstMatchFlow
==========

.. automodule:: penaltyblog.matchflow
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:


.. automodule:: penaltyblog.matchflow.contrib.statsbomb
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
MatchFlow API Documentation
===========================

.. automodule:: penaltyblog.matchflow.flow
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.group
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.executor
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.optimizer
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.helpers
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.plotting
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.predicates
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.predicates_helpers
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.steps.group
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.steps.source
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.steps.transform
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:

.. automodule:: penaltyblog.matchflow.steps.utils
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
```### Tutorial: docs/api/metrics.rst
```rstMetrics
=============

.. automodule:: penaltyblog.metrics
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
```### Tutorial: docs/api/models.rst
```rstModels
==========

.. automodule:: penaltyblog.models
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
```### Tutorial: docs/api/ratings.rst
```rstRatings
=============

.. automodule:: penaltyblog.ratings
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
```### Tutorial: docs/api/scrapers.rst
```rstScrapers
=============

.. automodule:: penaltyblog.scrapers
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
```### Tutorial: docs/api/viz.rst
```rstVizualisations
===============

.. automodule:: penaltyblog.viz
   :members:
   :undoc-members:
   :show-inheritance:
   :inherited-members:
```### Tutorial: docs/references/index.rst
```rstReferences
============

The models and methodologies implemented in penaltyblog are grounded in well-established academic research on football analytics, probability modeling, and betting market efficiency.

The following references include foundational papers on Poisson and Bivariate Poisson models, Dixon-Coles adjustments, Elo and alternative rating systems, and approaches to estimating bookmaker probabilities.

These works have been instrumental in shaping the statistical techniques used within penaltyblog, providing a solid theoretical foundation for accurate football prediction and betting analysis.


- Baio, G., & Blangiardo, M. (2010). Bayesian hierarchical model for the prediction of football results. *Journal of Applied Statistics, 37*(2), 253‚Äì264. `Available here <https://discovery.ucl.ac.uk/id/eprint/16040/>`_.
- Buchdahl, J. (2015). *The Wisdom of the Crowd.* `Available here <https://www.football-data.co.uk/The_Wisdom_of_the_Crowd.pdf>`_.
- Constantinou, A. C., & Fenton, N. E. (2011). Solving the problem of inadequate scoring rules for assessing probabilistic football forecast models. *Risk Assessment and Decision Analysis Research Group (RADAR), Queen Mary University of London.* `Available here <https://eecs.qmul.ac.uk/~norman/papers/assessing_probabilistic_football_forecast_models.pdf>`_.
- Constantinou, A. C., Fenton, N. E., & Neil, M. (2013). Profiting from an inefficient Association Football gambling market: Prediction, risk, and uncertainty using Bayesian networks. *Knowledge-Based Systems, 50*(1), 60‚Äì86. `Available here <https://www.researchgate.net/publication/263282308_Profiting_from_an_inefficient_Association_Football_gambling_market_Prediction_Risk_and_Uncertainty_using_Bayesian_networks>`_.
- Dixon, M. J., & Coles, S. G. (1997). Modelling association football scores and inefficiencies in the football betting market. *Journal of the Royal Statistical Society: Series C (Applied Statistics), 46*(2), 265‚Äì280. `Available here <https://academic.oup.com/jrsssc/article-abstract/46/2/265/6990546>`_.
- Elo, A. (1978). *The Rating of Chessplayers, Past and Present.* Batsford. `Available here <https://gwern.net/doc/statistics/order/comparison/1978-elo-theratingofchessplayerspastandpresent.pdf>`_.
- Karlis, D., & Ntzoufras, I. (2003). Analysis of sports data by using bivariate Poisson models. *Journal of the Royal Statistical Society: Series D (The Statistician), 52*(3), 381‚Äì393. `Available here <https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9884.00243>`_.
- Maher, M. J. (1982). Modelling association football scores. *Statistica Neerlandica, 36*(3), 109‚Äì120. `Available here <https://doi.org/10.1111/j.1467-9574.1982.tb00782.x>`_.
- Rue, H., & Salvesen, √ò. (1999). Prediction and retrospective analysis of soccer matches in a league. *Journal of the Royal Statistical Society: Series D (The Statistician), 50*(3), 399‚Äì418. `Available here <https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9884.00243>`_.
- Shin, H. S. (1992). Prices of state contingent claims with insider traders, and the favourite-longshot bias. *The Economic Journal, 102*(411), 426‚Äì435. Published by Oxford University Press. `Available here <https://www.jstor.org/stable/2234521>`_.
- Shin, H. S. (1993). Measuring the incidence of insider trading in a market for state-contingent claims. *The Economic Journal, 103*(420), 1141‚Äì1153. Published by Oxford University Press. `Available here <https://www.jstor.org/stable/2234240>`_.







.. toctree::
   :maxdepth: 1
   :caption: Examples:

   rps
```### Tutorial: docs/metrics/briar.rst
```rstMulticlass Briar Score
======================

The multiclass Brier score is a proper scoring rule that measures the accuracy of probabilistic predictions across multiple categories by calculating the mean squared difference between predicted probabilities and actual outcomes.

For a prediction with K possible classes, it computes the sum of squared differences between the predicted probability for each class and the actual outcome (encoded as 1 for the true class and 0 for all others), making it essentially an extension of the binary Brier score to multiple categories.

The score ranges from 0 to 2, where 0 represents perfect prediction (assigning probability 1 to the correct class) and 2 represents the worst possible prediction (assigning probability 1 to an incorrect class), though in practice scores typically fall between 0 and 1 for reasonable models.

In soccer analytics, the multiclass Brier score is commonly used to evaluate match outcome predictions (home win/draw/away win) and is particularly valued because it's a strictly proper scoring rule - meaning forecasters are incentivized to report their true beliefs rather than hedging their predictions.

Unlike metrics that only consider the predicted class, the Brier score penalizes overconfident wrong predictions more severely than uncertain predictions, making it especially useful for assessing calibration in probabilistic forecasting models where understanding prediction confidence is as important as accuracy itself.

.. code-block:: python

    import penaltyblog as pb

    predictions = [
        [1, 0, 0],
        [0.9, 0.1, 0],
        [0.8, 0.1, 0.1],
        [0.5, 0.25, 0.25],
        [0.35, 0.3, 0.35],
        [0.6, 0.3, 0.1],
        [0.6, 0.25, 0.15],
        [0.6, 0.15, 0.25],
        [0.57, 0.33, 0.1],
        [0.6, 0.2, 0.2],
    ]

    observed = [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]

.. code-block:: python

    pb.metrics.multiclass_brier_score(predictions, observed)

.. code-block:: text

    0.30838
```### Tutorial: docs/metrics/ignorance.rst
```rstIgnorance Score
======================

The Ignorance Score, also known as the logarithmic scoring rule or log-loss, is a strictly proper scoring metric that evaluates probabilistic predictions by calculating the negative logarithm of the probability assigned to the actual outcome that occurred.

In practical terms, it measures how "surprised" a model is by the actual result - assigning a probability of 0.1 to an event that actually happens yields a high ignorance score of -log(0.1) ‚âà 2.3, while correctly assigning high probability like 0.9 yields a low score of -log(0.9) ‚âà 0.1.

The score ranges from 0 to infinity, where lower values indicate better predictions, and it heavily penalizes overconfident wrong predictions since the logarithm approaches infinity as probabilities approach zero.

In soccer analytics, the ignorance score is particularly useful for evaluating match prediction models because it forces forecasters to be well-calibrated across their entire probability range - a model cannot achieve good scores by simply being accurate on favorites while making poor predictions on underdogs.

Unlike the Brier score which uses squared differences, the logarithmic nature of the ignorance score makes it more sensitive to extreme probability assignments, making it especially valuable when the cost of being completely wrong is high, such as in betting scenarios where confidently backing the wrong outcome can be catastrophic.

.. code-block:: python

    import penaltyblog as pb

    predictions = [
        [1, 0, 0],
        [0.9, 0.1, 0],
        [0.8, 0.1, 0.1],
        [0.5, 0.25, 0.25],
        [0.35, 0.3, 0.35],
        [0.6, 0.3, 0.1],
        [0.6, 0.25, 0.15],
        [0.6, 0.15, 0.25],
        [0.57, 0.33, 0.1],
        [0.6, 0.2, 0.2],
    ]

    observed = [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]

.. code-block:: python

    pb.metrics.ignorance_score(predictions, observed)

.. code-block:: text

    0.7969725334773428
```### Tutorial: docs/metrics/index.rst
```rstMetrics
============

Useful functions for working with football (soccer) data, such as ranked probability scores (RPS) for
measuring the performance of football model predictions.

You can see article here for more details on selecting metrics in football analytics: https://pena.lt/y/2025/05/01/better-metrics-for-football-forecasts-moving-beyond-the-ranked-probability-score/

.. toctree::
   :maxdepth: 1
   :caption: Examples:

   ignorance
   briar
   rps
```### Tutorial: docs/metrics/rps.rst
```rstRanked Probability Scores (RPS)
================================

The Ranked Probability Score (RPS) is a metric used to evaluate the accuracy of probabilistic predictions for ordinal outcomes, making it particularly useful in sports analytics where results naturally have an order (win > draw > loss).

Unlike traditional accuracy metrics that only consider whether the predicted outcome was correct, RPS accounts for the entire probability distribution across all possible outcomes and penalizes predictions based on how "wrong" they are - for instance, predicting a home win when the actual result is a draw incurs a smaller penalty than predicting a home win when the away team wins.

Mathematically, RPS is calculated as the sum of squared differences between the cumulative probability distributions of the predicted and observed outcomes, where a lower score indicates better prediction accuracy.

In soccer analytics, RPS is especially valuable for evaluating betting models and match prediction systems because it rewards models that assign high probabilities to outcomes "close" to the actual result, providing a more nuanced assessment than simple binary accuracy or log-loss metrics that don't account for the ordinal relationship between match outcomes.

.. code-block:: python

    import penaltyblog as pb

    predictions = [
        [1, 0, 0],
        [0.9, 0.1, 0],
        [0.8, 0.1, 0.1],
        [0.5, 0.25, 0.25],
        [0.35, 0.3, 0.35],
        [0.6, 0.3, 0.1],
        [0.6, 0.25, 0.15],
        [0.6, 0.15, 0.25],
        [0.57, 0.33, 0.1],
        [0.6, 0.2, 0.2],
    ]

    observed = [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]

.. code-block:: python

    pb.metrics.rps_array(predictions, observed)

.. code-block:: text

    array([0.     , 0.005  , 0.025  , 0.15625, 0.1225 , 0.185  , 0.09125,
       0.11125, 0.09745, 0.1])

.. code-block:: python

    pb.metrics.rps_average(predictions, observed)

.. code-block:: text

    0.08937
```### Tutorial: docs/models/bayesian.rst
```rst====================================
Bayesian Football Goal Models
====================================

The ``penaltyblog`` package provides powerful Bayesian alternatives to traditional Maximum Likelihood Estimation (MLE) models. These models use Markov Chain Monte Carlo (MCMC) sampling to estimate the full posterior distribution of model parameters, allowing you to account for parameter uncertainty in your predictions.

Bayesian Goal Model
===================

The ``BayesianGoalModel`` implements the Dixon-Coles methodology within a Bayesian framework. Instead of single point estimates for team strengths, it provides a distribution of possible values.

- **Idea**: Use MCMC (via an ensemble sampler) to sample from the posterior distribution of attack, defense, home advantage, and rho parameters.
- **Strengths**: Captures parameter uncertainty, provides full posterior distributions, avoids over-fitting in small datasets via priors.
- **Best for**: Small datasets, understanding uncertainty, or when you need more than just point estimates.

Hierarchical Bayesian Goal Model
================================

An advanced extension that automatically learns the 'variance' of the league's attack and defense strengths.

- **Idea**: The priors for team attack and defense strengths are themselves learned from the data (hierarchical priors).
- **Strengths**: Automatically adjusts the 'shrinkage' of team strengths towards the mean based on the league's overall competitiveness.
- **Best for**: Multi-league modeling or when you want the model to decide how much to "trust" individual team performances versus the league average.

Quick Example
=============

Fitting a Bayesian model follows the same consistent API as other ``penaltyblog`` models, with a few extra options for the MCMC sampler.

.. code-block:: python

    from penaltyblog.models import BayesianGoalModel

    # Initialize the model
    model = BayesianGoalModel(
        train["goals_home"],
        train["goals_away"],
        train["team_home"],
        train["team_away"],
    )

    # Fit using MCMC sampling
    # n_samples: number of samples per chain
    # burn: samples to discard at the start
    # n_chains: number of parallel chains
    # thin: thinning factor to reduce autocorrelation
    model.fit(n_samples=1000, burn=1000, n_chains=4, thin=5)

    # Predict probabilities for a fixture
    # This automatically integrates over the posterior distribution
    prediction = model.predict("Arsenal", "Manchester City")
    print(prediction.home_draw_away)

MCMC Diagnostics
================

When using Bayesian models, it is crucial to verify that the MCMC chains have converged. ``penaltyblog`` provides built-in diagnostics for R-hat (Gelman-Rubin) and Effective Sample Size (ESS).

.. code-block:: python

    # Get a DataFrame with R-hat and ESS for all parameters
    diagnostics = model.get_diagnostics()
    print(diagnostics)

Generally, you want **R-hat values close to 1.0** (typically < 1.1) and a sufficiently large **Effective Sample Size** for all parameters to ensure reliable inference.

Inspecting the Posterior
========================

After calling the ``fit()`` method, the ``trace_dict`` attribute contains the traces for all parameters. You can use these to visualize the uncertainty in team strengths.

.. code-block:: python

    # Access the trace dictionary
    print(model.trace_dict.keys())

    # Example: get the posterior samples for Arsenal's attack
    arsenal_att = model.trace_dict["attack_Arsenal"]

Diagnostic Plotting
===================

The Bayesian models provide rich interactive diagnostic plots to assess MCMC convergence and parameter distributions. All plotting methods return Plotly figures that can be displayed in Jupyter notebooks or saved to files.

Trace Plots
-----------

Trace plots show the evolution of parameter values across MCMC iterations. Well-converged chains should look like "fuzzy caterpillars" with no trends or drift.

.. code-block:: python

    # Plot trace for all parameters (default)
    # Shows: home_advantage, rho, sigma_* (if hierarchical),
    # and ALL team attack/defense parameters (overlaid)
    fig = model.plot_trace()
    fig.show()

    # Plot specific parameters
    fig = model.plot_trace(params=["home_advantage", "rho"])
    fig.show()

    # Combine chains instead of showing them separately
    fig = model.plot_trace(chains=False)
    fig.show()

**Team Parameter Overlays**: By default, all team attack parameters are overlaid on one subplot (with different colors per team), and all defense parameters on another. This creates compact, readable plots that make it easy to compare convergence across teams.

Autocorrelation Plots
---------------------

Autocorrelation plots help identify the thinning interval needed for independent samples. Autocorrelation should decay to near zero within a reasonable lag.

.. code-block:: python

    # Plot autocorrelation for all parameters
    fig = model.plot_autocorr()
    fig.show()

    # Customize maximum lag
    fig = model.plot_autocorr(max_lag=100)
    fig.show()

    # Plot specific parameters
    fig = model.plot_autocorr(params=["home_advantage"])
    fig.show()

Posterior Distribution Plots
-----------------------------

Visualize the marginal posterior distributions to see the uncertainty in parameter estimates.

.. code-block:: python

    # Plot posterior distributions (density plots)
    fig = model.plot_posterior()
    fig.show()

    # Use histograms instead of density plots
    fig = model.plot_posterior(kind="histogram")
    fig.show()

    # Plot specific parameters
    fig = model.plot_posterior(params=["home_advantage", "rho"])
    fig.show()

Convergence Diagnostics Plot
-----------------------------

Visualize R-hat and Effective Sample Size (ESS) for all parameters in a single plot.

.. code-block:: python

    # Plot convergence diagnostics
    fig = model.plot_convergence()
    fig.show()

The plot uses color coding:
- **Green**: Excellent convergence (R-hat < 1.01, ESS > 400)
- **Orange**: Acceptable (R-hat < 1.1, ESS > 100)
- **Red**: Poor convergence (needs more samples)

Comprehensive Diagnostic Dashboard
-----------------------------------

Create a multi-panel figure combining trace, autocorrelation, and posterior plots.

.. code-block:: python

    # Create comprehensive diagnostic dashboard
    fig = model.plot_diagnostics()
    fig.show()

This creates a 3-column layout with trace, autocorrelation, and posterior plots for each parameter, providing a complete view of MCMC performance.

Customizing Plots
-----------------

All plotting methods accept additional keyword arguments that are passed to Plotly's ``update_layout()`` method:

.. code-block:: python

    # Customize plot appearance using Plotly layout parameters
    fig = model.plot_trace(
        width=1200,
        height=800,
        title="Custom MCMC Trace Plot",
        showlegend=True
    )
    fig.show()

    # Save to file
    fig.write_html("diagnostics.html")
    fig.write_image("diagnostics.png")  # Requires kaleido

For a full list of available layout parameters, see the `Plotly documentation <https://plotly.com/python/reference/layout/>`_.
```### Tutorial: docs/models/football_prob_grid.rst
```rst========================================
FootballProbabilityGrid (Model Output)
========================================

All goals models in ``penaltyblog`` return a ``FootballProbabilityGrid`` when you call ``.predict(home_team, away_team)``.

This object wraps the full exact-score **probability grid** and provides **fast, vectorised access** to popular betting markets and analytics in a single, consistent interface.

Why it's useful
================

- **One object, many markets**: 1X2, BTTS, totals (with **push**), Asian handicaps (including **quarter lines**), double chance, DNB, win to nil, clean sheets, expected points, and more.
- **Internally consistent**: Every market is derived from the same score grid, so probabilities never conflict.
- **Fast**: Vectorised NumPy operations and lightweight caching for repeated calls.
- **Backwards compatible**: Older methods like ``total_goals("over", 2.5)`` and ``asian_handicap("home", -0.5)`` still work.

Quick Start
===========

.. code-block:: python

   pred = model.predict("Arsenal", "Manchester City")

   # 1X2
   pred.home_win      # P(Home win)
   pred.draw          # P(Draw)
   pred.away_win      # P(Away win)
   pred.home_draw_away  # [P(Home), P(Draw), P(Away)]

   # Expected goals (from the fitted model)
   pred.home_goal_expectation
   pred.away_goal_expectation

   # Both Teams To Score
   pred.btts_yes                 # BTTS Yes
   pred.btts_no                  # BTTS No

   # Totals (with push handling)
   pred.totals(2.0)              # -> (under, push, over)
   pred.total_goals("over", 2.5) # backward-compatible: returns P(Over 2.5)

   # Asian handicap
   pred.asian_handicap_probs("home", -0.25)  # -> {"win": ..., "push": ..., "lose": ...}
   pred.asian_handicap("home", -0.5)         # backward-compatible: win prob only

   # More handy markets
   pred.double_chance_1x
   pred.double_chance_x2
   pred.double_chance_12
   pred.draw_no_bet_home
   pred.draw_no_bet_away

   # Distributions & exact scores
   pred.exact_score(2, 1)                # P(2-1)
   pred.home_goal_distribution()         # P(H=0), P(H=1), ...
   pred.away_goal_distribution()
   pred.total_goals_distribution()       # P(T=0), P(T=1), ...

   # Team-centric analytics
   pred.win_to_nil_home()
   pred.win_to_nil_away()
   pred.expected_points_home()
   pred.expected_points_away()

API Summary
===========

+--------------------------------------------------------------+-------------------------------------------------------------------------+
| Attribute / Method                                           | Description                                                             |
+==============================================================+=========================================================================+
| ``grid``                                                     | 2D ``np.ndarray`` with exact-score probabilities ``grid[h, a] = P(H=h, A=a)`` |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``home_goal_expectation``, ``away_goal_expectation``         | Expected goals for each team                                            |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``home_win``, ``draw``, ``away_win``                         | 1X2 probabilities                                                       |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``home_draw_away``                                           | ``[P(Home), P(Draw), P(Away)]``                                         |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``btts_yes``, ``btts_no``                                    | BTTS Yes/No probabilities                                               |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``totals(line)``                                             | Returns ``(under, push, over)`` for integer/half lines (e.g., 2.0, 2.5) |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``total_goals(side, line)``                                  | Back-compat Over/Under prob (push excluded)                             |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``asian_handicap_probs(side, line)``                         | Proper **Win/Push/Lose** for integer/half/**quarter** lines             |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``asian_handicap(side, line)``                               | Back-compat: **win** probability only                                   |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``double_chance_1x``, ``double_chance_x2``, ``double_chance_12`` | Double chance markets                                                |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``draw_no_bet_home``, ``draw_no_bet_away``                   | DNB win probabilities (conditional on no draw)                          |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``exact_score(h, a)``                                        | Probability of an exact scoreline                                       |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``home_goal_distribution()``                                 | Marginal distribution over home goals                                   |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``away_goal_distribution()``                                 | Marginal distribution over away goals                                   |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``total_goals_distribution()``                               | Distribution over total goals ``T = H + A``                             |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``win_to_nil_home()``, ``win_to_nil_away()``                 | Win-to-nil probabilities                                                |
+--------------------------------------------------------------+-------------------------------------------------------------------------+
| ``expected_points_home()``, ``expected_points_away()``       | Expected points under 3/1/0                                             |
+--------------------------------------------------------------+-------------------------------------------------------------------------+

Totals: Over/Under and Pushes
==============================

Totals lines can **push** when the line is an integer (e.g., 2.0). Use ``totals(line)`` to get the full breakdown:

.. code-block:: python

   under, push, over = pred.totals(2.0)   # push > 0 possible at integer lines
   p_over_25 = pred.total_goals("over", 2.5)  # back-compat helper (no push)

- Half-lines (e.g., **2.5**) cannot push ‚Üí push = 0.
- Integer lines (e.g., **2.0**) can push ‚Üí non-zero push.

Asian Handicap: Integer, Half, and Quarter Lines
================================================

The grid supports correct settlement for **integer**, **half**, and **quarter** lines:

.. code-block:: python

   # Quarter lines split stake across neighbouring half-lines
   pred.asian_handicap_probs("home", -0.25)  # 50% at 0.0, 50% at -0.5 internally
   pred.asian_handicap_probs("away", +1.0)   # integer line: push possible

- ``asian_handicap_probs(side, line)`` ‚Üí ``{"win": p, "push": p, "lose": p}``
- ``asian_handicap(side, line)`` ‚Üí **win** probability only (backwards compatible)

Performance Notes
=================

- Operations use **NumPy masks** and **lazy caching** for frequently accessed metrics (e.g., ``home_win``, ``draw``, ``away_win``).
- The probability grid is validated on construction and (optionally) **normalised** to sum to **1**.
- You can enable normalisation via ``normalize=True`` if required.

Controlling Grid Normalisation
==============================

By default, ``FootballProbabilityGrid`` **normalises** the score grid so that all exact-score probabilities sum to 1. However, you can control this behaviour via the model's ``predict`` method:

.. code-block:: python

   # Normalised grid (default)
   pred = model.predict("Arsenal", "Manchester City", normalize_grid=True)

   # Skip normalisation (use your grid as-is)
   pred = model.predict("Arsenal", "Manchester City", normalize_grid=False)

- ``normalize_grid=True`` (default) ‚Üí the returned ``FootballProbabilityGrid`` normalises its grid.
- ``normalize_grid=False`` ‚Üí normalisation is skipped (useful if you already normalised externally or are auditing raw grids).

Normalising vs Not Normalising the Probability Grid
===================================================

When you call ``.predict(...)``, the model calculates probabilities for all scorelines from 0‚Äì``max_goals`` (default: 15). This means extremely high-scoring outcomes (e.g., 16‚Äì14) are excluded from the grid.

There are two approaches to handling this:

Not normalising
---------------

The probability grid keeps its *true* mass, with the missing probability sitting beyond the ``max_goals`` cut-off. This is statistically purist, but it means your derived markets (1X2, totals, Asian handicaps) will not sum exactly to 1.0. For example, you might see ``home_win + draw + away_win = 0.9999997``. This may be awkward if you need perfectly balanced pricing or hedging.

Normalising
-----------

The grid is rescaled so that all probabilities sum exactly to 1.0. The small "tail" probability beyond ``max_goals`` is implicitly reallocated proportionally across the included outcomes. This ensures all markets are internally consistent - 1X2, totals, and Asian handicap probabilities will align perfectly - and is generally safe if the missing probability mass is negligible.

By default, ``penaltyblog`` normalises the grid to avoid confusing inconsistencies in downstream markets. Advanced users can disable this with ``normalize_grid=False`` in ``.predict()`` if they want to inspect the raw, unadjusted probabilities.

Backwards Compatibility
=======================

- The following legacy-style calls still work exactly as before:
    - ``pred.total_goals("over"|"under", strike)`` - returns probability excluding pushes.
    - ``pred.asian_handicap("home"|"away", strike)`` - returns win probability only.
- Prefer the new, more explicit variants for production:
    - ``pred.totals(strike)`` to obtain (under, push, over)
    - ``pred.asian_handicap_probs(side, strike)`` for Win/Push/Lose

Reproducibility & Export (Optional Tips)
========================================

Because all markets derive from ``pred.grid``, you can export or visualise it for auditing:

.. code-block:: python

   import pandas as pd

   grid_df = pd.DataFrame(pred.grid)   # rows: home goals, cols: away goals
   grid_df.to_csv("score_grid.csv", index_label="home_goals")

This makes it easy to trace any market probability back to the underlying score distribution.
```### Tutorial: docs/models/goal_expectancy.rst
```rst===============================================
Inferring Goal Expectancies from Bookmaker Odds
===============================================

``penaltyblog`` also includes a utility that works in the **opposite** direction to the goals models: given **bookmaker 1X2 probabilities** (home/draw/away), it estimates the **implied goal expectancies** (Œº_home, Œº_away).

What it does
============

- Finds Œº_home and Œº_away such that a Poisson (optionally Dixon‚ÄìColes-adjusted) model best matches the given 1X2 probabilities.
- Uses numerical optimisation (scipy.optimize.minimize) with stable parameterisation (log Œº bounded).
- Supports:
    - Time-decay adjustment for low-score events (Dixon‚ÄìColes).
    - Flexible scoring rules: Brier/MSE or cross-entropy.
    - Configurable grid size (max_goals) and normalisation after Dixon‚ÄìColes adjustment.

Parameters
==========

- **home, draw, away** - 1X2 probabilities (must be in [0,1]).
- **dc_adj** - whether to apply Dixon‚ÄìColes adjustment.
- **rho** - correlation parameter for Dixon‚ÄìColes.
- **minimizer_options** - dict of options to pass to SciPy's optimiser.
- **max_goals** - maximum goals per team in the grid (default 15 ‚áí 0‚Äì15 inclusive).
- **remove_overround** - if True, probabilities are renormalised to sum to 1 before fitting.
- **method** - optimiser method (default "L-BFGS-B").
- **bounds** - bounds on (log Œº_home, log Œº_away) for stability.
- **x0** - optional starting guess for (log Œº_home, log Œº_away).
- **renormalize_after_dc** - if True, re-normalises the probability grid after DC adjustments and clips small negatives.
- **objective** - 'brier' for mean-squared error or 'cross_entropy' for KL-style loss.
- **return_details** - if True, includes extra audit information in the result.

Returns
=======

A dict with:

- ``home_exp`` - implied home goal expectancy (Œº_home)
- ``away_exp`` - implied away goal expectancy (Œº_away)
- ``error`` - final mean squared error between predicted and target 1X2
- ``success`` - whether the optimiser reported success

If ``return_details=True``, also includes:

- **predicted** - model's predicted [P(home win), P(draw), P(away win)]
- **mass** - total probability in the truncated grid (‚â§ 1.0 if max_goals small or normalize_after_dc=False)

Quick Example
=============

.. code-block:: python

   from penaltyblog.models import goal_expectancy
   from pprint import pprint

   # Suppose your market is:
   p_home, p_draw, p_away = 0.45, 0.28, 0.29

   est = goal_expectancy(
       home=p_home,
       draw=p_draw,
       away=p_away,
       dc_adj=True,              # use Dixon‚ÄìColes low-score correction
       rho=0.001,                # typical small value
       minimizer_options={"maxiter": 5000},
       remove_overround=True
   )

   pprint(est)

.. code-block:: text

   {'away_exp': 1.018968393752446,
    'error': 1.4642670964617868e-12,
    'home_exp': 1.3415375327000219,
    'mass': 0.9999999999999999,
    'predicted': array([0.44117672, 0.27450821, 0.28431507]),
    'success': True}

You can then use these expectancies directly in your own Poisson simulator or as a prior/anchor when comparing to model-based expectancies.

Notes & Best Practices
======================

- **Probabilities vs odds:** If you start from odds, convert to probabilities and (optionally) remove overround before passing to this function.
- **Truncation:** Only scores up to ``max_goals`` are considered; very small tail mass may be lost if ``normalize_after_dc=False``.
- **DC adjustment:** Can help fit when draw prices are high; rho is typically small (0.001‚Äì0.01).
- **Stability:** The optimiser works on bounded log-Œº space, preventing non-physical negative goal expectancies.
- **Diagnostics:** Use ``return_details=True`` to check mass and predicted 1X2 to understand residual errors.

Behind the Scenes: How the Optimiser Works
==========================================

This function reverse-engineers Œº_home and Œº_away via a small **non-linear optimisation** problem.

1. Parameterisation
-------------------

- The optimiser works in **log Œº** space (``log_mu_home``, ``log_mu_away``), ensuring Œº > 0 at all times.
- Bounds on log Œº (default ``[-3, 3]``) correspond to Œº ‚àà [0.05, 20] ‚Äì covering realistic football scoring ranges but preventing runaway values that could destabilise the fit.

2. Objective Function
---------------------

- Default: **Brier score** (mean squared error) between the model's predicted 1X2 probabilities and the input values.
- Alternative: **Cross-entropy** loss (KL divergence direction) if ``objective='cross_entropy'``.

3. Probability Grid
-------------------

- A Poisson model generates a probability matrix over scores ``(0..max_goals) √ó (0..max_goals)``.
- The Dixon‚ÄìColes adjustment optionally tweaks four low-score cells to better match real-world correlation in low-scoring games.
- If ``renormalize_after_dc=True``, the grid is re-scaled to sum exactly to 1.0 after the adjustment (and any small negatives are clipped).

4. From Grid to 1X2
--------------------

- ``P(home win)`` = sum of all cells below the main diagonal.
- ``P(draw)`` = sum of diagonal cells.
- ``P(away win)`` = sum of cells above the diagonal.

5. Optimisation
---------------

- The optimiser (``scipy.optimize.minimize``) searches log Œº space to minimise the chosen loss.
- By default, the **L-BFGS-B** method is used, as it handles bounds well and converges quickly for small parameter spaces.
- The starting guess defaults to a mild home advantage (``log(1.3)``, ``log(1.1)``), but you can override with ``x0``.

6. Diagnostics & Tail Mass
---------------------------

- The returned ``mass`` is the sum of all probabilities in the truncated grid.
  If ``max_goals`` is too low, ``mass`` < 1.0 means you've cut off a non-negligible tail - increasing ``max_goals`` will reduce this.
- With ``normalize_after_dc=False``, residuals may include both truncation error and DC-induced mass shifts.
```### Tutorial: docs/models/index.rst
```rstGoal Models
========================

This section provides powerful statistical models for predicting the outcomes of football (soccer) matches.

Each model can generate accurate probability estimates across various betting markets, including match results, total goals, Asian handicaps, and over/under goals.

For users interested in understanding the underlying theory of these models, links to detailed explanations and foundational research papers are provided via the the `pena.lt/y/blog`_ website.

.. toctree::
   :maxdepth: 1
   :caption: Examples:

   overview
   football_prob_grid
   example
   goal_expectancy
   bayesian


.. _`pena.lt/y/blog`: http://www.pena.lt/y/blog.html
```### Tutorial: docs/models/overview.rst
```rst==============================
Overview of the Different Models
==============================

The ``penaltyblog`` package provides a suite of **robust, ready-to-use statistical models** for predicting football (soccer) match scores. All models are **highly optimised with Cython** for speed, making them fast, even for large-scale forecasting, betting analysis, and live in-play applications. Whether you want a quick baseline or an advanced model capturing complex goal-scoring patterns, ``penaltyblog``'s models provide a consistent, user-friendly API.

1. Poisson Goals Model
======================

The simplest and most widely used approach.

- **Idea**: Goals follow a Poisson distribution, with rates determined by attack strength, defense strength, and home advantage.
- **Strengths**: Easy to understand, quick to fit, good baseline accuracy.
- **Weaknesses**: Overpredicts high scores, struggles with low-score biases.
- **Best for**: General forecasting, fast model training.

2. Dixon and Coles Goals Model
==============================

A refinement of the Poisson model that corrects for the higher-than-expected frequency of low-score draws (e.g., 0-0, 1-0, 1-1).

- **Strengths**: More realistic score predictions in low-scoring leagues, improved match outcome accuracy.
- **Weaknesses**: Adds parameter tuning, assumes the same low-score adjustment for all matches.
- **Best for**: Leagues with many draws or defensive play styles.

3. Bivariate Poisson Goals Model
================================

Extends the Poisson model by introducing correlation between teams' goal counts.

- **Strengths**: Captures match dynamics affecting both teams, better for high-scoring matches.
- **Weaknesses**: More complex and harder to interpret, slower to fit.
- **Best for**: Leagues where team performances are strongly linked (e.g., end-to-end attacking games).

4. Zero-Inflated Poisson Goals Model
====================================

Adds an explicit mechanism for handling excess goalless matches.

- **Strengths**: Improves accuracy in ultra-defensive contexts.
- **Weaknesses**: Only adjusts for excess 0-0 games; doesn't fix other Poisson issues.
- **Best for**: Competitions or teams with frequent goalless draws.

5. Negative Binomial Goals Model
================================

Handles **overdispersion** - when goal count variance is greater than the mean.

- **Strengths**: More realistic for high-scoring or unpredictable leagues, better at extreme results.
- **Weaknesses**: Still assumes independence between team scores.
- **Best for**: High-variance, goal-heavy competitions.

6. Weibull Count + Copula Goals Model
=====================================

A more flexible alternative to Poisson-based models, using a Weibull distribution for goals and a copula for score correlation.

- **Strengths**: Handles complex goal patterns and diverse score dependencies.
- **Weaknesses**: Statistically and computationally intensive, not always worth the added complexity.
- **Best for**: Advanced modelling in leagues with unusual scoring patterns.

7. Bayesian Goal Models
=======================

Uses MCMC sampling to estimate the full posterior distribution of parameters.

- **Strengths**: Captures parameter uncertainty, avoids over-fitting, provides full distributions.
- **Weaknesses**: Computationally expensive (slow to fit), requires convergence diagnostics.
- **Best for**: Small datasets, understanding uncertainty.

8. Hierarchical Bayesian Goal Model
===================================

An advanced Bayesian model that learns league-wide priors for team strengths.

- **Strengths**: Automatically adjusts shrinkage, excellent for multi-league or sparse data.
- **Weaknesses**: Most computationally intensive model.
- **Best for**: Professional-grade modeling where capturing uncertainty is critical.

Model Comparison
================

+----------------------------+---------------------------------------------------+-------------------------------------------------+---------------+
| Model                      | Strengths                                         | Weaknesses                                      | Best Used For |
+============================+===================================================+=================================================+===============+
| **Poisson**                | Simple, efficient, widely used                   | Overpredicts high scores, ignores low-score bias| General forecasting |
+----------------------------+---------------------------------------------------+-------------------------------------------------+---------------+
| **Dixon & Coles**          | Corrects low-score bias, better match accuracy   | Fixed adjustment across matches, extra tuning  | Low-scoring leagues |
+----------------------------+---------------------------------------------------+-------------------------------------------------+---------------+
| **Bivariate Poisson**      | Models score correlation, useful for high-scoring| Complex, harder to interpret                    | High-scoring leagues |
+----------------------------+---------------------------------------------------+-------------------------------------------------+---------------+
| **Zero-Inflated Poisson**  | Better at goalless matches                       | Only fixes 0-0 bias                            | Defensive teams |
+----------------------------+---------------------------------------------------+-------------------------------------------------+---------------+
| **Negative Binomial**      | Handles overdispersion, realistic extreme scores | Still independent goal counts                   | High-scoring, volatile leagues |
+----------------------------+---------------------------------------------------+-------------------------------------------------+---------------+
| **Weibull + Copula**       | Flexible distribution & correlation modelling    | Highly complex, slow to fit                     | Complex goal patterns |
+----------------------------+---------------------------------------------------+-------------------------------------------------+---------------+
| **Bayesian**               | Captures parameter uncertainty                   | Slow to fit, requires convergence checks       | Small data, uncertainty |
+----------------------------+---------------------------------------------------+-------------------------------------------------+---------------+
| **Hierarchical Bayesian**  | Learns priors, automatic shrinkage               | Very slow to fit                               | Sparse data, multi-league |
+----------------------------+---------------------------------------------------+-------------------------------------------------+---------------+

Consistent API Across Models
=============================

All goal models in ``penaltyblog`` share the **same interface**, making it simple to switch between them, run comparisons, or fine-tune parameters without rewriting your code.

This design means you can:

- Swap out a Poisson model for a Dixon & Coles model in one line.
- Benchmark multiple models on the same dataset with minimal changes.
- Apply optimisations (like lookback windows or time weighting) consistently across all models.

Common Methods
--------------

Every model implements the following core methods:

- ``fit(minimizer_options)``: Train the model using your dataset.
- ``predict(home_team, away_team, max_goals, normalize)``: Predict scoreline probabilities for a given fixture.
- ``get_params()``: Retrieve the model's fitted parameters.
- ``save(filepath)``: Save the model to disk as a pickled file.
- ``load(filepath)``: Load the saved model.

Example
-------

Switching from a Poisson model to a Dixon and Coles model is as simple as:

.. code-block:: python

   from penaltyblog.models import PoissonGoalsModel, DixonColesGoalsModel

   # Train a Poisson model
   model = PoissonGoalsModel(
       train["goals_home"],
       train["goals_away"],
       train["team_home"],
       train["team_away"],
   )
   model.fit()

   # Swap to Dixon & Coles
   model = DixonColesGoalsModel(
       train["goals_home"],
       train["goals_away"],
       train["team_home"],
       train["team_away"],
   )
   model.fit()

   # Predict probabilities for a fixture
   prediction = model.predict("Arsenal", "Manchester City")
   print(prediction.home_draw_away)

Because the API is consistent, you can automate model testing and tuning. For example, by looping through a list of model classes, fitting each one, and comparing metrics like Ranked Probability Score (RPS) without special-case code.

Time Weighting to Prioritise Recent Matches
============================================

Football is dynamic - teams change managers, players, and tactics over time. Using too much historical data can let outdated results dilute your predictions.

To address this, all ``penaltyblog`` models support **time weighting**, allowing you to give recent fixtures more influence than older ones.

The most common approach is the **Dixon and Coles exponential decay weighting**, where a decay factor ``Œæ`` controls how quickly older matches lose importance:

- ``Œæ = 0`` ‚Üí all matches are weighted equally.
- Small ``Œæ`` (e.g., 0.001) ‚Üí older matches still contribute, but recent ones matter more.
- Large ``Œæ`` (e.g., 0.03) ‚Üí the model focuses heavily on the most recent results.

Example
-------

.. code-block:: python

   from penaltyblog.models import PoissonGoalsModel, dixon_coles_weights

   # Generate weights with a decay factor of 0.001
   weights = dixon_coles_weights(train["date"], xi=0.001)

   # Fit a Poisson model using time weighting
   model = PoissonGoalsModel(
       train["goals_home"],
       train["goals_away"],
       train["team_home"],
       train["team_away"],
       weights=weights
   )
   model.fit()

Rich Probability Outputs for Betting and Analytics
==================================================

All goal models in ``penaltyblog`` return their predictions as a ``FootballProbabilityGrid`` object.

This class automatically gives you access to a wide range of **pre-calculated betting markets and metrics**, with no extra coding required.

When you call ``.predict(home_team, away_team)``, you receive:

- The **full probability grid** for every possible scoreline (e.g., 0‚Äì0, 1‚Äì0, 2‚Äì3, ‚Ä¶)
- Expected goals for each team (``home_goal_expectation``, ``away_goal_expectation``)
- Ready-to-use probabilities for popular markets:
  - **Match result** (``home_win``, ``draw``, ``away_win``, ``home_draw_away``)
  - **Both Teams to Score** (``both_teams_to_score``)
  - **Over/Under Total Goals** (``total_goals("over", strike)``)
  - **Asian Handicap** (``asian_handicap("home", strike)`` / ``asian_handicap("away", strike)``)

Example
-------

.. code-block:: python

   prediction = model.predict("Arsenal", "Manchester City")

   # Expected goals
   print(prediction.home_goal_expectation)  # e.g. 1.45
   print(prediction.away_goal_expectation)  # e.g. 1.12

   # Match odds (1X2)
   print(prediction.home_draw_away)  # [P(Home), P(Draw), P(Away)]

   # Both teams to score
   print(prediction.both_teams_to_score)  # Probability both teams score

   # Over/Under 2.5 goals
   print(prediction.total_goals("over", 2.5))

   # Asian handicap (home -0.5)
   print(prediction.asian_handicap("home", -0.5))

Because the grid is generated directly from the underlying scoreline probabilities, **all these markets are perfectly internally consistent** - a crucial advantage for betting analytics and trading models. No more recalculating market probabilities from scratch; the ``FootballProbabilityGrid`` makes it instant.

Faster Fitting with Gradients (Optional)
=========================================

All goals models now support **analytical gradients** during fitting to speed up convergence. Gradients are **on by default** but can be **turned off** for backward compatibility or if they don't suit your data.

- **Why use gradients?** Faster, more stable optimisation and fewer iterations.
- **When to turn them off?** If you're experimenting, debugging, or working with unusual data where numerical optimisation behaves better.

Example
-------

.. code-block:: python

   # Gradients enabled (default)
   model.fit()

   # Turn gradients off (backward compatible behaviour)
   model.fit(use_gradient=False)

.. note::
   Under the hood, when ``use_gradient=True``, the model supplies a ``jac`` function to ``scipy.optimize.minimize``. When ``use_gradient=False``, it omits ``jac``, falling back to numerical approximations.

Passing Options to the Optimiser
=================================

You can pass keyword options straight through to SciPy's optimiser via the ``minimizer_options`` argument. Typical knobs include ``maxiter``, ``ftol``, ``gtol``, etc. (the optimisation method is chosen per-model to suit its bounds/constraints).

Example
-------

.. code-block:: python

   # Increase iterations and tighten tolerances
   model.fit(
       minimizer_options={
           "maxiter": 5000,
           "gtol": 1e-8,
           "ftol": 1e-9,
           "disp": False,  # silence SciPy output
       }
   )

   # Combine with gradient toggle
   model.fit(
       use_gradient=True,
       minimizer_options={"maxiter": 3000, "gtol": 1e-8}
   )

.. note::
   Each model chooses an appropriate optimisation method internally based on bounds/constraints. The ``minimizer_options`` you provide are forwarded to ``scipy.optimize.minimize(options=...)``.

Inspecting Fit Results
======================

After fitting, models expose common diagnostics:

- ``model.fitted`` ‚Äî boolean flag
- ``model.loglikelihood`` ‚Äî maximised log-likelihood
- ``model.n_params`` ‚Äî number of fitted parameters
- ``model.aic`` ‚Äî Akaike Information Criterion
- ``model.params`` / ``model.get_params()`` ‚Äî dict of named parameters

Example
-------

.. code-block:: python

   model.fit()
   print(model.fitted, model.loglikelihood, model.aic)
   print(model.params)

Accessing Parameters Directly
==============================

For advanced use cases, you can access the model's parameters directly via **NumPy arrays** and **parameter indices**. This is useful when you need to perform numerical operations on the parameters, integrate with external tools, or apply custom adjustments.

``params_array`` Property
--------------------------

The ``params_array`` property returns a **read-only copy** of the fitted parameter vector as a NumPy array. This provides direct access to the underlying parameter values for downstream tools that need to perform numerical calculations.

The parameter layout follows a consistent pattern:

.. code-block:: text

   [attack_0, ..., attack_{n-1}, defense_0, ..., defense_{n-1}, <model_specific_params>]

Where ``n`` is the number of teams in the training data.

Model-specific trailing parameters:

- **Poisson**: ``[home_advantage]``
- **DixonColes**: ``[home_advantage, rho]``
- **NegativeBinomial**: ``[home_advantage, dispersion]``
- **ZeroInflatedPoisson**: ``[home_advantage, zero_inflation]``
- **BivariatePoisson**: ``[home_advantage, correlation]``
- **WeibullCopula**: ``[home_advantage, shape, kappa]``

Example:

.. code-block:: python

   model.fit()
   p = model.params_array

   # Access a team's attack strength
   arsenal_attack = p[model.team_to_idx["Arsenal"]]

   # Access home advantage (always at position -2 for most models)
   hfa = p[-2]

.. note::
   ``params_array`` returns a **copy**, so modifications to the array do not affect the model.

``param_indices()`` Method
--------------------------

The ``param_indices()`` method returns a dictionary that maps **parameter group names** to their positions in the parameter array. This provides a stable API for accessing parameters without relying on internal implementation details.

Returns:

- ``'attack'``: slice for attack parameters (0 to n_teams)
- ``'defense'``: slice for defense parameters (n_teams to 2*n_teams)
- Model-specific keys for trailing parameters

Example:

.. code-block:: python

   model.fit()
   idx = model.param_indices()

   # Get all attack parameters
   attacks = model.params_array[idx['attack']]

   # Get all defense parameters
   defenses = model.params_array[idx['defense']]

   # Get model-specific parameters
   hfa = model.params_array[idx['home_advantage']]
   rho = model.params_array[idx['rho']]  # DixonColes only

   # Print all available indices
   print(idx)
   # Output: {'attack': slice(0, 20), 'defense': slice(20, 40), 'home_advantage': -2, 'rho': -1}

Use Cases
----------

These tools are particularly useful for:

- **External adjustments**: Apply custom factors to parameters (e.g., scaling attack strengths)
- **Model comparison**: Extract parameters from multiple models for statistical analysis
- **Integration**: Pass parameter arrays to external optimization or simulation tools
- **Diagnostics**: Analyze parameter distributions across teams

Example: Scaling Attack Parameters
--------------------------------

.. code-block:: python

   model.fit()
   idx = model.param_indices()

   # Scale all attack strengths by 10%
   p = model.params_array.copy()
   p[idx['attack']] *= 1.1

   # Use the scaled parameters in your own calculations
   print(f"Scaled attacks: {p[idx['attack']]}")

Saving and Loading Models
=========================

Use built-in persistence helpers to save a fitted model to disk and load it later without retraining

.. code-block:: python

   model.fit()
   model.save("models/eredivisie_dc.pkl")

.. code-block:: python

   from penaltyblog.models import DixonColesGoalModel  # or the relevant class

   loaded = DixonColesGoalModel.load("models/eredivisie_dc.pkl")
   prediction = loaded.predict("Ajax", "PSV")
   print(prediction.home_draw_away)

.. note::
   Models are serialised with ``pickle``. Ensure you import the same model class before loading.

Minimal End-to-end Example
==========================

.. code-block:: python

   import penaltyblog as pb

   # Prepare your training arrays (goals & teams) and optional weights
   gh, ga = train["goals_home"], train["goals_away"]
   th, ta = train["team_home"], train["team_away"]
   w = pb.models.dixon_coles_weights(train["date"], xi=0.001)  # optional

   # Choose a model (swap freely thanks to the shared API)
   model = pb.models.DixonColesGoalsModel(gh, ga, th, ta, weights=w)

   # Fit fast with gradients and optional custom optimiser options
   model.fit(
       use_gradient=True,
       minimizer_options={"maxiter": 3000, "gtol": 1e-8}
   )

   # Predict and access rich markets
   pred = model.predict("Ajax", "PSV")
   print(pred.home_draw_away)               # [P(Home), P(Draw), P(Away)]
   print(pred.totals(2.5))                  # (under, push, over)
   print(model.aic, model.loglikelihood)    # diagnostics

   # Save for later reuse
   model.save("models/eredivisie_dc.pkl")
```### Tutorial: docs/backtest/index.rst
```rstBacktest
==========================

Backtesting betting strategies is crucial to assess their effectiveness and reliability before risking real money.

By systematically evaluating a strategy against historical data, bettors can determine its historical profitability, consistency, and risk profile.

Backtesting helps identify potential pitfalls, such as overfitting or unrealistic assumptions, and provides insights into how a betting approach might perform in future markets.

Ultimately, this process ensures more informed decision-making and increases confidence in deploying betting strategies in real-world scenarios.

.. toctree::
   :maxdepth: 1
   :caption: Examples:

   backtest
```### Tutorial: docs/matchflow_recipes/index.rst
```rstMatchflow Examples
=============================================

This section shows real-world examples of using **MatchFlow** to explore and analyze StatsBomb event data.
Each recipe is a focused, end-to-end workflow: loading data, transforming it with `Flow`, and visualizing
or exporting the results.

You'll find patterns for:

- Filtering and transforming events
- Calculating per-player or per-team summaries
- Visualizing shots, passes, and duels
- Combining multiple matches
- Building datasets for machine learning or reporting

These notebooks are designed to be simple, to give you a quick feel for how MatchFlow works.

.. list-table:: Guide Index
   :widths: 25 75
   :header-rows: 1

   * - Section
     - Description
   * - :doc:`06_statsbomb_api`
     - Streaming data directly from the StatsBomb API
   * - :doc:`01_xg_by_player`
     - Grouping and aggregating stats
   * - :doc:`02_shot_accuracy_by_team`
     - Using custom aggregation functions
   * - :doc:`03_pass_map`
     - Accessing values in arrays
   * - :doc:`04_cumulative_xg_by_time`
     - Calculating grouped cumulative stats
   * - :doc:`05_touchmap`
     - Using a pipe to apply a custom function to the Flow


.. toctree::
   :hidden:

   06_statsbomb_api
   01_xg_by_player
   02_shot_accuracy_by_team
   03_pass_map
   04_cumulative_xg_by_time
   05_touchmap
```### Tutorial: docs/ratings/colley.rst
```rst==============
Colley Ratings
==============

.. raw:: html

   <a href="https://colab.research.google.com/drive/1gjQASy0Ge_I_qdsJaBDfGTiwRzXqCISW?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

The Colley rating system is a sophisticated mathematical approach to team ranking that was originally developed by Wesley Colley for college football.

The method uses linear algebra to solve a system of equations based on team performance, creating ratings that reflect relative strength while maintaining mathematical rigor and objectivity.
What sets Colley apart from other rating systems is its focus purely on wins, losses, and draws, completely ignoring score margins, which eliminates potential bias from "running up the score" or other strategic considerations.
The system works by constructing a matrix equation where each team's rating is determined by their win-loss record relative to their opponents' strength.

This creates a self-reinforcing system where beating strong teams boosts your rating more than beating weak teams, while the mathematical framework ensures the ratings converge to a stable, unique solution.
The elegance of the Colley method lies in its ability to produce meaningful rankings with relatively simple inputs, making it both computationally efficient and resistant to manipulation.

Basic Usage
----------------

.. code-block:: python

   import penaltyblog as pb

   # Load your match data
   fbd = pb.scrapers.FootballData("ENG Premier League", "2021-2022")
   df = fbd.get_fixtures()

Colley Ratings Including Tied Scorelines
------------------------------------------

By default, the Colley method treats draws as partial wins for both teams (0.5 each):

.. code-block:: python

   colley = pb.ratings.Colley(
       df["goals_home"],
       df["goals_away"],
       df["team_home"],
       df["team_away"]
   )
   ratings = colley.get_ratings()
   print(ratings.head(10))

Example output:

.. code-block:: text

            .. list-table:: Colley Ratings Example
               :header-rows: 1

               * - team
                 - rating
               * - Liverpool
                 - 1.904762
               * - Man City
                 - 1.892857
               * - Chelsea
                 - 1.791667
               * - Tottenham
                 - 1.708333
               * - Arsenal
                 - 1.672619
               * - Man United
                 - 1.654762
               * - Brighton
                 - 1.64881
               * - Crystal Palace
                 - 1.625
               * - West Ham
                 - 1.619048
               * - Leicester
                 - 1.607143

Colley Ratings Excluding Tied Scorelines
------------------------------------------

You can exclude draws from the calculation by setting ``include_draws=False``.
This focuses purely on decisive results:

.. code-block:: python

   colley = pb.ratings.Colley(
       df["goals_home"],
       df["goals_away"],
       df["team_home"],
       df["team_away"],
       include_draws=False,
   )
   ratings = colley.get_ratings()
   print(ratings.head(10))

Example output:

.. list-table:: Colley Ratings Example (Excluding Draws)
   :header-rows: 1

   * - team
     - rating
   * - Liverpool
     - 0.809524
   * - Man City
     - 0.809524
   * - Chelsea
     - 0.678571
   * - Tottenham
     - 0.630952
   * - Arsenal
     - 0.607143
   * - Man United
     - 0.547619
   * - West Ham
     - 0.52381
   * - Brighton
     - 0.511905
   * - Leicester
     - 0.5
   * - Crystal Palace
     - 0.488095

Key Features
-------------

- **Objective**: Uses only match results, not subjective assessments
- **Stable**: Mathematical foundation prevents extreme fluctuations
- **Flexible**: Can include or exclude drawn matches
- **Fast**: Efficient computation suitable for regular updates
- **Unbiased**: No home field advantage or margin of victory weighting

Interactive Example
--------------------

For a comprehensive, hands-on demonstration of the Colley rating system, try the interactive Colab notebook.
The notebook walks you through loading match data, calculating ratings, and visualizing the results.
You can modify the code, experiment with different parameters, and see how the ratings change in real-time.

.. raw:: html

   <a href="https://colab.research.google.com/drive/1gjQASy0Ge_I_qdsJaBDfGTiwRzXqCISW?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
```### Tutorial: docs/ratings/elo.rst
```rstElo Ratings
===========

.. raw:: html

   <a href="https://colab.research.google.com/drive/14KTWI_-_fzTZPUAcZghZxcNYb7ODSstW?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

The Elo rating system is a method for calculating the relative skill levels of players or teams in competitive games.
Originally developed by Arpad Elo for chess, it has since been adapted for many other sports and competitions.
In an Elo system, each player or team has a numerical rating that increases when they win matches and decreases when they lose, with the magnitude of change depending on the expected outcome of the match based on the rating difference between opponents.
Higher-rated teams are expected to win against lower-rated teams, so an upset victory results in larger rating changes than a predictable outcome.

.. code-block:: python

    import penaltyblog as pb

.. code-block:: python

    elo = pb.ratings.Elo()

New Teams Default to 1500 Elo
-----------------------------

.. code-block:: python

    elo.get_team_rating("Team A"), elo.get_team_rating("Team B")

.. code-block:: none

    (1500.0, 1500.0)

Predict Match Results
--------------------

.. code-block:: python

    elo.calculate_match_probabilities("Team A", "Team B")

.. code-block:: none

    {'home_win': np.float64(0.5060806246811322),
     'draw': np.float64(0.20932932618252026),
     'away_win': np.float64(0.28459004913634756)}

Update Ratings
--------------

.. code-block:: python

    elo.update_ratings("Team A", "Team B", 0)

Get New Ratings
---------------

.. code-block:: python

    elo.get_team_rating("Team A")

.. code-block:: none

    1507.1987000039423

Interactive Example
-------------------

For a comprehensive, hands-on demonstration of the Elo rating system, try the interactive Colab notebook.
The notebook walks you through loading match data, calculating ratings, and visualizing the results.
You can modify the code, experiment with different parameters, and see how the ratings change in real-time.

.. raw:: html

   <a href="https://colab.research.google.com/drive/14KTWI_-_fzTZPUAcZghZxcNYb7ODSstW?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br>
```### Tutorial: docs/ratings/index.rst
```rstRatings / Rankings
===================

Rating models such as Colley, Elo, Massey, and Pi Ratings are valuable tools for evaluating football teams because they provide objective, quantitative measures of team strength based on historical performance.

Unlike subjective evaluations, these models systematically incorporate match outcomes, scoring margins, and relative opponent strength, offering insights into team capabilities beyond simple league standings.

By quantifying team performance accurately, these rating systems can significantly enhance predictive modeling, inform strategic betting decisions, and identify undervalued or overvalued teams within betting markets or competition analyses.

.. toctree::
   :maxdepth: 1
   :caption: Examples:

   colley
   elo
   massey
   pi
```### Tutorial: docs/ratings/massey.rst
```rst==============
Massey Ratings
==============

.. raw:: html

   <a href="https://colab.research.google.com/drive/1d_WPJwQgrogeSI9oIO9fY8s18CPPZ8nL?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

Overview
--------

The Massey rating system is a linear algebraic approach to team ranking developed by Kenneth Massey that gained prominence in college sports, particularly as part of the NCAA's Bowl Championship Series (BCS) computer rankings.

Unlike systems that rely solely on win-loss records, the Massey method incorporates point differentials to create a more nuanced assessment of team strength.

The system works by setting up a system of linear equations where each team's rating is determined by their average point differential against opponents, weighted by the strength of those opponents.

This creates a mathematically elegant solution that rewards teams not just for winning, but for winning convincingly against strong competition. The Massey ratings are particularly valued for their ability to handle strength-of-schedule adjustments automatically ‚Äî beating a strong team by a small margin can be rated higher than blowing out a weak team, making it especially useful for ranking teams across different conferences or leagues with varying competitive levels.

Offensive and Defensive Ratings
------------------------------

A distinctive feature of the Massey rating system is its ability to decompose overall team strength into separate offensive and defensive components.

The offensive rating represents a team's ability to score points above average, while the defensive rating reflects their ability to prevent opponents from scoring. This decomposition is mathematically derived from the same linear system that produces the overall ratings, making it a natural byproduct rather than an ad-hoc addition.

These component ratings provide valuable insights into team composition, for example, identifying whether a team's success comes from a dominant offense, stifling defense, or balanced strength on both sides of the ball. This granular analysis is particularly useful for coaches, analysts, and bettors who want to understand stylistic matchups and predict how different team strengths and weaknesses might interact in head-to-head competition.


Basic Usage
----------------

.. code-block:: python

   import penaltyblog as pb

   # Load your match data
   fbd = pb.scrapers.FootballData("ENG Premier League", "2021-2022")
   df = fbd.get_fixtures()

Calculate Ratings
----------------

.. code-block:: python

    massey = pb.ratings.Massey(
        df["goals_home"],
        df["goals_away"],
        df["team_home"],
        df["team_away"]
    )

   ratings = massey.get_ratings()

   ratings.head(10)
   print(ratings.head(10))

Example output:

.. list-table:: Massey Ratings Example
    :header-rows: 1

    * - team
      - rating
      - offence
      - defence
    * - Liverpool
      - 1.125
      - 1.51133
      - -0.38633
    * - Arsenal
      - 0.875
      - 1.052997
      - -0.177997
    * - Man City
      - 0.7
      - 1.146053
      - -0.446053
    * - Chelsea
      - 0.525
      - 0.933553
      - -0.408553
    * - Newcastle
      - 0.525
      - 1.044664
      - -0.519664
    * - Bournemouth
      - 0.3
      - 0.779386
      - -0.479386
    * - Nott'm Forest
      - 0.3
      - 0.779386
      - -0.479386
    * - Brentford
      - 0.225
      - 1.005775
      - -0.780775
    * - Aston Villa
      - 0.175
      - 0.78633
      - -0.61133
    * - Brighton
      - 0.175
      - 1.008553
      - -0.833553

Offensive and Defensive Ratings
------------------------------

.. code-block:: python

    print("Offense Ratings:")
    display(ratings[["team", "offence"]].head(10))

    print("\nDefence Ratings:")
    display(ratings[["team", "defence"]].head(10))

.. list-table:: Massey Ratings Example - Offense
    :header-rows: 1

    * - team
      - offence
    * - Liverpool
      - 1.51133
    * - Arsenal
      - 1.052997
    * - Man City
      - 1.146053
    * - Chelsea
      - 0.933553
    * - Newcastle
      - 1.044664
    * - Bournemouth
      - 0.779386
    * - Nott'm Forest
      - 0.779386
    * - Brentford
      - 1.005775
    * - Aston Villa
      - 0.78633
    * - Brighton
      - 1.008553


.. list-table:: Massey Ratings Example - Defensive
    :header-rows: 1

    * - team
      - defence
    * - Liverpool
      - -0.38633
    * - Arsenal
      - -0.177997
    * - Man City
      - -0.446053
    * - Chelsea
      - -0.408553
    * - Newcastle
      - -0.519664
    * - Bournemouth
      - -0.479386
    * - Nott'm Forest
      - -0.479386
    * - Brentford
      - -0.780775
    * - Aston Villa
      - -0.61133
    * - Brighton
      - -0.833553

Key Features
--------------

- **Comprehensive**: Incorporates both wins/losses and point differentials for richer analysis
- **Decomposable**: Automatically generates separate offensive and defensive ratings alongside overall team strength
- **Strength-of-schedule aware**: Ratings adjust based on opponent quality, rewarding performance against strong competition
- **Mathematically rigorous**: Based on linear algebra with unique, stable solutions
- **Predictive**: Component ratings can forecast expected point spreads for future matchups
- **Margin-sensitive**: Distinguishes between narrow victories and blowouts, providing more nuanced rankings
- **Scalable**: Handles leagues of any size with automatic strength-of-schedule adjustments

Interactive Example
-------------------

For a comprehensive, hands-on demonstration of the Massey rating system, try the interactive Colab notebook.
The notebook walks you through loading match data, calculating ratings, and visualizing the results.
You can modify the code, experiment with different parameters, and see how the ratings change in real-time.

.. raw:: html

   <a href="https://colab.research.google.com/drive/1d_WPJwQgrogeSI9oIO9fY8s18CPPZ8nL?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
```### Tutorial: docs/ratings/pi.rst
```rstPi Ratings
==========

.. raw:: html

   <a href="https://colab.research.google.com/drive/12qEDCNYG-FFHOJ_kURe0cm80sScandyh?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

The Pi rating system is a dynamic football-specific rating method developed by Constantinou & Fenton that addresses the key limitations of traditional systems like Elo when applied to football.

Pi Ratings are built on three key principles:

- score margins matter (a 5-0 win should receive a greater rating boost than a 1-0 win)
- home and away ratings are separate (maintaining distinct ratings for home and away performances)
- recent performance is more important (incorporating a learning rate that ensures recent matches influence ratings more strongly than older results)

Unlike Elo ratings which only consider wins, losses, and draws without regard to margin of victory, Pi Ratings incorporate goal differences to provide a more nuanced assessment of team strength.

Each team begins with a rating of 0, representing the level of an average team, and the system is zero-centered, meaning when one team gains rating points, the other loses the same amount. This makes ratings truly relative and allows for meaningful comparisons across teams, with a rating of +1.0 indicating a team is one goal better than average.

The system has demonstrated superior predictive accuracy compared to Elo in football contexts while remaining computationally efficient and interpretable.

You can read more about the Pi rating system in my blog post: https://pena.lt/y/2025/04/14/pi-ratings-the-smarter-way-to-rank-football-teams/


.. code-block:: python

    import penaltyblog as pb

    pi = pb.ratings.PiRatingSystem()


New Teams Default to a Rating of Zero
-------------------------------------

.. code-block:: python

    pi.get_team_rating("Team A"), pi.get_team_rating("Team B")

.. code-block:: none

    (0.0, 0.0)

Predict Match Results
--------------------

.. code-block:: python

    pi.calculate_match_probabilities("Team A", "Team B")

.. code-block:: text

    {
        'home_win': np.float64(0.3085375387259869),
        'draw': np.float64(0.38292492254802624),
        'away_win': np.float64(0.3085375387259869)
    }

Update Ratings
--------------

.. code-block:: python

    goal_diff = 3  # Team A wins 3-0
    pi.update_ratings("Team A", "Team B", goal_diff)

Get New Ratings
---------------

.. code-block:: python

    pi.get_team_rating("Team A")

.. code-block:: none

    0.11538461538461539

Interactive Example
-------------------

For a comprehensive, hands-on demonstration of the Pi rating system, try the interactive Colab notebook.
The notebook walks you through loading match data, calculating ratings, and visualizing the results.
You can modify the code, experiment with different parameters, and see how the ratings change in real-time.

.. raw:: html

   <a href="https://colab.research.google.com/drive/12qEDCNYG-FFHOJ_kURe0cm80sScandyh?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br>
```### Tutorial: docs/scrapers/index.rst
```rstScrapers
==============

The scrapers provide a consistent interface for extracting football data from multiple online sources, including FBRef, Understat, football-data.co.uk, and Club Elo.

Each scraper returns data in a standardized DataFrame format, ensuring uniform column names and structures across all sources.

Additionally, they support optional team name normalization (e.g., converting "Man United" to "Manchester United"), making it easy to merge datasets from different providers.

This consistency allows seamless integration and analysis, enabling users to combine data effortlessly without worrying about formatting discrepancies.

You can get a list of available competitions for each data source by calling the scraper's `list_competitions()` function.

.. code:: python

   import penaltyblog as pb

   pb.scraper.Understat.list_competitions()


See the examples below for more details on how to use the individual scrapers.


.. toctree::
   :maxdepth: 1
   :caption: Examples:

   fbref
   clubelo
   footballdata
   understat
```### Tutorial: docs/roadmap/index.rst
```rstRoadmap
====================

This roadmap outlines planned features, ideas under exploration, and long-term goals for ``penaltyblog``.

It‚Äôs not a guarantee, but a guide - contributions, feedback, and suggestions are welcome!

üîú Planned
-------------------------

MatchFlow
""""""""""""

**Usability + Helper Expansion**

- ‚òê General speed optimisations + cythonization to make faster
- ‚òê More ``where_`` and ``get_`` helpers
- ‚òê ``Flow.describe()`` improvements
- ‚òê Docs: Writing custom helpers tutorial
- ‚òê Docs: More ``Flow`` recipes
- ‚òê Add plugin interface to make it easy to add in other data providers
- ‚òë Progress bars
- ‚òë Custom query DSL for natural quering - ``flow.query("player.name == 'Kevin de Bruyne'")``
- ‚òë Optimization of internal DAG plan

**Joins & I/O Enhancements**

- ‚òê Join-on-multiple-fields support
- ‚òê Benchmarks page in docs
- ‚òê Parallel loading of files

**Rolling & Windowed Aggregates**

- ‚òë ``.rolling(...)`` and ``.expanding(...)`` on grouped flows
- ‚òê Support for **rolling summary** fields like moving average xG

Plotting
""""""""

- ‚òë Publish penaltyblog **plotting** library
- ‚òë Native support for **plotting Flow pipelines**

Models
"""""""""

- ‚òê Bring the **Bayesian models** back to the party
- ‚òê Add new models based on **time-series approaches**
- ‚òê Pre-trained models, e.g. **xT**
- ‚òê Updated **player ratings** model

Scrapers
"""""""""

- ‚òê Give scraper module an overhaul to make it **more efficient and easier to use**
- ‚òê Add support for **new data sources** such as Sofa Score
- ‚òê Add automatic **throttling** to avoid overloading servers
- ‚òê Hook up scrapers to **MatchFlow**
- ‚òê Caching of scraped data sources

General
""""""""

- ‚òê Refresh / expand rest of documentation

--------

üß™ Under Exploration
---------------------

These are bigger ideas I'm researching - feedback welcome!

MatchFlow
""""""""""

- **FlowZ**: A custom binary format for fast I/O on nested JSON
- **Partitioning** of large datasets for faster processing
- Built-in **indexing or predicate pushdown**
- **Streaming joins** for large datasets
- A lightweight **visual data explorer** (maybe based on my upcoming plotting library)
- Declarative **YAML/JSON** pipeline definitions.
- **Pluggable transforms** (e.g. xT, formation_detection, pressing_zones)

Models
""""""""""

- Custom **Bayesian** library focussed on building sports models without depenency hassles

--------

Contributing
------------

If you're interested in helping with anything here, feel free to open an issue, submit a PR, or just reach out.
```### Tutorial: docs/changelog/index.rst
```rstChangelog
===========

Version Numbering
###################

``penaltyblog`` follows the SemVer versioning guidelines. For more information,
see `semver.org <http://semver.org/>`_

v1.8.0 (2026-01-08)
^^^^^^^^^^^^^^^^^^^^

* **Goal Models**

  * Added new ``BayesianGoalModel`` and ``HierarchicalBayesianGoalModel`` models
  * Added Cythonized MCMC sampler for Bayesian Modelling

* **Scraping**

  * Fixed Understat scraper to use new API endpoints (getLeagueData, getMatchData, getPlayerData) instead of parsing embedded JavaScript from HTML pages
  * Fixed FBRef scraper by using wrapper-tls-requests to bypass Cloudflare TLS fingerprinting protection



v1.7.1 (2025-12-24)
^^^^^^^^^^^^^^^^^^^^

* **Goal Models**

  * Added add public `params_array` and `param_indices` functions to all goal models. This makes it easier to work with a model's parameters without having to rely on its internal implementation details. Thank you to Sebastian Velandia for this contribution.


v1.7.0 (2025-11-30)
^^^^^^^^^^^^^^^^^^^^

* **Opta API Integration** (``penaltyblog.matchflow.contrib.opta``):

  * Added built-in integration with Stats Perform (Opta) API, allowing for lazy loading of data streams (data is fetched only on ``.collect()`` or ``.to_pandas()``).
  * Added support for major endpoints including ``events``, ``matches``, ``season_stats``, ``referees``, ``standings``, and ``pass_matrix``.
  * Added ``opta_helpers`` module for human-readable filtering (e.g., ``where_opta_event("Shot")``) to avoid manual ID lookups.
  * Added ``get_opta_mappings()`` to explore available event types and qualifiers[cite: 23].
  * Added support for authenticated access via environment variables or credential dictionaries, including proxy configuration support.
  * Added documentation and examples for using the Opta API integration.

v1.6.2 (2025-10-22)
^^^^^^^^^^^^^^^^^^^^

Package Updates
---------------

- Fixed bug in ``PoissonGoalsModel`` where weights parameter was not being handled correctly in the gradient function.

v1.6.1 (2025-10-17)
^^^^^^^^^^^^^^^^^^^^

Package Updates
---------------

- Updated goals models loss functions to work with ``scipy 1.16+``
- Improved numerical stability of the loss function for the Negative Binomial model to improve convergence
- Added colab notebook for implied probabilities examples
- Python 3.14 support

v1.6.0 (2025-09-23)
^^^^^^^^^^^^^^^^^^^^

Package Updates
---------------

- ``Matchflow``

- can now read / write data from cloud storage (e.g. S3, GCS, Azure Blob Storage) using ``fsspec``
- Now supports multiple join strategies:

  - left, right, outer, inner and anti joins
  - Automatic type inference and conversion for join keys
  - Customizable type coercion functions for complex join key scenarios

- Fixed bug where where executor did not recognise ``.concat()`` function

- Updated ``implied`` submodule to add logarithmic overround removal method and return structured results

- ``Betting``

  - Renamed ``kelly`` submodule to ``betting``
  - Added ``multiple_criterion`` function for calculating Kelly Criterion for multiple outcomes
  - Added ``arbitrage_hedge`` function to calculate hedge bet sizes
  - Added ``arbitrage_opportunities`` function to identify arbitrage opportunities across bookmakers
  - Added ``value_bets`` function to identify value bets based on model probabilities
  - Added ``odds_conversion`` function to convert between different odds formats (decimal, fractional, American)
  - Updated all betting utility functions to return structured output

Documentation Improvements
----------------------------

- Updated ``Matchflow`` documentation
- Updated ``implied`` documentation
- Updated ``betting`` documentation
- Started adding Colab notebooks for interactive examples, more to come!

v1.5.1 (2025-08-20)
^^^^^^^^^^^^^^^^^^^^

Package Updates
---------------

- Restricted ``scipy`` to version ``<=1.15.3`` due to breaking changes in the ``minimize`` function introduced in ``1.16+``, which affect model compatibility.

v1.5.0 (2025-08-15)
^^^^^^^^^^^^^^^^^^^^

Package Updates
---------------

- ``Pitch``

  - Initial release of interactive ``Pitch`` plotting library

- ``MatchFlow``

  - ``Flow`` now has it's own query language, with support for boolean expressions and field comparisons via ``.query``

- ``Goals Models``

  - All Goals Model's ``.fit`` functions now take an optional dictionary of arguments to pass to scipy's optimiser
  - All GoalsModels now fit using an optional gradient (defaults to True), which improves the fit time by approx 5-10x

- ``FootballProbabilityGrid``

  - Updated class to include more betting markets
  - Now supports fractional Asian handicaps and totals
  - Optionally normalizes probabilities to sum to 1 (default: True)
  - Calculations now use vectorized numpy operations for improved performance
  - Caching of results for repeated queries to improve efficiency

- ``Goal Expectancy``

  - Added support for removing overrounding from input probabilities
  - Improved handling of edge cases in probability distributions
  - Altered to using probabilities rather than odds
  - Added more diagnostic output for debugging
  - Optionally normalizes probabilities to sum to 1

Documentation Improvements
----------------------------

- Added Pitch documentation
- Updated Flow documentation with ``.query`` examples
- Completely rewritten documentation for Goals Models and goal expectancy
- Removed obsolete examples

v1.4.1 (2025-06-24)
^^^^^^^^^^^^^^^^^^^^

Package Updates
---------------

- Fixed bug in `Flow.cache` executor logic


v1.4.0 (2025-06-19)
^^^^^^^^^^^^^^^^^^^^

Package Updates
---------------

- Introduced optional ``FlowOptimizer`` for smart plan rewrites
  - New ``optimize=True`` flag on all flows (off by default)
  - Safe, conservative rewrites: pushdown, fusion, and simplification
  - Enhanced ``.explain(compare=True)`` for before/after plan introspection
  - Optimizer is backwards-compatible and fully opt-in
- Added ``.plot_plan()`` on ``Flow`` and ``FlowGroup`` to visualize pipeline structure
- ``.explain()`` now works on ``FlowGroup``, and supports ``compare=True``
- New ``.with_schema({...})`` method to cast and validate fields
  - Example: ``Flow.with_schema({"x": int, "ts": parse_datetime})``
- Added ``.rolling_summary()`` to ``FlowGroup`` for windowed group summaries
  (e.g. rolling 5-minute aggregates per player or team)
- Added ``.time_bucket()`` to ``FlowGroup`` for time-based binning summaries
- Added ``.show()`` method to pretty-print results using tabulate
- ``Flow.collect()`` now supports optional progress bars during execution

Documentation Improvements
--------------------------

- Refreshed documentation to include:
  - ``FlowOptimizer`` and ``.optimize=True``
  - ``.with_schema``, ``.rolling_summary``, ``.show()``
  - Plan introspection via ``.explain(compare=True)`` and ``.plot_plan()``
  - Enhanced type hints throughout the package for improved compatibility with `mypy`.

v1.3.0 (2025-05-20)
^^^^^^^^^^^^^^^^^^^^

Package Updates
-----------------

- Initial release of MatchFlow

Documentation Improvements
----------------------------

- Added MatchFlow documentation
- Added MatchFlow recipes documentation
- Added API references for all of ``penaltyblog``
- Added stub file for metric Cython code
- Added stub file for model Cython code


v1.2.0 (2025-04-10)
^^^^^^^^^^^^^^^^^^^^

Package Updates
-----------------

- Updated Elo Ratings model to be more football-specific so that it now includes home field advantage and can predict draw probabilities
- Added new Cythonised Ignorance Score metric
- Added new Cythonised Multiclass Briar Score metric
- RPS functions now raise a ValueError exception if outcome is out of bounds

Documentation Improvements
----------------------------

- Updated Elo documentation
- Added Pi Ratings documentation
- Added examples for ignorance score
- Added examples for multiclass briar score
- Updated examples for RPS

---

v1.1.0 (2025-03-15)
^^^^^^^^^^^^^^^^^^^^

Performance Enhancements
------------------------

- Rewrote Dixon-Coles model using Cython, achieving approximately 250x speed improvement.
- Rewrote Poisson model using Cython, achieving approximately 250x speed improvement.
- Implemented Negative Binomial Goals Model in Cython for enhanced performance.
- Added high-performance Cython implementation of the Bivariate Poisson Goals Model based on Karlis & Ntzoufras.
- Introduced Cython implementation of the Bivariate Weibull Count Copula Goals Model (`Boshnakov et al. paper <https://blogs.salford.ac.uk/business-school/wp-content/uploads/sites/7/2016/09/paper.pdf>`_).
- Added Pi Ratings System (`Constantinou paper <http://www.constantinou.info/downloads/papers/pi-ratings.pdf>`_).
- Migrated ranked probability score functions to Cython for improved speed.

Package Updates
---------------

- Temporarily removed Stan-based models due to dependency management challenges. Investigating improved packaging strategies for future reintegration.
- Temporarily removed Rue and Salvesen model pending revision to accurately reflect its intended methodology (previously implemented as a hybrid Dixon-Coles variant).

Documentation Improvements
--------------------------

- Updated and expanded model examples in the documentation.
- Enhanced type hints throughout the package for improved compatibility with `mypy`.
- Updated documentation to `pydata` Sphinx theme.

CI/CD and Testing
-----------------

- Expanded GitHub Actions workflows to perform unit tests across all supported Python versions.
- Extended GitHub Actions workflows to perform unit tests on Windows, macOS, and Linux.
- Configured GitHub Actions to automatically build wheels for all supported Python versions across Windows, macOS, and Linux.

---

v1.0.4 (2025-01-10)
^^^^^^^^^^^^^^^^^^^^

Package Updates
---------------

- Moved Stan code to separate files to prevent access denied issues on Windows.

---

v1.0.3 (2024-12-19)
^^^^^^^^^^^^^^^^^^^^

Bug Fixes
---------

- Fixed bug in how the Bayesian models indexed teams in the `predict` function.
- Goals models now only predict individual team names rather than iterables of team names, fixing compatibility issues between different sequence objects.

---

v1.0.2 (2024-12-18)
^^^^^^^^^^^^^^^^^^^^

Bug Fixes
---------

- Updated how the Bayesian models handle the Stan files to prevent access denied issues on Windows.

---

v1.0.1 (2024-12-13)
^^^^^^^^^^^^^^^^^^^^

Improvements
------------

- Updated `install_stan` to install the C++ toolchain on Windows if required.

---

v1.0.0 (2024-12-12)
^^^^^^^^^^^^^^^^^^^^

Performance Enhancements
------------------------

- Removed `pymc` as a dependency.
- Optimized `RPS` calculation.
- Optimized `ELO` code.
- Optimized `Kelly Criterion` code.
- Updated `FootballProbabilityGrid` to store its internal matrix as a NumPy array.

Model Updates
-------------

- Rewrote `BayesianHierarchicalGoalModel` in Stan instead of `pymc`, updating the prediction method to integrate over the posterior rather than sampling the mid-point.
- Rewrote `BayesianRandomInterceptGoalModel` in Stan, improved the random intercept, and updated the prediction method.
- Rewrote `BayesianBivariateGoalModel` in Stan for better convergence and updated the prediction method.
- Added `BayesianSkellamGoalModel` for predicting football match outcomes using the Skellam distribution.

Package Updates
---------------

- Added support for Python 3.13.
- Removed obsolete **SoFifa** and **ESPN** scrapers.
- Updated all example notebooks.
- Increased unit test coverage.
- Added CI/CD workflows.
- Removed `Poetry` from the build step.
- Updated documentation.
- Added type hinting to `Colley` and `Massey` classes.

---

v0.8.1 (2023-09-31)
^^^^^^^^^^^^^^^^^^^^

Bug Fixes
---------

- Changed FBRef `born` column to `Int64` dtype to allow `NULL` values.

---

v0.8.0 (2023-08-31)
^^^^^^^^^^^^^^^^^^^^

New Features
------------

- Added initial **Backtest framework** for backtesting betting strategies.
- Added function to calculate the **Kelly Criterion**.
- Added class for calculating **Elo ratings**.

Bug Fixes
---------

- Fixed bug in FBRef scraper for player age and year of birth.
- All goal models can now accept iterables as team inputs.
- Fixed mapping of Belgium leagues in the **FootballData** scraper.

---

v0.7.0 (2023-03-13)
^^^^^^^^^^^^^^^^^^^^

New Features
------------

- Added **FBRef scraper**.

Package Updates
---------------

- Minimum Python version supported is now **Python 3.8**.

---

v0.6.1 (2023-01-06)
^^^^^^^^^^^^^^^^^^^^

Bug Fixes
---------

- Tweaked **Understat scraper** to avoid bot detection.

---

v0.6.0 (2022-12-02)
^^^^^^^^^^^^^^^^^^^^

New Features
------------

- Added `goal_expectancy` function.
- Added **Bayesian Random Intercept Model**.

Performance Enhancements
------------------------

- Tweaked `pymc` settings for Bayesian goal models to improve speed.

Bug Fixes
---------

- Fixed bug in **Bayesian Bivariate Goals Model**.
- Fixed bug in **FootballData scraper** where a null value was breaking the index column.

---

v0.5.1 (2022-11-03)
^^^^^^^^^^^^^^^^^^^^

Bug Fixes
---------

- Fixed bug in goal models when printing an instance before fitting it.
- Fixed bug in Bayesian goal models' weighted decay.
- Fixed default value of `xi` in `dixon_coles_weights` to `0.0018`.

---

v0.5.0 (2022-10-11)
^^^^^^^^^^^^^^^^^^^^

New Features
------------

- Added `get_player_season` and `get_player_shots` to **Understat scraper**.
- Added **Bayesian Hierarchical Goal Model**.
- Added **Bayesian Bivariate Poisson Goal Model**.
- Added **Bayesian Random Intercept Poisson Goal Model**.

Bug Fixes
---------

- `get_fixtures` in **Understat scraper** now only returns completed fixtures (consistent with FootballData scraper).
- Fixed bug in **FootballData scraper** for older seasons missing the `Time` column.

Package Updates
---------------

- Added **SoFifa scraper**.
- Added compatibility for **Python 3.7**.

---

v0.4.0 (2022-08-08)
^^^^^^^^^^^^^^^^^^^^

General Improvements
--------------------

- General bug fixes.
- Reorganized internal package structure.
- Added unit tests.
- Added documentation and uploaded to **ReadTheDocs**.

New Features
------------

- Added **FPL scraper**.
- Added **FPL optimizer**.
- Added **ESPN scraper**.
- Added **Understat scraper**.
- Added **pre-commit checks** to repository.
- Added both-teams-to-score probability to football goals models.
- Refactored **FootballData scraper** for consistency with other scrapers.
- Refactored **Club Elo scraper** for consistency with other scrapers.

Performance Enhancements
------------------------

- Refactored **Colley ratings** and **Massey ratings** for consistency.
- Updated example notebooks and included them in documentation.
```### Tutorial: docs/install/index.rst
```rstInstallation
============

``penaltyblog`` can be easily installed from PyPI or built from source. The package is optimized using **Cython**, which requires a C compiler if building from source. However, pre-built wheels are available on PyPI for most modern Python versions and operating systems (Windows, macOS, Linux).

Installing from PyPI (recommended)
----------------------------------

To install the latest stable release:

.. code-block:: bash

    pip install penaltyblog

If you want to read / write data from cloud storage (e.g., AWS S3, Google Cloud Storage) using ``Matchflow``,
you may need to install additional dependencies:

.. code-block:: bash

    pip install penaltyblog[s3]      # For AWS S3 support
    pip install penaltyblog[gcs]     # For Google Cloud Storage support
    pip install penaltyblog[azure]   # For Azure Blob Storage support
    pip install penaltyblog[cloud]   # For all cloud storage support

Installing from Source
----------------------

To install from source, clone the repository and install dependencies:

.. code-block:: bash

    git clone https://github.com/martineastwood/penaltyblog.git
    cd penaltyblog
    pip install .

Ensure you have a suitable C compiler available (e.g., GCC, Clang, or MSVC) when building from source.
```### Tutorial: docs/betting/arbitrage_hedging.rst
```rst==================
Arbitrage Hedging
==================

Arbitrage hedging is the practice of placing bets on different outcomes of an event to manage risk from an existing bet. This can be used to either lock in a guaranteed profit or to minimize a potential loss, regardless of the final result.

The primary function, ``arbitrage_hedge``, uses a **linear programming optimizer** to find the ideal hedge stakes that maximize your worst-case (guaranteed) profit.

``arbitrage_hedge()``
=====================

This function calculates the required stake(s) for hedge bets to guarantee a specific profit or minimize your loss from one or more existing positions.

.. code-block:: python

   penaltyblog.betting.arbitrage_hedge(
       existing_stakes: List[float],
       existing_odds: List[float],
       hedge_odds: List[float],
       target_profit: Optional[float] = None,
       hedge_all: bool = True,
       allow_lay: bool = False,
       tolerance: float = 1e-10,
   ) -> ArbitrageHedgeResult

.. important::
   **Understanding "Guaranteed Profit"**

   The ``guaranteed_profit`` calculated by this function is your worst-case profit across all possible outcomes.

   In many real-world scenarios (e.g., with uneven existing bets), the profit you make will be *different* for each outcome. The function returns the *minimum amount* you are guaranteed to receive. For example, if a hedge results in potential profits of ``[+¬£105, -¬£2, -¬£50]``, the ``guaranteed_profit`` will be **-¬£50**.

   Equal profits across all outcomes are only possible in perfectly symmetric situations or when "laying" (betting against an outcome) is allowed.

Parameters
----------

- ``existing_stakes`` ``(List[float])``: A list of the amounts you have already staked on each outcome.
- ``existing_odds`` ``(List[float])``: The decimal odds for your existing bets.
- ``hedge_odds`` ``(List[float])``: The current decimal odds available for placing hedge bets.
- ``target_profit`` ``(float, optional)``: A specific profit you want to lock in. If provided, the function will calculate the stakes needed to achieve this exact profit, if possible. If ``None``, it will maximize the guaranteed profit.
- ``hedge_all`` ``(bool, default=True)``: If ``True``, the function hedges against all possible outcomes. If ``False``, it only hedges the specific outcomes where you have an existing stake.
- ``allow_lay`` ``(bool, default=False)``: If ``True``, allows the function to calculate negative ("lay") stakes. Standard bookmakers typically don't allow this, so the default is ``False``, which forces the function to redistribute these amounts across other bets.
- ``tolerance`` ``(float, default=1e-10)``: A small number for handling floating-point comparisons.

Returns
-------

The function returns an ``ArbitrageHedgeResult`` object, which contains detailed information about the calculated hedge.

Understanding the Result (``ArbitrageHedgeResult``)
===================================================

The function returns a rich data object with useful attributes for analysis and execution.

- ``practical_hedge_stakes`` ``(List[float])``: A list of the actual, non-negative bet amounts you should place on each outcome. This is the primary result you'll use.
- ``guaranteed_profit`` ``(float)``: The guaranteed minimum profit (or loss, if negative) you will receive after placing the hedge bets.
- ``raw_hedge_stakes`` ``(List[float])``: The theoretical stakes calculated by the optimizer. This may contain negative values, which represent a "lay" bet.
- ``total_hedge_needed`` ``(float)``: The total value of negative stakes that had to be redistributed to other outcomes because allow_lay was ``False``.
- ``lp_success`` ``(bool)``: ``True`` if the linear programming optimizer found a solution, ``False`` if the function had to use its fallback heuristic.
- ``lp_message`` ``(str | None)``: A message from the optimizer, usually present if it failed.
- ``existing_payouts`` ``(List[float])``: The potential payout for each of your original bets.
- ``total_existing_stakes`` ``(float)``: The total amount of your original stakes.

Usage Examples
==============

Example 1: Locking in a Guaranteed Profit (A "Good" Hedge)
-----------------------------------------------------------

This is the ideal scenario. You bet on an underdog, the odds move significantly in your favour, and you can now hedge to guarantee a profit no matter what.

Let's say you bet ¬£25 on an Away Win at high odds of 6.0. On match day, their odds have shortened to 3.0.

.. code-block:: python

   import penaltyblog as pb

   # Your existing bet: ¬£25 on an Away Win at 6.0
   # Format: [Home, Draw, Away]
   stakes = [0, 0, 25]
   old_odds = [1.5, 4.0, 6.0]

   # On match day, the odds have shifted significantly
   new_odds = [2.5, 3.5, 3.0]

   result = pb.betting.arbitrage.arbitrage_hedge(
       existing_stakes=stakes,
       existing_odds=old_odds,
       hedge_odds=new_odds,
   )

   print(f"Hedge bets to place: [Home: ¬£{result.raw_hedge_stakes[0]:.2f}, Draw: ¬£{result.raw_hedge_stakes[1]:.2f}, Away: ¬£{result.raw_hedge_stakes[2]:.2f}]")
   print(f"Guaranteed profit: ¬£{result.guaranteed_profit:.2f}")
   print(f"Optimizer success: {result.lp_success}")

.. code-block:: text

   Hedge bets to place: [Home: ¬£60.00, Draw: ¬£42.86, Away: ¬£0.00]
   Guaranteed profit: ¬£22.14
   Optimizer success: True

**Conclusion**: The function advises betting **¬£47.24** on the Home Win and **¬£33.75** on the Draw. This eliminates the risk and locks in a **guaranteed profit of ¬£21.87**.

Example 2: Assessing Risk (A "Bad" Hedge)
------------------------------------------

Sometimes, the function's value is in telling you **not** to hedge.

Let's use the example from before that resulted in a negative profit. You bet ¬£50 on a Home Win at 3.5, and the odds shorten to 2.8.

.. code-block:: python

   import penaltyblog as pb

   stakes = [50, 0, 0]
   old_odds = [3.5, 3.4, 2.9]
   new_odds = [2.8, 3.8, 3.1]

   result = pb.betting.arbitrage.arbitrage_hedge(
       existing_stakes=stakes,
       existing_odds=old_odds,
       hedge_odds=new_odds,
   )

   print(f"Guaranteed profit: ¬£{result.guaranteed_profit:.2f}")

.. code-block:: text

   Guaranteed profit: ¬£-50.90

**Conclusion**: The function correctly calculates that there is no combination of hedge bets at the new odds that can guarantee a profit. The best possible worst-case outcome is a loss of **¬£50.90**, which is no better than your original risk of losing ¬£50. The tool has successfully shown you that **hedging is not advisable here.**
```### Tutorial: docs/betting/arbitrage_opportunities.rst
```rst===============================
Identifying Arbitrage Opportunities
===============================

An arbitrage bet (or "arb") is a risk-free opportunity. It exists when you can bet on all outcomes of a single event across different bookmakers and guarantee a profit, because their odds are misaligned. These are rare but highly valuable.

The ``find_arbitrage_opportunities`` Function
=============================================

This function scans lists of odds from multiple bookmakers for the same event to find these risk-free opportunities.

.. code-block:: python

   penaltyblog.betting.find_arbitrage_opportunities(
       bookmaker_odds_list: List[List[float]],
       outcome_labels: List[str] = None
   ) -> ArbitrageResult

Parameters
----------

- ``bookmaker_odds_list``: A list of lists. Each inner list represents one bookmaker's odds for all outcomes of an event.
- ``outcome_labels``: Optional names for the outcomes (e.g., ["Home", "Away"]).

Returns (``ArbitrageResult``)
-----------------------------

- ``has_arbitrage`` (``bool``): ``True`` if a risk-free opportunity exists.
- ``guaranteed_return`` (``float``): The guaranteed profit as a percentage of your total stake.
- ``best_odds`` (``List[float]``): The best odds found for each outcome across all bookmakers.
- ``best_bookmakers`` (``List[int]``): The index of the bookmaker offering the best odds for each outcome.
- ``stake_percentages`` (``List[float]``): The percentage of your total stake to place on each outcome to guarantee the profit.

Usage Example
=============

.. code-block:: python

   import penaltyblog as pb

   # Odds for a soccer match (Home Win, Draw, Away Win) from three different bookmakers
   # Each inner list represents one bookmaker's odds for [Home, Draw, Away]
   odds_data = [
       [2.80, 3.50, 3.10],  # Bookmaker 1
       [3.10, 3.40, 2.90],  # Bookmaker 2
       [3.00, 3.20, 3.00],  # Bookmaker 3
   ]

   # Define the labels for the outcomes
   outcome_labels = ["Home Win", "Draw", "Away Win"]

   arb_result = pb.betting.find_arbitrage_opportunities(odds_data, outcome_labels)

   if arb_result.has_arbitrage:
       print("Arbitrage opportunity found!")
       print(f"Guaranteed Return on Investment: {arb_result.guaranteed_return:.2%}")
       print("-" * 20)

       # The function tells you exactly where to bet and how much to stake
       for i, label in enumerate(arb_result.outcome_labels):
           stake_pct = arb_result.stake_percentages[i]
           best_odd = arb_result.best_odds[i]
           # Adding 1 to the index to make it human-readable (Bookmaker 1, 2, 3)
           bookie_idx = arb_result.best_bookmakers[i] + 1

           print(f"Bet {stake_pct:.2%} on {label} at odds {best_odd} with Bookmaker {bookie_idx}")
   else:
       print("No arbitrage opportunity found.")

.. code-block:: text

   Arbitrage opportunity found!
   Guaranteed Return on Investment: 7.43%
   --------------------
   Bet 34.65% on Home Win at odds 3.1 with Bookmaker 2
   Bet 30.69% on Draw at odds 3.5 with Bookmaker 1
   Bet 34.65% on Away Win at odds 3.1 with Bookmaker 1

Simple Expected Value Calculation
=================================

If you don't need the full analysis from ``identify_value_bet`` and just want a quick Expected Value (EV) calculation, you can use this lightweight utility function.

.. code-block:: python

   penaltyblog.betting.calculate_bet_value(
       bookmaker_odds: float,
       estimated_probability: float
   ) -> float

.. code-block:: python

   import penaltyblog as pb

   # 60% chance at odds of 2.0
   ev = pb.betting.calculate_bet_value(2.0, 0.6)
   print(f"Expected Value (per ¬£1 staked): ¬£{ev:.2f}")

.. code-block:: text

   Expected Value (per ¬£1 staked): ¬£0.20
```### Tutorial: docs/betting/bet_size.rst
```rst===========
Bet Sizing
===========

This submodule provides powerful tools for calculating optimal bet sizes using the **Kelly Criterion**, a mathematical formula designed to maximize the long-term growth of a bankroll.

Single Bet Analysis (``kelly_criterion``)
==========================================

Use this function to perform a deep analysis of a single betting opportunity. It calculates the optimal stake and provides a wealth of metrics to help you understand the bet's risk and reward profile.

.. code-block:: python

   penaltyblog.betting.kelly_criterion(
       decimal_odds: Union[float, NDArray, List[float]],
       true_prob: Union[float, NDArray, List[float]],
       fraction: float = 1.0,
   ) -> KellyResult

Parameters
----------

- ``decimal_odds``: The decimal odds for the bet (e.g., 2.5). Can be a single number or a NumPy array for multiple independent bets.
- ``true_prob``: Your estimated "true" probability of the outcome (from 0 to 1).
- ``fraction`` (default=``1.0``): A fraction of the full Kelly stake to use. Common values are ``0.5`` for "Half Kelly" or ``0.25`` for "Quarter Kelly" to adopt a more conservative strategy.

Returns (``KellyResult`` Object)
--------------------------------

The function returns a ``KellyResult`` data object containing a complete analysis.

- ``stake`` (``float``): The recommended fraction of your bankroll to wager (e.g., 0.05 for 5%).
- ``expected_growth`` (``float``): The expected logarithmic growth rate of your bankroll if you place this bet. This is the metric that the Kelly Criterion optimizes.
- ``edge`` (``float``): Your mathematical edge on the bet. A positive edge means the bet has a positive expected value.
- ``is_favorable`` (``bool``): ``True`` if the bet has a positive edge.
- ``risk_metrics`` (``RiskMetrics``): A detailed object containing advanced risk and return metrics. See the **Understanding the Risk Metrics** section below for a full explanation.

Usage Example
-------------

.. code-block:: python

   import penaltyblog as pb

   # Analyze a single bet with a 55% chance of winning at odds of 2.1
   # We'll use a conservative Half Kelly approach (fraction=0.5)
   result = pb.betting.kelly_criterion(2.1, 0.55, fraction=0.5)

   print(f"Is the bet favorable? {result.is_favorable}")
   print(f"Recommended Stake: {result.stake:.2%} of bankroll")
   print(f"Expected Growth Rate: {result.expected_growth:.4%}")
   print("-" * 50)
   print("Advanced Risk Metrics:")
   if result.risk_metrics:
       print(f"  - Sharpe Ratio: {result.risk_metrics.sharpe_ratio:.2f}")
       print(f"  - Volatility of Wealth: {result.risk_metrics.wealth_volatility:.4f}")
       print(f"  - 95% Value at Risk: {result.risk_metrics.value_at_risk_95:.2%} of bankroll")

.. code-block:: text

   Is the bet favorable? True
   Recommended Stake: 7.05% of bankroll
   Expected Growth Rate: 0.8177%
   --------------------------------------------------
   Advanced Risk Metrics:
     - Sharpe Ratio: 0.11
     - Volatility of Wealth: 0.0736
     - 95% Value at Risk: 7.05% of bankroll

Portfolio Betting (``multiple_kelly_criterion``)
================================================

This is a powerful function for calculating optimal stakes when you have the opportunity to bet on multiple, mutually exclusive outcomes at the same time (e.g., Home, Draw, and Away in a football match).

Instead of just calculating Kelly for each bet independently, this function uses an optimizer to treat them as a portfolio, finding the allocation that maximizes the overall growth rate of your bankroll.

.. code-block:: python

   penaltyblog.betting.multiple_kelly_criterion(
       decimal_odds: Union[List[float], NDArray],
       true_probs: Union[List[float], NDArray],
       fraction: float = 1.0,
       max_total_stake: float = 1.0,
       method: Literal["simultaneous", "independent"] = "simultaneous",
   ) -> MultipleKellyResult

Parameters
----------

- ``decimal_odds`` (``List[float]``): A list of decimal odds for each outcome.
- ``true_probs`` (``List[float]``): A list of your estimated probabilities for each outcome. The sum must be <= 1.0.
- ``fraction`` (default=``1.0``): A fraction of the optimal Kelly stakes to apply.
- ``max_total_stake`` (default=``1.0``): The maximum total fraction of your bankroll you are willing to stake across all bets combined.
- ``method`` (default=``"simultaneous"``):
    - ``simultaneous``: (Recommended) Uses a numerical optimizer to find the best possible allocation across all bets to maximize portfolio growth.
    - ``independent``: Calculates the Kelly stake for each bet individually and then scales them down if they exceed ``max_total_stake``. Less optimal but faster.

Returns (``MultipleKellyResult`` Object)
----------------------------------------

- ``stakes`` (``List[float]``): The list of recommended stakes for each outcome.
- ``total_stake`` (``float``): The total fraction of your bankroll to be staked.
- ``expected_growth`` (``float``): The expected logarithmic growth rate for the entire portfolio.
- ``risk_metrics`` (``RiskMetrics``): A detailed risk analysis for the entire portfolio.
- ``optimization_success`` (``bool``): ``True`` if the "simultaneous" optimizer found a valid solution.

Usage Example
-------------

.. code-block:: python

   import penaltyblog as pb

   # A 1X2 football market where we have a very strong edge on the Home team
   odds = [2.5, 3.2, 2.8]

   # Our probabilities show a much higher chance for a Home win (55%)
   # than the odds imply (1 / 2.5 = 40%).
   probs = [0.55, 0.25, 0.20]

   result = pb.betting.kelly.multiple_kelly_criterion(odds, probs)

   print("Optimal Portfolio Stakes:")
   print(f"- Home Win (at {odds[0]}): {result.stakes[0]:.2%} of bankroll")
   print(f"- Draw (at {odds[1]}): {result.stakes[1]:.2%} of bankroll")
   print(f"- Away Win (at {odds[2]}): {result.stakes[2]:.2%} of bankroll")
   print("-" * 20)
   print(f"Total Stake: {result.total_stake:.2%}")
   print(f"Portfolio Expected Growth: {result.expected_growth:.4%}")
   print(f"Portfolio Sharpe Ratio: {result.risk_metrics.sharpe_ratio:.2f}")

.. code-block:: text

   Optimal Portfolio Stakes:
   - Home Win (at 2.5): 27.17% of bankroll
   - Draw (at 3.2): 3.26% of bankroll
   - Away Win (at 2.8): 0.00% of bankroll
   --------------------
   Total Stake: 30.43%
   Portfolio Expected Growth: 4.6783%
   Portfolio Sharpe Ratio: 0.15

Understanding the Risk Metrics
==============================

Both functions return a ``RiskMetrics`` object that gives you a deep insight into the risk/reward profile of your strategy.

- ``expected_return``: Your expected profit as a percentage of your total stake. A 10% expected return means you expect to make ¬£0.10 for every ¬£1 staked.
- ``kelly_growth_rate``: The expected long-term growth rate of your bankroll, expressed as a percentage. This is the core metric Kelly optimizes. A higher number is better.
- ``wealth_volatility``: The standard deviation of your final bankroll. This measures how much your bankroll is expected to swing up and down. A lower number indicates a less risky strategy.
- ``sharpe_ratio``: A measure of risk-adjusted return (growth rate divided by its volatility). It helps you compare strategies with different risk levels. A higher Sharpe Ratio is better.
- ``probability_of_ruin``: The chance of losing your entire staked capital in this specific round of betting.
- ``value_at_risk_95``: The maximum you can expect to lose 95% of the time, expressed as a percentage of your bankroll.
```### Tutorial: docs/betting/index.rst
```rstBetting Utilities
==========================

This submodule provides a collection of tools for bet sizing and portfolio management.
It includes functions for calculating arbitrage hedges to lock in profit and for determining
optimal bet sizes using the Kelly Criterion.

.. toctree::
   :maxdepth: 1
   :caption: Examples:

   arbitrage_hedging
   arbitrage_opportunities
   bet_size
   value_bets
   odds_conversion
```### Tutorial: docs/betting/odds_conversion.rst
```rst========================
Odds Conversion Utilities
========================

This submodule provides a simple and reliable way to convert betting odds from different common formats into a standardized Decimal format.

Since most analytical functions in penaltyblog expect odds to be in decimal format, this utility is a crucial first step for working with data from various sources.

Supported Odds Formats
======================

The converter understands the three most common odds formats used worldwide.

- **Decimal Odds (e.g., ``2.50``, ``1.80``)**: Represents the total amount returned for a 1-unit stake, including the original stake. A stake of ¬£10 at 2.50 odds returns ¬£25 (¬£15 profit + ¬£10 stake). This is typically the standard format in Europe, Australia, and Canada.
- **American (Moneyline) Odds (e.g., ``+150``, ``-200``)**: A positive number shows how much profit you win for a 100-unit stake (e.g., ``+150`` means you win ¬£150 profit for a ¬£100 stake). A negative number shows how much you must stake to win 100 units of profit (e.g., ``-200`` means you must stake ¬£200 to win ¬£100 profit).
- **Fractional Odds (e.g., ``"5/2"``, ``"2/1"``)**: Shows the profit relative to the stake. The first number is the profit, the second is the stake. For example, ``5/2`` (read "five to two") means you win ¬£5 profit for every ¬£2 you stake. This format is common in the UK and Ireland.

The ``convert_odds`` Function
=============================

This is the primary, easy-to-use function for all conversions. It takes a list of odds in a specified format and returns them as a list of decimal odds.

.. code-block:: python

   penaltyblog.betting.convert_odds(
       odds: List[Union[float, str]],
       odds_format: Union[str, OddsFormat],
       market_names: List[str] = None,
   ) -> List[float]

Parameters
----------

- **odds** (``List[Union[float, str]]``): The list of odds you want to convert. This can be numbers for Decimal/American or strings for Fractional.
- **odds_format** (``str | OddsFormat``): The format of the odds you are providing. This can be a string (e.g., ``"american"``, ``"fractional"``) or an ``OddsFormat`` enum member.
- **market_names** (``List[str], optional``): Optional names for each market outcome; this parameter is included for API consistency but is not used in the conversion calculation.

Returns
-------

``List[float]``: A new list containing the odds converted to the **Decimal** format.

Usage Examples
==============

Converting American Odds to Decimal
------------------------------------

.. code-block:: python

   import penaltyblog as pb

   american_odds = [+170, +130, -110]

   decimal_odds = pb.betting.convert_odds(american_odds, "american")

   print(f"American: {american_odds}")
   print(f"Decimal:  {decimal_odds}")

.. code-block:: text

   American: [170, 130, -110]
   Decimal:  [2.7, 2.3, 1.9090909090909092]

Converting Fractional Odds to Decimal
--------------------------------------

.. code-block:: python

   import penaltyblog as pb

   fractional_odds = ['7/4', '13/10', '7/2']

   decimal_odds = pb.betting.convert_odds(fractional_odds, "fractional")

   print(f"Fractional: {fractional_odds}")
   print(f"Decimal:    {decimal_odds}")

.. code-block:: text

   Fractional: ['7/4', '13/10', '7/2']
   Decimal:    [2.75, 2.3, 4.5]
```### Tutorial: docs/betting/value_bets.rst
```rst=====================
Identifying Value Bets
=====================

A "value bet" is the cornerstone of any successful betting strategy. It's a bet where you believe the true probability of an outcome is higher than the probability implied by the bookmaker's odds. Placing value bets consistently is the key to long-term profitability.

The ``identify_value_bet`` Function
===================================

This is the core function for value analysis. It takes bookmaker odds and your own estimated probabilities, and returns a comprehensive analysis of the betting opportunity, including expected value and a recommended Kelly stake.

.. code-block:: python

   penaltyblog.betting.identify_value_bet(
       bookmaker_odds: Union[float, List[float], NDArray],
       estimated_probability: Union[float, List[float], NDArray],
       kelly_fraction: float = 1.0,
       min_edge_threshold: float = 0.0,
   ) -> Union[ValueBetResult, MultipleValueBetResult]

Parameters
----------

- ``bookmaker_odds``: A single decimal odd, or a list/array of odds.
- ``estimated_probability``: Your estimated true probability (from 0 to 1) for the corresponding outcome(s).
- ``kelly_fraction`` (default=``1.0``): The fraction of the Kelly Criterion to recommend (e.g., 0.5 for a more conservative "Half Kelly" stake).
- ``min_edge_threshold`` (default=``0.0``): The minimum required "edge" (your probability minus the implied probability) for a bet to be flagged as a value bet.

Returns
-------

The function intelligently returns one of two detailed data objects:

- ``ValueBetResult``: If you provide a single odd and probability.
- ``MultipleValueBetResult``: If you provide a list of odds and probabilities.

Understanding the Results
=========================

For Single Bets (``ValueBetResult``)
------------------------------------

When analyzing a single bet, you get a detailed breakdown:

- ``is_value_bet`` (``bool``): True if the bet has a positive edge above your threshold.
- ``expected_value`` (``float``): The amount you expect to win or lose per unit staked. A positive EV indicates a profitable bet in the long run.
- ``edge`` (``float``): The difference between your probability and the bookmaker's implied probability.
- ``recommended_stake_kelly`` (``float``): The optimal fraction of your bankroll to stake, according to the full Kelly Criterion.
- ``recommended_stake_fraction`` (``float``): The Kelly stake, adjusted by the kelly_fraction you provided.

For Multiple Bets (``MultipleValueBetResult``)
----------------------------------------------

When analyzing a list of bets (e.g., a weekend's fixtures), you get a portfolio-level summary:

- ``individual_results`` (``List[ValueBetResult]``): A list containing a detailed ``ValueBetResult`` object for each bet you provided.
- ``total_value_bets`` (``int``): The number of bets in the list that were identified as having value.
- ``average_edge`` (``float``): The average edge across all identified value bets.
- ``kelly_stakes`` (``List[float]``): A list of the recommended (fractional) Kelly stakes for the entire portfolio of bets.

Usage Examples
==============

Single Bet Analysis
-------------------

.. code-block:: python

   import penaltyblog as pb

   # We think a team has a 50% chance to win, but the odds are 2.5
   result = pb.betting.identify_value_bet(2.5, 0.50)

   if result.is_value_bet:
       print("This is a value bet!")
       print(f"Edge: {result.edge:.2%}")
       print(f"Expected Value (per ¬£1 staked): ¬£{result.expected_value:.2f}")
       print(f"Recommended Full Kelly Stake: {result.recommended_stake_kelly:.2%} of bankroll")
   else:
       print("This is not a value bet.")

.. code-block:: text

   This is a value bet!
   Edge: 10.00%
   Expected Value (per ¬£1 staked): ¬£0.25
   Recommended Full Kelly Stake: 16.67% of bankroll

Multiple Bet Analysis
---------------------

.. code-block:: python

   import penaltyblog as pb

   # Analyzing three different bets from a weekend
   odds = [2.1, 3.5, 1.8]
   my_probs = [0.5, 0.25, 0.6] # Our estimated probabilities

   results = pb.betting.identify_value_bet(odds, my_probs)

   print(f"Found {results.total_value_bets} value bets out of {len(odds)}.")
   print(f"The average edge on these value bets is {results.average_edge:.2%}")

   # You can also inspect each individual result
   for bet_result in results.individual_results:
       if bet_result.is_value_bet:
           print(f"- Bet at odds {bet_result.bookmaker_odds} has an edge of {bet_result.edge:.2%}")

.. code-block:: text

   Found 2 value bets out of 3.
   The average edge on these value bets is 3.41%
   - Bet at odds 2.1 has an edge of 2.38%
   - Bet at odds 1.8 has an edge of 4.44%
```### Tutorial: docs/fpl/index.rst
```rstFantasy Premier League
==========================

Building a successful fantasy football team requires more than just picking top players ‚Äî it involves strategic optimization to maximize points while staying within budget constraints.

Advanced mathematical models can help identify undervalued players, predict future performance based on historical data, and optimize transfers to adapt to upcoming fixtures.

Techniques such as linear programming allow for data-driven decision-making, ensuring your squad is balanced and competitive.

Whether you're selecting the best captain, managing budget constraints, or planning for double gameweeks, an optimized approach can give you a crucial edge over the competition.

.. toctree::
   :maxdepth: 1
   :caption: Examples:

   fpl
```### Tutorial: docs/matchflow/advanced.rst
```rst==============================
Advanced Pipeline Operations
==============================

Beyond basic filtering and assignment, Flow provides advanced operations for manipulating, combining, and analyzing structured data at scale.

These tools help you:

- Sort by xG or timestamp
- Join datasets (e.g. match metadata + events)
- Eliminate duplicates
- Sample subsets for debugging
- Combine multiple flows

üîÉ Sorting and Ordering
=======================

``.sort_by()`` ‚Äì Sort Records
-----------------------------

Sort records by one or more fields:

.. code-block:: python

   from flow import Flow, where_equals
   from pprint import pprint

   sorted_events = Flow(events).sort_by("timestamp")

Sort shots by shot_xg, descending:

.. code-block:: python

   shots = (
       Flow(events)
       .filter(where_equals("type_name", "Shot"))
       .sort_by("shot_xg", ascending=False)
   )

   pprint(shots.head(1))

Sort by multiple fields:

.. code-block:: python

   Flow(events).sort_by(["team_name", "type_name"], ascending=False)

.. note::
   Sorting loads the full flow into memory.

üìè Limiting Results
===================

Use ``.limit(n)`` or ``.head(n)`` to take the first N records:

.. code-block:: python

   top_5 = Flow(events).limit(5)

üéØ Sampling
===========

``.sample_n()`` ‚Äì Random N Records
----------------------------------

.. code-block:: python

   sample = Flow(events).sample_n(3, seed=42)

``.sample_fraction(p)`` ‚Äì Fractional Sampling
---------------------------------------------

.. code-block:: python

   sample = Flow(events).sample_fraction(0.2, seed=1)  # 20% chance per row

ü§ù Joining Datasets
===================

You can combine two Flow objects based on common keys, similar to a SQL join, with the ``.join()`` function.

.. code-block:: python

   flow.join(
       other: "Flow",
       on: Union[str, List[str], None] = None,
       left_on: Union[str, List[str], None] = None,
       right_on: Union[str, List[str], None] = None,
       how: Literal["left", "right", "outer", "inner", "anti"] = "left",
       lsuffix: str = "",
       rsuffix: str = "_right",
       type_coercion: Literal["strict", "auto", "string"] = "strict",
   )

**Key join Parameters:**

- ``other``: The other ``Flow`` object to join with.
- ``on``, ``left_on``, ``right_on``: The key(s) to join on.
    - Use ``on="field_name"`` if the key has the same name in both flows.
    - Use ``left_on="left_field"`` and ``right_on="right_field"`` if the key names are different.
- ``how``: The type of join to perform.
    - ``left``: (Default) Keep all records from the left ``Flow``, and add matching data from the right.
    - ``inner``: Keep only records where the key exists in both flows.
    - ``outer``: Keep all records from both flows, filling in missing data with None.
    - ``right``: Keep all records from the right ``Flow``.
    - ``anti``: Keep only the records from the left ``Flow`` that do not have a match in the right ``Flow``.
- ``type_coercion``: How to handle join keys of different types (e.g., 123 vs "123"). Default is ``"strict"`` (must be the same type). Use ``"auto"`` for smart coercion.

.. code-block:: python

   events_records = [
       {"event_id": 1, "player_id": 101, "action": "Shot"},
       {"event_id": 2, "player_id": 102, "action": "Pass"},
   ]
   players_records = [
       {"id": 101, "name": "Bukayo Saka"},
       {"id": 102, "name": "Martin √òdegaard"},
   ]

   events_flow = pb.Flow.from_records(events_records)
   players_flow = pb.Flow.from_records(players_records)

   # Join the two flows to add the player's name to each event
   enriched_flow = events_flow.join(
       players_flow,
       left_on="player_id",
       right_on="id",
       how="left"
   )

‚ö†Ô∏è Notes on ``.join()``
-----------------------

- The right-hand Flow is fully materialized in memory.

‚ûï Combining Flows
==================

Use ``.concat()`` to merge multiple flows:

.. code-block:: python

   combined = flow1.concat(flow2, flow3)

üö´ Handling Duplicates
======================

``.distinct()`` ‚Äì Drop Duplicates
---------------------------------

Drop exact or partial duplicates:

.. code-block:: python

   unique_events = Flow(events).distinct()

   deduped = Flow(events).distinct("player_name", "type_name", keep="first")

Options for keep:

- "first" (default)
- "last"
- False ‚Üí removes all duplicates

üßæ Extracting Unique Field Values
=================================

``.distinct("field")`` for unique values
----------------------------------------

.. code-block:: python

   unique_players = Flow(events).distinct("player_name")

For combinations:

.. code-block:: python

   unique = Flow(events).distinct("team_name", "type_name")

.. note::
   Internally tracks key combinations so be careful on large datasets with high cardinality.

üß™ Example: Join Events with Match Info
=======================================

.. code-block:: python

   events = Flow(events)
   matches = Flow(matches)

   enriched = events.join(matches, on="match_id", how="left")
   pprint(enriched.head(1))

.. code-block:: python

   {
       'event_id': 1,
       'match_id': 123,
       'type_name': 'Pass',
       'player_name': 'Kevin De Bruyne',
       'team_name': 'Manchester City',
       'competition_name': 'Premier League',   # from match metadata
       'match_date': '2023-10-08'
   }

üß† Summary
==========

Flow's advanced operations let you:

- Sort and rank streams
- Sample intelligently
- Merge datasets using joins
- Deduplicate messy input
- Combine multiple sources

These tools are built for working with real-world, irregular JSON records - not just clean flat tables.

üì• Next: Saving and Exporting Data
==================================

In the next guide, we'll look at writing flows to disk using ``.to_jsonl()``, ``.to_json()``, and ``.to_pandas()`` for final output or reporting.
```### Tutorial: docs/matchflow/basic_pipeline.rst
```rst=======================================
Basic Pipelines: Transforming Your Data
=======================================

Once you've loaded your data into a ``Flow``, the next step is usually to clean, reshape, and enrich it.

Flow provides familiar methods like ``.filter()``, ``.assign()``, ``.select()``, and ``.explode()``, designed to work **lazily** over nested JSON records - no flattening or DataFrame conversion required.

üì¶ Example Records
==================

.. code-block:: python

   from penaltyblog.matchflow import Flow

   sample_records = [
       {
           "event_id": 1,
           "match_id": 123,
           "period": 1,
           "timestamp": "00:01:30.500",
           "type_name": "Pass",
           "player_name": "Kevin De Bruyne",
           "location": [60.1, 40.3],
           "pass_recipient_name": "Erling Haaland",
           "pass_outcome_name": "Complete",
       },
       {
           "event_id": 2,
           "type_name": "Shot",
           "player_name": "Erling Haaland",
           "location": [85.5, 50.2],
           "shot_xg": 0.05,
           "shot_outcome_name": "Goal",
       },
       # More records...
   ]

   flow = Flow.from_records(sample_records)

üéØ Selecting Fields with ``.select()``
=======================================

.. code-block:: python

   player_locations = flow.select("player_name", "location").head(1)
   print(player_locations)

.. code-block:: python

   [{'player_name': 'Kevin De Bruyne', 'location': [60.1, 40.3]}]

üß† Accessing Nested Fields
===========================

.. code-block:: python

   example = [{"a": {"b": {"c": 1}}}]
   flow = Flow.from_records(example).select("a.b.c")
   print(flow.head(1))

.. code-block:: python

   [{'a': {'b': {'c': 1}}}]

üßπ Handling Dotted Keys
=======================

Option 1 ‚Äî Flatten the record
-----------------------------

If your keys contain dots (e.g. "player.info.name.full"), you can:

.. code-block:: python

   flow.flatten().select("player.info.name.full")

Option 2 ‚Äî Rename and assign
----------------------------

.. code-block:: python

   flow.rename(**{"player.info": "player_info"})
       .assign(name_full=lambda r: r["player_info"].get("name.full"))
       .select("name_full")

üîç Filtering Records
====================

Basic filter using a lambda
----------------------------

.. code-block:: python

   shots = flow.filter(lambda r: r.get("type_name") == "Shot")
   print(shots.select("player_name", "shot_outcome_name").collect())

Using predicate helpers
-----------------------

.. code-block:: python

   from penaltyblog.matchflow import where_equals

   goals = flow.filter(
       where_equals("type_name", "Shot"),
       where_equals("shot_outcome_name", "Goal"),
       where_equals("player_name", "Erling Haaland")
   )
   print(goals.select("player_name", "shot_xg").collect())

‚úçÔ∏è Assigning Fields with ``.assign()``
=======================================

.. code-block:: python

   half_flow = flow.assign(
       half=lambda r: "First" if r.get("period") == 1 else "Second"
   )
   print(half_flow.select("player_name", "half").head(1))

You can also overwrite fields:

.. code-block:: python

   uppercase_flow = flow.assign(
       player_name=lambda r: r.get("player_name", "").upper()
   )

üîÄ Renaming Fields with ``.rename()``
=====================================

.. code-block:: python

   renamed = flow.rename(
       match_id="id",
       type_name="event_type"
   ).select("id", "event_type")

   print(renamed.head(1))

üéà Exploding Lists with ``.explode()``
======================================

.. code-block:: python

   example = [{
       "event_id": 30,
       "players": ["Player X", "Player Y"],
       "roles": ["Passer", "Receiver"]
   }]

   exploded = Flow.from_records(example).explode("players", "roles")
   pprint(exploded.collect())

.. code-block:: python

   [{'event_id': 30, 'players': 'Player X', 'roles': 'Passer'},
    {'event_id': 30, 'players': 'Player Y', 'roles': 'Receiver'}]

üéØ Splitting Arrays with ``.split_array()``
============================================

.. code-block:: python

   split = flow.split_array("location", into=["x", "y"]).select("x", "y").head(1)
   print(split)

.. code-block:: python

   [{'x': 60.1, 'y': 40.3}]

üßÆ Accessing Array Elements by Index
====================================

If a field is a list (like coordinates or player IDs), you can extract specific values using dot notation with a numeric index:

.. code-block:: python

   record = {"player": "Kevin De Bruyne", "location": [60.1, 40.3]}
   flow = Flow.from_records([record])

To get just the X or Y value from location:

.. code-block:: python

   flow.select("location.0", "location.1").collect()

.. code-block:: python

   [{'location': {'0': 60.1, '1': 40.3}}]

.. note::
   The numeric indexes are treated like nested keys internally, so "location.0" means "first element of location".

If you want those values as top-level fields, just rename them:

.. code-block:: python

   xy = (
       flow.select("location.0", "location.1")
           .rename(**{
               "location.0": "x",
               "location.1": "y"
           })
   )

   print(xy.collect())

.. code-block:: python

   [{'location': {}, 'x': 60.1, 'y': 40.3}]

‚úÖ Summary
==========

These methods form the building blocks of most Flow pipelines:

- ``.select()`` to pick fields
- ``.filter()`` to narrow your data
- ``.assign()`` to compute new columns
- ``.rename()`` to simplify field names
- ``.explode()`` to unpack lists
- ``.split_array()`` to handle coordinate fields

You chain these operations lazily and collect results only when you're ready.

.. code-block:: python

   flow = (
       Flow.from_records(sample_records)
       .filter(where_equals("type_name", "Shot"))
       .assign(xg_bin=lambda r: "High" if r.get("shot_xg", 0) > 0.1 else "Low")
       .select("player_name", "xg_bin")
       .show(3)
   )

üöÄ Next: Grouping and Summaries
===============================

In the next section, we'll cover ``.group_by()`` and ``.summary()`` to compute aggregates - like total xG per player or matc
```### Tutorial: docs/matchflow/best_practices.rst
```rst=============================================
Best Practices, Performance & Troubleshooting
=============================================

Flow is designed for **clarity**, **composability**, and **structured JSON pipelines**. But to use it effectively ‚Äî especially on large or semi-structured data ‚Äî you need to understand how Flow executes and when data is consumed.

üß† Think in DAGs, Not DataFrames
================================

Flow builds a **deferred plan** of steps (like a DAG). Nothing runs until you collect results:

.. code-block:: python

   flow = Flow.from_folder("data/").filter(...).assign(...).select(...)

At this point, **no data has been read**.

üö® When Execution Happens
=========================

Flow starts processing only when you:

- ``.collect()``
- ``.to_pandas()``
- ``.to_json()``, ``.to_jsonl()``
- Iterate over the Flow
- Call ``.first()``, ``.keys()``, ``len()``

‚ö†Ô∏è When Materialization Happens
===============================

Certain operations require the **full dataset** and will materialize in memory:

+---------------+-----------------------------+
| Operation     | Reason                      |
+===============+=============================+
| ``.group_by()`` | Groups must be fully built  |
+---------------+-----------------------------+
| ``.summary()``  | Aggregates need full access |
+---------------+-----------------------------+
| ``.sort_by()``  | Requires sorting all rows   |
+---------------+-----------------------------+
| ``.join()``     | Right side is pre-loaded    |
+---------------+-----------------------------+
| ``.pivot()``    | Reshapes after aggregation  |
+---------------+-----------------------------+
| ``.limit()``    | Buffers to truncate         |
+---------------+-----------------------------+
| ``.cache()``    | Explicit full collection    |
+---------------+-----------------------------+

You can always call ``.explain()`` to see where materialization occurs:

.. code-block:: python

   flow.explain()

üß™ Inspect Safely
==================

You can preview without consuming the full plan:

.. code-block:: python

   Flow.from_jsonl("match.jsonl").head(3)

``.head(n)`` adds a ``.limit()`` and returns the first ``n`` results via ``.collect()``. It's a safe way to preview data.

üîÅ Fork Pipelines Naturally
============================

.. code-block:: python

   f = Flow.from_jsonl("match.jsonl")

   attacks = f.filter(lambda r: r["team"] == "Arsenal")
   defence = f.filter(lambda r: r["team"] == "Manchester City")

Because the pipeline is just a plan, each branch is safe and isolated.

üß∞ Use ``.pipe()`` for Debugging or Custom Steps
================================================

You can insert custom logic mid-pipeline with ``.pipe()``:

.. code-block:: python

   def peek(flow):
       print(flow.head(3))
       return flow

   Flow.from_jsonl("match.jsonl").pipe(peek).filter(...)

üîÑ Pure Functions = Safer Pipelines
===================================

Since ``.map()`` and ``.assign()`` modify records, avoid side effects or mutating shared input.

Prefer using ``.from_records(copy.deepcopy(data))`` if you're passing mutable records from outside.

üí° Performance Tips
===================

- Prefer ``.from_jsonl()`` over ``.from_json()`` for large files
- Minimize ``.sort_by()`` or ``.group_by()`` until late in pipeline
- Use ``.filter()`` early to reduce data as soon as possible
- Avoid flattening too early. Use ``.select()`` to access nested fields instead

üß† Summary
==========

+---------------------------+------------------------------------------+
| Principle                 | Recommendation                           |
+===========================+==========================================+
| Inspection                | Use ``.head(n)`` to preview              |
+---------------------------+------------------------------------------+
| Debugging                 | Use ``.pipe()`` for custom hooks         |
+---------------------------+------------------------------------------+
| Materialization Awareness | Use ``.explain()`` to understand plan    |
+---------------------------+------------------------------------------+
| Filtering Early           | Always filter before heavy ops           |
+---------------------------+------------------------------------------+

Flow gives you a structured, schema-aware, and composable pipeline for working with JSON, especially valuable when you want to defer flattening and stay close to raw data.
```### Tutorial: docs/matchflow/file_io.rst
```rst==================================
Working with Files: Input & Output
==================================

Flow makes it easy to **load, stream, and save structured JSON data** from a variety of sources. Whether you're pulling from disk, an API, or a folder of ``.jsonl`` files ‚Äî Flow provides a consistent, lazy interface for building pipelines.

üì• Loading Data into Flow
=========================

Use ``Flow.from_*`` methods to create a new Flow from Python objects or files.

üß† From Python Data: ``.from_records(...)``
-------------------------------------------

.. code-block:: python

   from penaltyblog.matchflow import Flow

   data = [{"id": 1, "value": "A"}, {"id": 2, "value": "B"}]
   flow = Flow.from_records(data)

Also works with single dicts or generators:

.. code-block:: python

   flow = Flow.from_records({"id": 3, "value": "C"})

   def gen():
       for i in range(3):
           yield {"id": i}

   flow = Flow.from_records(gen())

.. warning::
   If you mutate records (e.g. with ``.assign()``), Flow modifies them in place. Use ``.copy()`` or ``deepcopy()`` to protect your originals.

üìÑ From JSON Lines (JSONL) File: ``.from_jsonl(...)``
=====================================================

.. code-block:: python

   flow = Flow.from_jsonl("data/events.jsonl")

üìÇ From Folder of JSON Files: ``.from_folder(...)``
===================================================

.. code-block:: python

   flow = Flow.from_folder("data/events/")

Reads all ``.json`` and ``.jsonl`` files in a directory.

Each ``.json`` file must contain either:

- A single dict
- A list of dicts
- Files are streamed one at a time - efficient for bulk ingestion.

‚ú® From Glob Pattern: ``.from_glob(...)``
=========================================

.. code-block:: python

   flow = Flow.from_glob("data/**/*.json")

Searches recursively using ``glob.glob``. Same behavior as ``.from_folder``, but more flexible for matching paths and subfolders.

üßæ From JSON File (Single Object or Array): ``.from_json(...)``
===============================================================

.. code-block:: python

   flow = Flow.from_json("data/game.json")

- Accepts a single object (as one record), or
- A list of objects (as multiple records)

.. note::
   This reads the entire file into memory. Use ``.from_jsonl()`` for streaming large datasets.

Working with Cloud Storage (S3, GCS, Azure)
============================================

All file-based creation methods (``from_json``, ``from_jsonl``, ``from_folder``, ``from_glob``) can read directly from cloud storage by providing the appropriate URI and storage_options.

To do this, you'll need to install the necessary dependencies for your cloud provider:

- **Amazon S3**: pip install penaltyblog[aws]
- **Google Cloud Storage**: pip install penaltyblog[gcp]
- **Azure Data Lake / Blob Storage**: pip install penaltyblog[azure]

The ``storage_options`` parameter is an optional dictionary containing your credentials if you are not storing them as environment variables.

.. code-block:: python

   import penaltyblog as pb

   s3_options = {
       "key": "YOUR_AWS_ACCESS_KEY_ID",
       "secret": "YOUR_AWS_SECRET_ACCESS_KEY",
   }
   flow = pb.Flow.from_json("s3://my-bucket/data.json", storage_options=s3_options)

   gcs_options = {"token": "path/to/your/gcs_credentials.json"}
   flow = pb.Flow.from_jsonl("gs://my-gcs-bucket/data.jsonl", storage_options=gcs_options)

   azure_options = {
       "account_name": "YOUR_STORAGE_ACCOUNT_NAME",
       "account_key": "YOUR_STORAGE_ACCOUNT_KEY",
   }
   flow = pb.Flow.from_folder("abfs://container/data/", storage_options=azure_options)

üíæ Saving Data from a Flow
==========================

Once your pipeline is complete, use ``.to_*()`` methods to export the result.

``.to_jsonl(path)``
-------------------

Write one record per line:

.. code-block:: python

   flow.to_jsonl("output/events.jsonl")

``.to_json(path)``
------------------

Write all records as a JSON array:

.. code-block:: python

   flow.to_json("summary.json", indent=4)

.. note::
   This collects the entire stream before writing.

``.to_json_files(folder, by="id")``
-----------------------------------

Write each record to its own .json file:

.. code-block:: python

   flow.to_json_files("out/", by="event_id")

- "out/123.json"
- "out/456.json"

Field must be a string or something serializable to filename.

``.to_pandas()``
----------------

Convert the flow to a Pandas DataFrame:

.. code-block:: python

   df = flow.select("player_name", "shot_xg").to_pandas()

.. note::
   Best used after filtering/flattening to avoid deeply nested fields.

‚úÖ Summary
==========

Input Options
-------------

+------------------+-------------------------+------------+------------------------------+
| Source Format    | Method                  | Streaming? | Notes                        |
+==================+=========================+============+==============================+
| Python objects   | ``.from_records()``     | ‚úÖ         | Lists, dicts, or generators  |
+------------------+-------------------------+------------+------------------------------+
| JSONL file       | ``.from_jsonl()``       | ‚úÖ         | Efficient for large datasets |
+------------------+-------------------------+------------+------------------------------+
| Single JSON file | ``.from_json()``        | ‚ùå         | Loads entire file at once    |
+------------------+-------------------------+------------+------------------------------+
| Folder of files  | ``.from_folder()``      | ‚úÖ         | Streams one file at a time   |
+------------------+-------------------------+------------+------------------------------+
| Glob pattern     | ``.from_glob()``        | ‚úÖ         | Recursively matches files    |
+------------------+-------------------------+------------+------------------------------+

Output Options
--------------

+--------------------+-----------------+------------+-------------------------------+
| Output Method      | Format          | Streaming? | Notes                         |
+====================+=================+============+===============================+
| ``.to_jsonl()``    | JSONL           | ‚úÖ         | One line per record           |
+--------------------+-----------------+------------+-------------------------------+
| ``.to_json()``     | JSON array      | ‚ùå         | Collects before writing       |
+--------------------+-----------------+------------+-------------------------------+
| ``.to_json_files()`` | Folder of files | ‚úÖ         | One file per record           |
+--------------------+-----------------+------------+-------------------------------+
| ``.to_pandas()``   | DataFrame       | ‚ùå         | Collects all data into memory |
+--------------------+-----------------+------------+-------------------------------+

üß† What's Next?
===============

Now that you can load and save data, let's look at inspecting, debugging, and explaining your flows using ``.head()``, ``.keys()``, ``.explain()`` and more.
```### Tutorial: docs/matchflow/grouping_and_aggregating.rst
```rst============================
Grouping and Aggregating Data
============================

After cleaning and transforming individual records, the next step in data analysis is often to summarize information across different groups.

For example:

- Count the number of shots per team
- Compute the average xG per player
- Sum the number of passes per zone

Flow provides powerful tools for these group-based operations.

üîÄ Grouping Records: ``.group_by(...)``
=======================================

Use ``.group_by(...)`` to define how records should be grouped. It takes one or more field names and returns a ``FlowGroup`` object - a pipeline for grouped records.

.. code-block:: python

   from penaltyblog.matchflow import Flow

   sample_records = [
       {"event_id": 1, "type_name": "Pass", "team_name": "Manchester City", "player_name": "Kevin De Bruyne"},
       {"event_id": 2, "type_name": "Shot", "team_name": "Manchester City", "player_name": "Erling Haaland", "shot_xg": 0.05},
       {"event_id": 3, "type_name": "Duel", "team_name": "Manchester City", "player_name": "Rodri"},
       {"event_id": 4, "type_name": "Pass", "team_name": "Manchester City", "player_name": "Kevin De Bruyne"},
       {"event_id": 5, "type_name": "Shot", "team_name": "Arsenal", "player_name": "Bukayo Saka", "shot_xg": 0.01},
   ]

   flow = Flow.from_records(sample_records)

   grouped = flow.group_by("team_name")

You can group by multiple keys:

.. code-block:: python

   flow.group_by("type_name", "player_name")

üìä Aggregating Groups with ``.summary(...)``
=============================================

Once you have a group, use ``.summary(...)`` to compute one or more aggregations per group.

Example: Sum xG per team
------------------------

.. code-block:: python

   result = (
       flow
       .group_by("team_name")
       .summary(total_xg=("shot_xg", "sum"))
   )

   print(result.collect())

Example: Shots and xG per player
--------------------------------

.. code-block:: python

   from penaltyblog.matchflow import where_equals

   player_summary = (
       flow
       .filter(where_equals("type_name", "Shot"))
       .group_by("player_name")
       .summary(
           total_xg=("shot_xg", "sum"),
           number_of_shots="count"
       )
   )

   print(player_summary.collect())

‚öôÔ∏è Built-in Aggregation Functions
=================================

Flow supports many built-in aggregators:

- ``count``, ``sum``, ``mean``, ``min``, ``max``, ``median``, ``std``, ``var``
- ``first``, ``last``, ``mode``, ``range``, ``nunique``
- ``all``, ``any``, ``prod``
- Custom callables or lambdas

üß™ Custom Aggregation Example
=============================

Want to calculate a custom stat, like shots on target %?

.. code-block:: python

   def shot_accuracy(rows):
       outcomes = ["Goal", "Saved"]
       shots = [r for r in rows if r.get("shot_outcome_name")]
       if not shots:
           return 0
       return 100 * sum(r["shot_outcome_name"] in outcomes for r in shots) / len(shots)

Apply it:

.. code-block:: python

   result = (
       flow
       .filter(where_equals("type_name", "Shot"))
       .group_by("player_name")
       .summary(sot_percentage=shot_accuracy)
   )

   print(result.collect())

üîÑ Rolling and Time-Based Aggregations
======================================

In addition to simple group summaries, Flow provides powerful tools to aggregate events across time windows. These are especially useful for event-based data like football matches, where you'd like to calculate rolling metrics or fixed interval summaries.

üîÅ Rolling Summaries: .rolling_summary(...)
-------------------------------------------

Rolling summaries compute an aggregation for each row, based on a moving window of previous rows. This is useful for things like:

- xG over the previous 5 minutes
- Cumulative passes in the last 10 events
- Momentum metrics that change throughout a match

.. code-block:: python

   from datetime import timedelta

   result = (
       flow
       .filter(where_equals("type_name", "Shot"))
       .assign(
           timestamp=lambda r: timedelta(
               minutes=r["minute"],
               seconds=r.get("second", 0)
           )
       )
       .group_by("team_name")
       .sort_by("timestamp")  # Important: sort within groups!
       .rolling_summary(
           window="5m",
           time_field="timestamp",
           aggregators={
               "xg": ("sum", "shot_xg"),
               "shots": ("count", "shot_xg")
           }
       )
       .select("team_name", "timestamp", "xg", "shots")
   )

   result.show()

- The window can be either a time string (``"5m"``, ``"30s"``, ``"1h"``) or an integer (number of rows).
- Always ``.sort_by()`` on your time field after grouping: this ensures the rolling window works as intended.
- The function emits one row per input row, where each aggregation is computed over the previous window of rows.

‚è±Ô∏è Fixed Time Buckets: ``.time_bucket(...)``
--------------------------------------------

If you want non-overlapping, regular time intervals (e.g. total xG every 5 minutes), use ``.time_bucket()``. This partitions your data into uniform windows and computes aggregates for each.

.. code-block:: python

   result = (
       flow
       .filter(where_equals("type_name", "Shot"))
       .assign(
           timestamp=lambda r: timedelta(
               minutes=r["minute"],
               seconds=r.get("second", 0)
           )
       )
       .group_by("team_name")
       .time_bucket(
           freq="5m",
           time_field="timestamp",
           label="left",   # bucket labeled at start of interval
           aggregators={
               "xg": ("sum", "shot_xg"),
               "shots": ("count", "shot_xg")
           }
       )
       .select("team_name", "bucket", "xg", "shots")
   )

   result.show()

- ``freq`` defines the bucket size (e.g. ``"10s"``,  ``"5m"``).
- You don't need to sort beforehand - ``.time_bucket()`` handles sorting internally.
- The label argument controls whether the bucket timestamp refers to the start (``"left"``) or end (``"right"``) of each window.
- The output field for the bucket timestamp defaults to "bucket", but can be renamed via ``bucket_name="..."``.

üìà Aggregating the Whole Dataset
================================

You can call ``.summary()`` directly on a ``Flow`` to compute dataset-wide aggregates without grouping.

.. code-block:: python

   summary = (
       flow
       .filter(where_equals("type_name", "Shot"))
       .summary(
           total_xg=("shot_xg", "sum"),
           avg_xg=("shot_xg", "mean"),
           total_shots="count"
       )
   )

   print(summary.head(1))

‚úÖ Summary
==========

- ``.group_by()`` groups records by field(s)
- ``.summary()`` applies aggregations to each group (or full dataset)
- You can mix built-in aggregators with custom functions
- Grouped flows return regular Flow objects - chain ``.select()``, ``.sort_by()``, etc.

üëâ Next Up: Joining Flows
=========================

Learn how to join datasets together - like linking events with players or match metadata - using ``.join()``.
```### Tutorial: docs/matchflow/index.rst
```rstMatchFlow
==========

.. raw:: html

   <a href="https://colab.research.google.com/drive/1rRJV8mNOTLTXmn5cOGT4faxIwIP44pC-?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

**MatchFlow** is a lightweight toolkit for working with structured football data, especially nested JSON like StatsBomb event files or match-level logs. Whether you're building quick explorations or full pipelines, MatchFlow helps you work directly with deeply structured data using a clean, lazy, and chainable API.

What is MatchFlow?
------------------

Flow is not a DataFrame, it's a **stream-first query engine** built for irregular, event-based football data.

You can:

- Load JSON, JSONL, or entire folders of match data
- Filter and transform records lazily with ``.filter()``, ``.assign()``, ``.select()``
- Group and summarize using ``.group_by()`` + ``.summary()``
- Join datasets, explode lists, split arrays, pivot rows
- Work with nested data without flattening too early
- Chain steps fluently, materialize only when ready
- Filtering using string expressions, like ``"age > 30 and team == @team_name"``
- Stream data directly from the StatsBomb or Opta APIs

All transformations are **lazy**; nothing runs until you ask for results with ``.collect()``, ``.to_pandas()``, ``.to_jsonl()`` etc.

Interactive Examples
--------------------

For a comprehensive, hands-on demonstration of the Matchflow, try the interactive Colab notebook.
The notebook walks you downloading data directly from the Statsbomb API (including Statsbomb's free, open data sets),
building data pipelines, and creating interactive vizualisations using ``penaltyblog``'s ``Pitch`` plotting library.
You can modify the code, experiment with different parameters, and see how the data changes in real-time.

.. raw:: html

   <a href="https://colab.research.google.com/drive/1rRJV8mNOTLTXmn5cOGT4faxIwIP44pC-?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>

Guide Index
-----------

.. list-table:: Guide Index
   :widths: 25 75
   :header-rows: 1

   * - Section
     - Description
   * - :doc:`why`
     - Why working with nested football data needs a new tool
   * - :doc:`introduction`
     - Introduction to MatchFlow
   * - :doc:`basic_pipeline`
     - Filtering, assigning, selecting, and shaping your data
   * - :doc:`grouping_and_aggregating`
     - Summarizing by team, player, period, and more
   * - :doc:`advanced`
     - Sorting, ranking, joining and deduplicating
   * - :doc:`schema`
     - Schema inference, casting, and field validation
   * - :doc:`file_io`
     - Working with JSON, JSONL, folders, glob patterns
   * - :doc:`inspection`
     - Exploring structure, peeking at records, debugging
   * - :doc:`best_practices`
     - Materialization, memory, performance, clean code
   * - :doc:`predicates`
     - Reusable filters like ``where_equals()``, ``and_()``
   * - :doc:`query`
     - Filtering using string expressions, like ``"age > 30 and team == @team_name"``
   * - :doc:`optimizer`
     - Smart plan rewrites for faster execution
   * - :doc:`statsbomb`
     - Streaming data directly from the StatsBomb API
   * - :doc:`opta`
     - Streaming data directly from the Opta API


Quick Start
------------

.. code-block:: python

   from penaltyblog.matchflow import Flow, where_equals

   # Load and filter StatsBomb shots
   flow = (
      Flow.statsbomb.events(match_id=19716)
      .filter(where_equals("type.name", "Shot"))
      .select("player.name", "location", "shot.statsbomb_xg")
   )

   for shot in flow.head(5):
      print(shot)

Ready to Flow?
--------------

Pick a section from the guide above, or jump in with ``.from_jsonl()``, ``.from_folder()``, or ``.statsbomb.events()``  and start building your pipeline.

Need help? Ask questions, file issues, or suggest improvements any time.

.. toctree::
   :hidden:

   why
   introduction
   basic_pipeline
   grouping_and_aggregating
   advanced
   schema
   optimizer
   file_io
   inspection
   best_practices
   predicates
   query
   statsbomb
   opta
```### Tutorial: docs/matchflow/inspection.rst
```rst=====================================
Utility, Inspection & Interoperability
=====================================

Flow gives you flexible tools to inspect, debug, and branch your data pipelines, as well as connect to external libraries like pandas. These tools help you:

- ‚úÖ Peek into streams
- ‚úÖ Materialize for reuse
- ‚úÖ Split pipelines
- ‚úÖ Convert to pandas for export or further analysis

üîç Inspecting Your Flow
=======================

``.first()`` ‚Äì Get the First Record
-----------------------------------

.. code-block:: python

   flow.first()

Returns the first record (or None if empty).

.. warning::
   This materializes the full flow under the hood. For lightweight preview, use .head() instead.

``.head(n)`` ‚Äì Peek at the First N Records
-------------------------------------------

.. code-block:: python

   flow.head(3)

Returns a new Flow with just the first n records. Safe for previewing.

``.show(n, format="table")`` ‚Äì Peek at the First N Records
-----------------------------------------------------------

.. code-block:: python

   flow.show(3)

Prints the first ``n`` records in a prettier format. If ``format`` is "table", prints a table. If ``format`` is "record", prints the raw list of dicts.

``.is_empty()`` ‚Äì Check if Flow is Empty
----------------------------------------

.. code-block:: python

   if flow.is_empty():
       print("No records")

Efficiently checks for the presence of at least one record.

``.keys(limit=100)`` ‚Äì Explore Schema
-------------------------------------

.. code-block:: python

   flow.keys()
   # ‚Üí {'player.name', 'location', 'shot_xg', ...}

Looks at a sample of records and returns the union of top-level (or flattened) keys.

``len(flow)`` ‚Äì Count Records
-----------------------------

.. code-block:: python

   print(len(flow))

Materializes and counts records.

``.schema(n=100)`` ‚Äì Infer Types
--------------------------------

.. code-block:: python

   Flow(...).schema()
   # => {'shot_xg': float, 'player.name': str}

Internally flattens records and maps keys to their types.

``.explain(optimize=None, compare=False)`` ‚Äì Visualize the Plan
---------------------------------------------------------------

.. code-block:: python

   Flow(...).filter(...).assign(...).explain()

.. code-block:: python

   flow = (
       Flow.statsbomb.events(16023)
       .filter(where_equals("type.name", "Shot"))
       .group_by("player.name")
       .summary({"n_shots": ("count", "shot")})
       .sort_by("n_shots", ascending=False)
       .limit(3)
   )
   flow.explain()

.. code-block:: bash

   === Plan ===
      1. from_statsbomb  {'source': 'events', 'args': {'match_id': 16023, 'include_360_metrics': False, 'creds': {'user': None, 'passwd': None}}}
      2. filter          {'predicate': <FieldPredicate: type.name>}
      3. group_by        {'keys': ['player.name']}
      4. group_summary   {'agg': <function FlowGroup.summary.<locals>.agg_func at 0x13ac305e0>, 'group_keys': ['player.name']}
      5. sort            {'keys': ['n_shots'], 'ascending': [False]}
      6. limit           {'count': 3}

Shows the steps in your DAG as text. If ``optimize`` is True, shows the optimized plan. If ``compare`` is True, shows both the raw and optimized plans side by side.

``.plot_plan(optimize=None, compare=False)`` ‚Äì Visualize the Plan
-----------------------------------------------------------------

.. code-block:: python

   Flow(...).filter(...).assign(...).plot_plan()

Plots the steps in your DAG. If ``optimize`` is True, shows the optimized plan. If ``compare`` is True, shows both the raw and optimized plans side by side.

``.profile(optimize=None, fmt="table")`` ‚Äì Profile the Flow
-----------------------------------------------------------

.. code-block:: python

   flow.profile()

Profiles each step in the plan. Returns a report of (step_index, op_name, time_s, rows_emitted). If ``fmt`` is "table", prints a table. If ``fmt`` is "records", returns the raw list of dicts.

.. code-block:: python

   flow = (
      Flow.from_jsonl("data.jsonl", optimize=True)
          .filter(lambda r: r["x"] > 0)
          .group_by("x")
          .summary({"sum_x": ("sum","x")})
   )
   flow.profile()

.. code-block:: bash

   |  # | op           |   sec |   rows |
   |---:|:-------------|------:|-------:|
   |  1 | from_jsonl   | 0.015 | 100000 |
   |  2 | filter       | 0.020 |  90000 |
   |  3 | group_by     | 0.050 |     10 |
   |  4 | group_summary| 0.002 |     10 |

üì¶ Materializing Data
=====================

Flow is lazy by default. Use these methods to "force" evaluation.

``.collect(optimize=None, progress=None, total_records=None)`` - Convert to List
-------------------------------------------------------------------------------

Fully materializes the flow into a list of records.

This method executes the entire flow pipeline and returns all records as a list. It is typically used when you need to load the data into memory for downstream processing, visualization, or export.

.. code-block:: python

   records = Flow(...).collect()

**Parameters**

- ``optimize``:
    - Whether to apply plan optimizations before execution.
    - If ``True``, applies optimizations to improve execution efficiency.
    - If ``False``, runs the plan exactly as constructed.
    - If ``None`` (default), uses the optimization setting specified when the Flow was created.
- ``progress``:
    - Enables progress bars during execution.
    - "input": displays progress while reading source data (before transformations).
    - "output": displays progress after transformations during final materialization.
    - None (default): disables progress bars.
- ``total_records``:
    - Expected total number of records (used for progress bar display).
    - If not provided, progress bars will fall back to indeterminate mode.

``.cache()`` ‚Äì Materialize Once
-------------------------------

.. code-block:: python

   flow.cache()

Materializes the current records into memory and gives you a new Flow from that result. This is useful when you want to reuse the same records multiple times without re-executing the pipeline.

üß© Custom Logic: ``.pipe()``
============================

``.map(func)`` ‚Äì Transform Records
----------------------------------

Applies a function to each record, replacing it with the returned dict.

.. code-block:: python

   flow = flow.map(lambda r: {"name": r["player"]["name"], "x": r.get("x")})

If ``func(record)`` returns ``None``, the record is skipped.

.. note::
   Use ``.map()`` when you want to remap the entire record. Use ``.assign()`` to add or update fields while keeping the rest intact.

``.pipe(func)`` ‚Äì Branch Into Custom Logic
------------------------------------------

Use ``.pipe()`` to cleanly encapsulate multi-step logic in a function:

.. code-block:: python

   def filter_shots(flow):
       return flow.filter(lambda r: r.get("type") == "Shot")

   Flow.from_folder("data/").pipe(filter_shots).select("player.name", "shot_xg")

üß© Interop with Other Tools
===========================

``.to_pandas()`` ‚Äì Convert to DataFrame
---------------------------------------

.. code-block:: python

   df = Flow(...).flatten().to_pandas()

Converts the flow to a pandas DataFrame. This is useful for exporting to CSV, Excel, or other tools.

‚úÖ Summary
==========

+------------------+------------------------------------------+
| Method           | Purpose                                  |
+==================+==========================================+
| ``.head(n)``     | Get first ``n`` records                 |
+------------------+------------------------------------------+
| ``.first()``     | First record or ``None``                |
+------------------+------------------------------------------+
| ``.show(n)``     | Print first ``n`` records               |
+------------------+------------------------------------------+
| ``.is_empty()``  | Check if Flow yields any data           |
+------------------+------------------------------------------+
| ``.keys()``      | Discover fields                         |
+------------------+------------------------------------------+
| ``.schema()``    | Infer field types                       |
+------------------+------------------------------------------+
| ``.explain()``   | Visualize DAG plan as text              |
+------------------+------------------------------------------+
| ``.plot_plan()`` | Visualize DAG plan                      |
+------------------+------------------------------------------+
| ``.map()``       | Transform records completely            |
+------------------+------------------------------------------+
| ``.pipe()``      | Encapsulate logic or interop with pandas|
+------------------+------------------------------------------+
| ``.collect()``   | Materialize to list                     |
+------------------+------------------------------------------+
| ``.cache()``     | Materialize once and cache in memory    |
+------------------+------------------------------------------+
| ``.profile()``   | Profile each step in the plan           |
+------------------+------------------------------------------+
| ``.to_pandas()`` | Convert to DataFrame                    |
+------------------+------------------------------------------+
```### Tutorial: docs/matchflow/introduction.rst
```rst====================
Introduction to Flow
====================

*A lazy, schema-aware pipeline for nested football data*

In football analytics, a lot of data comes as **deeply nested JSON** - think event data, match metadata, freeze frames, and tracking points.

Yet most tools flatten this structure too early, forcing everything into rigid tables. This leads to brittle pipelines, excessive cleanup, and premature decisions about schema.

**Flow** takes a different approach: it treats nested JSON as a first-class citizen. It lets you build clear, chainable pipelines over structured records without needing to normalize everything first.

üß† What is Flow?
=================

Flow is a lightweight query engine for nested data. It gives you:

- Lazy, chainable operations: ``filter()``, ``assign()``, ``group_by()``, etc.
- Natural access to nested fields (``"player.name"``, ``"location.x"``)
- Reusable, explainable pipelines
- Outputs to JSONL, pandas, or disk - but only when you ask

Under the hood, Flow builds a **plan** - a list of transformation steps - and doesn't execute anything until you call ``.collect()`` or ``.to_pandas()``.

üß™ Example: Filter and Transform Shots
=======================================

.. code-block:: python

   from penaltyblog.matchflow import Flow, where_equals, where_gt

   flow = (
       Flow.from_folder("data/events/")
       .filter(
           where_equals("type.name", "Shot"),
           where_gt("shot.stats.xG", 0.2)
       )
       .assign(xg_label=lambda r: "High xG" if r["shot"]["stats"]["xG"] > 0.5 else "Low xG")
       .select("player.name", "team.name", "xg_label")
   )

   flow.show(5)

Nothing is computed until the end, you're building a lazy pipeline, not evaluating data immediately.

‚öôÔ∏è Lazy Execution: Nothing Happens Until You Ask
=================================================

Flow's operations are lazy. Every method adds a step to the internal plan:

.. code-block:: text

   Flow(...) ‚Üí .filter(...) ‚Üí .assign(...) ‚Üí .select(...)

But no records are actually processed until you:

- Call ``.collect()`` ‚Üí get a list of records
- Call ``.to_pandas()`` ‚Üí build a DataFrame
- Call ``.to_jsonl()`` ‚Üí write to disk
- Use a loop: ``for row in flow``

üßä Reuse and Caching
====================

Flows are built to be reusable. You can run ``.collect()`` multiple times, and even inspect the pipeline with ``.explain()``:

.. code-block:: python

   flow.explain()
   # Shows a step-by-step plan of your pipeline

If your data source is expensive (e.g. API or big JSONL), cache it:

.. code-block:: python

   flow = Flow.from_jsonl("events.jsonl").filter(...)

   cached = flow.cache()  # Runs once, stores the results

   df = cached.to_pandas()
   head = cached.head(3)

``.cache()`` materializes the current records into memory and gives you a new Flow from that result.

üß† A Different Way of Thinking
==============================

Flow is not a dataframe.

It's a pipeline builder for nested JSON - more like SQL or Spark, but designed for Python and football analytics.

You don't flatten your data until you're ready.

You don't write repetitive dict lookups or munging code.

You don't worry about rows with missing tags or optional fields.

You just write clear pipelines.

‚ö†Ô∏è Notes on Mutability
======================

Flow may modify records in-place for performance.

- If you care about preserving your original data, use ``copy.deepcopy(data)`` before passing it in.
- Or call ``.cache()`` or ``.materialize()`` to freeze the state into a new memory-backed Flow.

üöÄ Summary: Why Use Flow?
=========================

Flow is designed for working with real-world football data:

- ‚úÖ Natural access to nested fields
- ‚úÖ Lazy evaluation with reusability
- ‚úÖ Built-in filter helpers (``where_equals``, ``where_in``, ``where_gt`` etc)
- ‚úÖ Outputs to JSONL, pandas, or JSON
- ‚úÖ Keeps pipelines readable and composable

If you're flattening your data just to load it into pandas, Flow lets you skip that step, and work with the structure as-is.

üõ†Ô∏è Coming Soon: flowz Format
=============================

I'm actively working on a fast, binary format (``.flowz``) for even faster loading, predicate pushdown, and indexing. For now, JSON and JSONL are fully supported.

üí¨ Try it and break it
======================

.. code-block:: bash

   pip install penaltyblog

then

.. code-block:: python

   from penaltyblog.matchflow import Flow

   Flow.from_folder("data/")
       .filter(...)
       .select(...)
       .show()

If something doesn't work, or you're fighting the shape of your data, please open an issue or drop a note. That's the point of v1.
```### Tutorial: docs/matchflow/opta.rst
```rst===========================
Using Flow with Opta Data
===========================

Flow includes a built-in integration with the Stats Perform (Opta) API, making it easy to stream structured football data directly into your pipelines.

Rather than loading everything upfront, Flow wraps the API as **lazy operations** - each call builds a plan that fetches the data only when needed (e.g., on ``.collect()`` or ``.to_pandas()``).

‚öôÔ∏è Setup
========

Ensure your **Opta credentials** are set as environment variables:

.. code-block:: bash

   export OPTA_AUTH_KEY="your_auth_key"
   export OPTA_RT_MODE="b"

üöÄ Getting Started
==================

.. code-block:: python

   from penaltyblog.matchflow.contrib import opta

   # Fetch all areas
   areas = opta.areas()

   for area in areas.head(3):
       print(area)

All API calls return a ``Flow``, so you can apply all usual transformations like ``.filter()``, ``.select()``, ``.assign()``, etc.

üîç Available Endpoints
======================

.. list-table:: Available Opta API Endpoints
   :header-rows: 1
   :widths: 50 10 40

   * - Method
     - Feed ID
     - Description
   * - ``.tournament_calendars(...)``
     - OT2
     - All tournament calendars available via API
   * - ``.venues(...)``
     - OT3
     - All venues available via API
   * - ``.areas([area_uuid])``
     - OT4
     - All areas available via API
   * - ``.tournament_schedule(tournament_calendar_uuid, ...)``
     - MA0
     - Matches for a specific season
   * - ``.matches(...)``
     - MA1
     - All matches available via API
   * - ``.match(fixture_uuid, ...)``
     - MA1
     - A single match
   * - ``.match_stats_player(fixture_uuids, ...)``
     - MA2
     - Player-level stats for a match
   * - ``.match_stats_team(fixture_uuids, ...)``
     - MA2
     - Team-level stats for a match
   * - ``.events(fixture_uuid, ...)``
     - MA3
     - All events in a match
   * - ``.pass_matrix(fixture_uuid, ...)``
     - MA4
     - Pass matrix and average formation data
   * - ``.possession(fixture_uuid, ...)``
     - MA5
     - Possession and territorial advantage data
   * - ``.player_career(...)``
     - PE2
     - Player career data
   * - ``.referees(...)``
     - PE3
     - All referees available via API
   * - ``.rankings(tournament_calendar_uuid, ...)``
     - PE4
     - Rankings data for players, teams, and games
   * - ``.injuries(...)``
     - PE7
     - All injuries available via API
   * - ``.teams(...)``
     - TM1
     - All teams available via API
   * - ``.team_standings(tournament_calendar_uuid, ...)``
     - TM2
     - League table and standings data with multiple division types (total, home, away, form, half-time, etc.)
   * - ``.squads(...)``
     - TM3
     - All squads available via API
   * - ``.player_season_stats(tmcl_uuid, ctst_uuid, ...)``
     - TM4
     - Player stats over a season
   * - ``.team_season_stats(tmcl_uuid, ctst_uuid, ...)``
     - TM4
     - Team stats over a season
   * - ``.transfers(...)``
     - TM7
     - Player transfer data
   * - ``.contestant_participation(contestant_uuid, ...)``
     - TM16
     - Contestant participation data

All of these return a lazy Flow

üìã Parameter Validation & Constraints
==================================

Some methods have specific validation rules and parameter constraints:

**Required Parameters**

- ``venues()``: At least one of ``tournament_calendar_uuid``, ``contestant_uuid``, or ``venue_uuid`` must be provided
- ``matches()``: Both ``date_from`` and ``date_to`` must be provided together (if using date filtering)
- ``referees()``: Exactly one of ``person_uuid``, ``tournament_calendar_uuid``, or ``stage_uuid`` must be provided
- ``teams()``: Either ``tournament_calendar_uuid`` or ``contestant_uuid`` must be provided
- ``squads()``: Either ``tournament_calendar_uuid`` or ``contestant_uuid`` must be provided
- ``player_career()``: Exactly one of ``person_uuid`` or ``contestant_uuid`` must be provided
- ``injuries()``: Either ``person_uuid`` or ``tournament_calendar_uuid`` must be provided
- ``transfers()``: At least one of ``person_uuid``, ``contestant_uuid``, ``competition_uuid``, or ``tournament_calendar_uuid`` must be provided

**Date Parameter Constraints**

- ``matches()``: When using ``date_from``/``date_to``, they must be valid dates and ``date_from`` cannot be after ``date_to``
- ``transfers()``: When using ``start_date``/``end_date``, ``competition_uuid`` must be provided and ``tournament_calendar_uuid`` cannot be used

**Common Parameter Types**

- ``fixture_uuids``: Accepts ``str`` or ``List[str]`` (for match stats methods)
- ``event_types``: Accepts ``int`` or ``List[int]`` (for events method)
- ``coverage_level``: Accepts ``int`` or ``List[int]`` (for tournament_schedule method)
- ``contestant_uuid``: Accepts ``str`` or ``List[str]`` (for contestant_participation method)

**Optional Parameters**

- ``use_opta_names``: Available on most methods (default: ``False``) - Requests 'en-op' locale for Opta-specific names
- ``creds``: Dictionary with ``auth_key`` and ``rt_mode`` (or use environment variables)
- ``proxies``: Dictionary for proxy configuration (e.g., ``{'http': 'socks5h://localhost:9090'}``)
- ``optimize``: Boolean to optimize execution plan (default: ``False``)

üß™ Example: Referees in a Tournament
====================================

.. code-block:: python

   from penaltyblog.matchflow.contrib import opta

   referees = (
       opta.referees(tournament_calendar_uuid="51r6ph2woavlbbpk8f29nynf8")
       .select("firstName", "lastName", "nationality")
   )

   for referee in referees.head(3):
       print(referee)

üß™ Example: Using Opta-Specific Names
=====================================

.. code-block:: python

   from penaltyblog.matchflow.contrib import opta

   # Get team standings with Opta-specific names
   standings = (
       opta.team_standings(
           tournament_calendar_uuid="51r6ph2woavlbbpk8f29nynf8",
           type="total",
           use_opta_names=True
       )
   )

üß™ Example: Multiple Fixture UUIDs
================================

.. code-block:: python

   from penaltyblog.matchflow.contrib import opta

   # Get player stats for multiple matches
   player_stats = (
       opta.match_stats_player(
           fixture_uuids=["match1_uuid", "match2_uuid", "match3_uuid"],
           use_opta_names=True
       )
   )

üßº Filtering & Transforming
===========================

Because Flow supports deep access to nested fields, you can work directly with Opta's JSON structure without needing to flatten first:

.. code-block:: python

   from penaltyblog.matchflow.contrib import opta

   english_referees = (
       opta.referees(tournament_calendar_uuid="51r6ph2woavlbbpk8f29nynf8")
       .filter(lambda r: r["nationality"] == "England")
       .select("firstName", "lastName")
   )

üê¢ Lazy Until Needed
====================

Remember, nothing is downloaded or processed until you **materialize the flow**:

- ``.collect()`` ‚Üí fetches all records
- ``.to_pandas()`` ‚Üí fetches and converts to DataFrame
- ``.head(n)`` ‚Üí fetches just the first n records

.. code-block:: python

   df = opta.areas().to_pandas()
   print(df)

üîí Authenticated Access
=======================

All API methods accept a creds dictionary, or you can use environment variables. They also accept a `proxies` argument for routing requests through a proxy.

.. code-block:: python

   proxies = {
       'http': 'socks5h://localhost:9090',
       'https': 'socks5h://localhost:9090'
   }

   data = opta.tournament_calendars(
       status="all",
       proxies=proxies
   ).collect()

.. code-block:: python

   opta.referees(tournament_calendar_uuid="51r6ph2woavlbbpk8f29nynf8", creds={"auth_key": "...", "rt_mode": "..."})

üß† Tips
=======

- **Cloud Ready:** You can stream data directly to cloud storage without downloading it locally first: ``opta.events(...).to_jsonl("s3://my-bucket/events.jsonl")``
- **Integration:** Useful for clubs or analysts already using Opta data who want to join it with internal data.
- **Exporting:** Try ``.flatten().to_jsonl()`` to export clean, flat

üìù Summary
==========

Flow's Opta integration:

- ‚úÖ Keeps your data structured
- ‚úÖ Streams on demand (not loaded eagerly)
- ‚úÖ Integrates with full Flow pipeline tools
- ‚úÖ Works with both open and authenticated endpoints

.. _opta-helpers:

üíÅ Opta Helpers
===============

The ``penaltyblog.matchflow.opta_helpers`` module provides helper functions to simplify common filtering tasks when working with Opta event data. These helpers allow you to filter by human-readable names instead of remembering specific Opta ID codes.

Filtering by Event Type
-----------------------

Use ``where_opta_event()`` to filter events by their name, like "Pass" or "Shot". The helper automatically looks up the correct ``typeId``.

.. code-block:: python

   from penaltyblog.matchflow.contrib import opta
   from penaltyblog.matchflow.opta_helpers import where_opta_event

   # Get all shots for a match
   shots = (
       opta.events(fixture_uuid="some_match_id")
       .filter(where_opta_event("Shot"))
   )

   # You can also filter for multiple event types
   passes_and_shots = (
       opta.events(fixture_uuid="some_match_id")
       .filter(where_opta_event(["Pass", "Shot"]))
   )


Filtering by Qualifier
----------------------

Use ``where_opta_qualifier()`` to filter events that have a specific qualifier. You can check for the presence of a qualifier or for a qualifier with a specific value.

**Checking for Presence**

.. code-block:: python

   from penaltyblog.matchflow.contrib import opta
   from penaltyblog.matchflow.opta_helpers import where_opta_qualifier

   # Get all penalty shots
   penalty_shots = (
       opta.events(fixture_uuid="some_match_id")
       .filter(where_opta_event("Shot"))
       .filter(where_opta_qualifier("Penalty"))
   )

**Checking for a Specific Value**

.. code-block:: python

   from penaltyblog.matchflow.contrib import opta
   from penaltyblog.matchflow.opta_helpers import where_opta_qualifier

   # Get all shots from the "Danger Zone"
   danger_zone_shots = (
       opta.events(fixture_uuid="some_match_id")
       .filter(where_opta_event("Shot"))
       .filter(where_opta_qualifier("Zone", "Danger Zone"))
   )


Exploring Available Mappings
----------------------------

To see all available event and qualifier names that you can use with the helpers, use the ``get_opta_mappings()`` function.

.. code-block:: python

   from penaltyblog.matchflow.opta_helpers import get_opta_mappings

   mappings = get_opta_mappings()

   print("Available Event Types:")
   for event in mappings["events"]:
       print(f"  ID: {event['id']:3d} | Name: {event['name']}")

   print("\nAvailable Qualifier Types:")
   for qualifier in mappings["qualifiers"]:
       print(f"  ID: {qualifier['id']:3d} | Name: {qualifier['name']}")

This will return a dictionary containing all event and qualifier names and their corresponding IDs. The mappings include comprehensive football event data such as:

**Key Event Types:**
- Pass (1), Offside Pass (2), Take On (3), Foul (4)
- Save (10), Clearance (12), Miss (13), Post (14), Attempt Saved (15), Goal (16)
- Card (17), Substitutions (18, 19), Interception (8), Tackle (7)
- And many more specialized events (80+ total event types)

**Key Qualifier Types:**
- Long Ball (1), Cross (2), Head Pass (3), Through Ball (4)
- Penalty (9), Handball (10), Various card types (31-33)
- Pitch zones (e.g. Small box - Centre (16), Box - Right (63))
- Shot locations (76-87), Save types (173-183), VAR-related qualifiers (329-336)
- And hundreds of detailed qualifiers for specific situations

The helper functions automatically handle the case-insensitive lookup, so you can use human-readable names like "Shot", "Pass", "Penalty", "Zone" etc. in your filters without needing to remember the specific Opta IDs.

üîç Endpoint Arguments
======================

.. autoclass:: penaltyblog.matchflow.contrib.opta.Opta
   :members:
   :undoc-members:
   :show-inheritance:
```### Tutorial: docs/matchflow/optimizer.rst
```rst==================
Query Optimization
==================

MatchFlow includes a **built-in query optimizer** that transparently rewrites your pipeline to improve performance while preserving semantics.

In general:

- ‚úÖ safer pipelines
- ‚úÖ faster execution
- ‚úÖ smaller intermediate data
- ‚úÖ better scalability

üöÄ When Optimization Happens
============================

By default, flows are unoptimized:

.. code-block:: python

   flow = Flow.from_jsonl("match_events.jsonl")

To enable optimization, pass ``optimize=True``:

.. code-block:: python

   flow = Flow.from_jsonl("match_events.jsonl", optimize=True)

Or explicitly at collect-time:

.. code-block:: python

   flow.collect(optimize=True)

Any visualization (``explain()``, ``plot_plan()``, etc.) can also show optimized plans.

üß† What The Optimizer Does
==========================

The optimizer currently performs **conservative rule-based** rewrites, including:

+--------------------------------+-----------------------------------------------------------------------------+
| Optimization                   | Description                                                                 |
+================================+=============================================================================+
| **Filter Pushdown**            | Moves ``filter()`` earlier to reduce data earlier                          |
+--------------------------------+-----------------------------------------------------------------------------+
| **Limit Pushdown**             | Moves ``limit()`` closer to source                                         |
+--------------------------------+-----------------------------------------------------------------------------+
| **Select/Drop Pushdown**       | Drops unused fields as early as safely possible                            |
+--------------------------------+-----------------------------------------------------------------------------+
| **Map/Assign Fusion**          | Merges consecutive ``map()``, ``assign()``, ``filter()`` into a single fused step |
+--------------------------------+-----------------------------------------------------------------------------+
| **Redundant Step Elimination** | Removes unnecessary repeated ``drop()``, ``dropna()``                      |
+--------------------------------+-----------------------------------------------------------------------------+
| **Rolling Validation**         | Warns if rolling summaries lack prior ``sort()`` step                      |
+--------------------------------+-----------------------------------------------------------------------------+

üßê Example
==========

Consider the following flow:

.. code-block:: python

   flow = (
       Flow.from_jsonl("match_events.jsonl")
       .assign(team_name=lambda r: r["team"]["name"])
       .filter(lambda r: r["type"]["name"] == "Pass")
       .select("minute", "second", "team_name")
       .limit(100)
   )

Without optimization:

.. code-block:: bash

   from_jsonl ‚Üí assign ‚Üí filter ‚Üí select ‚Üí limit

With optimization:

.. code-block:: bash

   from_jsonl ‚Üí filter ‚Üí assign ‚Üí select ‚Üí limit

- The ``filter()`` is pushed earlier.
- The ``assign()`` and ``select()`` are reordered.
- The ``limit()`` is moved earlier.
- Fewer rows flow through the pipeline.

üîç Explain Your Plans
=====================

You can always inspect both raw and optimized plans:

.. code-block:: python

   flow.explain(compare=True)

Or visualize them:

.. code-block:: python

   flow.plot_plan(compare=True)

üö´ What The Optimizer Does Not Do (yet...)
==========================================

- Complex join reordering
- Predicate simplification
- Cost-based optimization
- Group-by optimizations

The optimizer is designed to be **safe-by-default**: it will only reorder steps when correctness can be statically guaranteed.

‚öô Optimizer Safety Model
========================

MatchFlow applies **conservative optimizations** to preserve correctness when working with arbitrary user-defined functions:

‚úÖ Safe to optimize:
  Operations like ``select()``, ``drop()``, ``limit()``, ``filter()`` (when independent), ``sort()``, ``group_by()``, and other structural plan steps.

üö´ Not assumed safe to reorder:
  - ``map()``
  - ``assign()``
  - any user-defined ``filter()`` with non-trivial predicates
  - any lambdas or custom functions

üîí Why conservative?
  Unlike SQL engines, MatchFlow makes no assumptions about:

  - Commutativity: e.g. ``map()`` and ``filter()`` may not commute.
  - Determinism: user functions may depend on external state, random values, timestamps, etc.
  - Purity: functions may have side-effects or depend on execution order.

‚ö† Fusion:
  - Consecutive ``map()`` / ``assign()`` / ``filter()`` steps may be fused together at plan build time (syntactic fusion).
  - Fusion never involves reordering; it only combines adjacent steps for efficiency.

üî¨ Invariant:
  The execution semantics of any user-specified Flow remain the same under optimization, unless steps were fused at creation time.

Summary
=======

+---------------------------+---------------------------------------+
| You Write                 | Optimizer Makes Fast                  |
+===========================+=======================================+
| **Declarative pipelines** | Minimal and efficient execution plans |
+---------------------------+---------------------------------------+
| **Readable code**         | Faster runtime                        |
+---------------------------+---------------------------------------+
| **Safe transformations**  | Transparent optimization              |
+---------------------------+---------------------------------------+
```### Tutorial: docs/matchflow/predicates.rst
```rst========================================
Filtering Data with Predicates and Helpers
========================================

Flow includes a powerful set of **predicate helpers** that make it easier to filter nested, irregular JSON records without writing complex lambda functions every time.

These functions are designed to be:

- ‚úÖ **Readable**: No more long inline lambdas
- ‚úÖ **Safe**: Handle nested paths, nulls, and edge cases
- ‚úÖ **Composable**: Chain filters with ``and_()``, ``or_()``, ``not_()``

‚ú® Why Use Predicates?
======================

Instead of writing:

.. code-block:: python

   flow.filter(lambda r: r.get("type") == "Shot" and r["xg"] > 0.1)

You can write:

.. code-block:: python

   from penaltyblog.matchflow import where_equals, where_gt, and_

   flow.filter(and_(
       where_equals("type", "Shot"),
       where_gt("xg", 0.1)
   ))

Cleaner, safer, and easier to maintain.

üîç Core Predicate Helpers
=========================

``where_equals(field, value)``
------------------------------

Match records where a field equals a specific value.

.. code-block:: python

   where_equals("team.name", "Arsenal")

``where_not_equals(field, value)``
----------------------------------

Inverse of where_equals.

``where_in(field, values)``
---------------------------

Match records where a field value (or items in a list field) are in a list.

.. code-block:: python

   where_in("player.name", ["Messi", "Mbappe"])

If the field is a list, it checks if any item is in the list of values.

.. warning::
   Fails safely if the field is a dict or a list of dicts.

``where_not_in(field, values)``
-------------------------------

Inverse of where_in. Matches if none of the values appear.

``where_contains(field, substring)``
------------------------------------

Check if a substring appears in the string form of a field.

.. code-block:: python

   where_contains("player.name", "Haaland")

``where_exists(field)``
-----------------------

Check if the field exists and is not None.

.. code-block:: python

   where_exists("location")

``where_is_null(field)``
------------------------

Only matches records where the field is missing or explicitly None.

.. code-block:: python

   where_is_null("location")

Comparison Helpers
==================

+-------------------+----------------+
| Function          | Matches When   |
+===================+================+
| ``where_gt(f, x)``  | Field ``f > x``  |
+-------------------+----------------+
| ``where_gte(f, x)`` | Field ``f >= x`` |
+-------------------+----------------+
| ``where_lt(f, x)``  | Field ``f < x``  |
+-------------------+----------------+
| ``where_lte(f, x)`` | Field ``f <= x`` |
+-------------------+----------------+

üîó Composing Predicates
=======================

Use logical combinators to build compound filters:

``and_(*predicates)``
---------------------

All must be true.

.. code-block:: python

   filter(and_(
       where_equals("type", "Shot"),
       where_gt("xg", 0.1)
   ))

``or_(*predicates)``
--------------------

Any can be true.

.. code-block:: python

   filter(or_(
       where_equals("type", "Shot"),
       where_equals("type", "Header")
   ))

``not_(predicate)``
-------------------

Negate any predicate.

.. code-block:: python

   filter(not_(where_equals("type", "Own Goal")))

üîß Advanced Use: Nested + Typed Safety
======================================

All predicate helpers:

- Support dot notation for nested fields
- Handle missing fields safely (return False)
- Raise helpful errors for unsupported types (e.g. filtering a dict)

üì¶ How to Import
================

You can import individual helpers:

.. code-block:: python

   from penaltyblog.matchflow import where_equals, and_

Or import all in one go:

.. code-block:: python

   from penaltyblog.matchflow import predicates

   flow.filter(predicates.and_(
       predicates.where_equals("type", "Shot"),
       predicates.where_gt("xg", 0.1)
   ))

‚úÖ Summary
==========

Predicate helpers make Flow filters:

- Safer on real-world nested JSON
- More expressive than bare lambdas
- Easier to reuse and compose

They're especially useful in pipelines that must remain readable, modular, or user-defined.

If you work with deeply nested data, predicates are the clearest way to say what you want.
```### Tutorial: docs/matchflow/query.rst
```rst================
The Query Method
================

The ``Flow`` class includes a powerful ``.query()`` method, enabling you to filter records using a concise, string-based expression. This improves the readability and flexibility of your data processing pipelines.

You can specify complex filtering conditions using standard Python comparison and logical operators, field access, and even built-in functions or string methods.

Use ``.query()`` when you want to:

- Prototype filters quickly.
- Write more readable and maintainable pipeline logic.
- Let users define filters without writing custom Python code.

How it Works
============

The ``.query()`` method parses a string expression using Python's Abstract Syntax Tree (AST) module. It then converts this AST into an efficient predicate function, which is applied to each record in the ``Flow`` stream. This approach ensures security (as it doesn't use ``eval()`` directly on arbitrary input) and allows for robust validation of the query syntax.

Basic Comparisons
=================

You can compare record fields to literal values using standard comparison operators:

- ``==`` (equals)
- ``!=`` (not equals)
- ``>`` (greater than)
- ``>=`` (greater than or equal to)
- ``<`` (less than)
- ``<=`` (less than or equal to)

.. code-block:: python

   # Example: Filter for matches with more than 3 goals
   flow.query("goals > 3")

   # Example: Filter for matches played by 'Man City'
   flow.query("home_team == 'Man City'")

Logical Operators
=================

Combine multiple conditions using ``and``, ``or``, and ``not``:

- ``and``
- ``or``
- ``not``

.. code-block:: python

   # Example: Home wins for 'Liverpool'
   flow.query("home_team == 'Liverpool' and home_goals > away_goals")

   # Example: Matches not involving 'Arsenal'
   flow.query("not (home_team == 'Arsenal' or away_team == 'Arsenal')")

Field Access
============

Access nested fields using dot notation:

- ``field.subfield``

.. code-block:: python

   # Example: Filter based on nested 'venue.city' field
   flow.query("venue.city == 'London'")

Membership Operators (``in``, ``not in``)
=========================================

Check if a field's value is present in a list or tuple:

- ``in``
- ``not in``

.. code-block:: python

   # Example: Filter for matches involving specific teams
   flow.query("home_team in ['Chelsea', 'Tottenham']")

   # Example: Filter for matches NOT involving a specific league
   flow.query("league not in ['Premier League', 'La Liga']")

.. warning::
   ``in`` and ``not in`` require the field to appear on the left-hand side of the expression. Reverse usage is not currently supported (e.g., "Man City" in home_team will raise an error).

Checking for NULLs
==================

Check for null/missing values:

- ``is None``
- ``is not None``

.. code-block:: python

   # Example: Find records where 'player.injury_status' is null
   flow.query("player.injury_status is None")

   # Example: Find records where 'player.injury_status' is not null
   flow.query("player.injury_status is not None")

String Methods
==============

Apply common string transformations for comparison. Note these are used *within* a comparison:

- ``len()``: Get the length of a string or list/tuple.
- ``.lower()``: Convert a string to lowercase.
- ``.upper()``: Convert a string to uppercase.

.. code-block:: python

   # Example: Find teams whose name is exactly 'manchester united' (case-insensitive)
   flow.query("home_team.lower() == 'manchester united'")

   # Example: Find teams with a short name
   flow.query("len(home_team) < 8")

Predicate-Style String Methods (Standalone)
===========================================

Directly check string properties using method calls:

- ``.contains(substring)``
- ``.startswith(prefix)``
- ``.endswith(suffix)``
- ``.regex(pattern, flags)`` or ``.match(pattern, flags)``

.. code-block:: python

   # Example: Find home teams containing 'united'
   flow.query("home_team.contains('united')")

   # Example: Find away teams starting with 'West'
   flow.query("away_team.startswith('West')")

   # Example: match player name using a regex
   flow.query("player.name.regex('^Mo')")

Referencing Local Python Variables (``@var``)
=============================================

To make your queries dynamic, you can inject external Python variables using the ``@`` symbol. This allows you to construct queries programmatically while maintaining readability. For example, ``@team_name`` will be replaced with the actual value of the variable ``team_name`` from your Python scope.

This is especially useful when working with date ranges, parameterized filters, or reusable queries.

.. code-block:: python

   import datetime

   min_goals = 2
   team_name = "Liverpool"
   start_date = datetime.date(2023, 1, 1)

   # Example: Using numeric and string variables
   flow.query("home_goals >= @min_goals and home_team == @team_name")

   # Example: Using a date object
   flow.query("match_date >= @start_date")

For regular expressions, you should pass flags such as ``re.IGNORECASE`` or ``re.MULTILINE`` by referencing them the same way:

.. code-block:: python

   import re

   pattern = r"liverpool"
   flags = re.IGNORECASE

   # Example: matching a string using a regular expression
   flow.query("home_team.regex(@pattern, @flags)")

Remember:

- Regex flags must be passed as values from the ``re`` module.
- The query parser substitutes ``@var`` with safe, scoped values - no arbitrary code execution occurs.

Filtering by Date and Time
==========================

You can filter results using ``datetime()`` and ``date()`` objects from Python's built-in ``datetime`` module.
These can be used directly in your query strings to create date or datetime values for comparison.

.. code-block:: python

   # Example: Matches after a specific date
   flow.query("match_date > date(2024, 6, 30)")
```### Tutorial: docs/matchflow/schema.rst
```rst====================================
Schema Validation and Type Casting
====================================

Working with messy football data often means handling nested structures, missing fields, and inconsistent types.

MatchFlow provides several tools to help you explore, infer, and enforce schemas as your pipeline evolves.

üîç Quick Field Exploration: ``.keys()``
========================================

Use ``.keys()`` to quickly inspect the set of fields present in your data. This scans a sample of records, flattens nested structures, and returns a set of unique field names.

.. code-block:: python

   flow = Flow.from_jsonl("match_events.jsonl")
   fields = flow.keys()

   print(fields)
   # {'type.name', 'player.name', 'location', 'shot.statsbomb_xg', ...}

You can control the number of records sampled:

.. code-block:: python

   flow.keys(limit=10)

- Only inspects field names.
- Does not infer types.
- Useful for quickly exploring raw data.

üßÆ Full Schema Inference: ``.schema()``
=======================================

For a deeper look at both field names and data types, use ``.schema()``.

.. code-block:: python

   schema = flow.schema()
   print(schema)
   # {'type.name': str, 'player.name': str, 'location': list, 'shot.statsbomb_xg': float, ...}

- Samples the first 100 records by default (you can override with ``n=``).
- Supports nested fields via dot notation.
- Helps you understand the structure before casting.

üéØ Type Casting: ``.cast()``
============================

You can cast fields to specific types or functions using ``.cast()``:

.. code-block:: python

   flow = flow.cast(
       minute=int,
       second=int,
       shot_xg=float
   )

- Takes keyword arguments where keys are field names (dot notation supported) and values are casting functions or types.
- If casting fails, original value is kept (safe fallback).

üö¶ Full Schema Enforcement: ``.with_schema()``
==============================================

For full control, you can use ``.with_schema()`` to:

- Cast fields
- Optionally enforce strict type safety
- Optionally drop fields not in the schema

.. code-block:: python

   from datetime import datetime

   def parse_datetime(dt_str):
       return datetime.strptime(dt_str, "%Y-%m-%d %H:%M:%S")

   flow.with_schema({
       "team.name": str,
       "score": int,
       "timestamp": parse_datetime
   }, strict=True, drop_extra=True)

- ``strict=True`` will raise an error on casting failure.
- ``drop_extra=True`` will retain only fields listed in the schema.

This is useful when you want to fully sanitize your data before downstream analysis or modeling.
```### Tutorial: docs/matchflow/statsbomb.rst
```rst===============================
Using Flow with StatsBomb Data
===============================

.. raw:: html

   <a href="https://colab.research.google.com/drive/1vctEMktiSri4zUhawT7Z3KauKprWkGtW?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

Flow includes a built-in integration with the StatsBomb API, making it easy to stream structured football data directly into your pipelines.

Rather than loading everything upfront, Flow wraps the API as **lazy operations** - each call builds a plan that fetches the data only when needed (e.g., on ``.collect()`` or ``.to_pandas()``).

‚öôÔ∏è Setup
========

Ensure your **StatsBomb credentials** are set as environment variables if you're using private access:

.. code-block:: bash

   export SB_USERNAME="your_username"
   export SB_PASSWORD="your_password"

üöÄ Getting Started
==================

.. code-block:: python

   from penaltyblog.matchflow import Flow

   # Fetch all competitions
   comps = Flow.statsbomb.competitions()

   for comp in comps.head(3):
       print(comp)

All API calls return a ``Flow``, so you can apply all usual transformations like ``.filter()``, ``.select()``, ``.assign()``, etc.

üîç Available Endpoints
======================

+-----------------------------------------------------+------------------------------------+
| Method                                              | Description                        |
+=====================================================+====================================+
| ``.competitions()``                                 | All competitions available via API |
+-----------------------------------------------------+------------------------------------+
| ``.matches(competition_id, season_id)``             | Matches for a specific season      |
+-----------------------------------------------------+------------------------------------+
| ``.events(match_id)``                               | All events in a match              |
+-----------------------------------------------------+------------------------------------+
| ``.lineups(match_id)``                              | Lineups and formation for a match  |
+-----------------------------------------------------+------------------------------------+
| ``.player_match_stats(match_id)``                   | Player-level stats for a match     |
+-----------------------------------------------------+------------------------------------+
| ``.player_season_stats(competition_id, season_id)`` | Player stats over a season         |
+-----------------------------------------------------+------------------------------------+
| ``.team_match_stats(match_id)``                     | Team stats for a match             |
+-----------------------------------------------------+------------------------------------+
| ``.team_season_stats(competition_id, season_id)``   | Team stats over a season           |
+-----------------------------------------------------+------------------------------------+

All of these return a lazy Flow

üß™ Example: Shots in a Match
============================

.. code-block:: python

   from penaltyblog.matchflow import Flow, where_equals

   shots = (
       Flow.statsbomb.events(match_id=19716)
       .filter(where_equals("type.name", "Shot"))
       .select("player.name", "location", "shot.outcome.name")
   )

   for shot in shots.head(3):
       print(shot)

üßº Filtering & Transforming
===========================

Because Flow supports deep access to nested fields, you can work directly with StatsBomb's JSON structure without needing to flatten first:

.. code-block:: python

   from penaltyblog.matchflow import Flow, where_equals

   top_scorers = (
       Flow.statsbomb.player_season_stats(competition_id=43, season_id=106)
       .filter(lambda r: r["goals"] >= 5)
       .select("player.name", "team.name", "goals")
   )

üê¢ Lazy Until Needed
====================

Remember, nothing is downloaded or processed until you **materialize the flow**:

- ``.collect()`` ‚Üí fetches all records
- ``.to_pandas()`` ‚Üí fetches and converts to DataFrame
- ``.head(n)`` ‚Üí fetches just the first n records

.. code-block:: python

   df = Flow.statsbomb.competitions().to_pandas()
   print(df)

üîí Authenticated Access
=======================

All API methods accept a creds dictionary, or you can use environment variables:

.. code-block:: python

   Flow.statsbomb.events(match_id=123, creds={"user": "...", "passwd": "..."})

üß† Tips
=======

- Useful for clubs or analysts already using StatsBomb data
- Flows can be joined with your internal data or flattened and saved
- Try ``.flatten().to_jsonl()`` to export clean JSONL for later

üìù Summary
==========

Flow's StatsBomb integration:

- ‚úÖ Keeps your data structured
- ‚úÖ Streams on demand (not loaded eagerly)
- ‚úÖ Integrates with full Flow pipeline tools
- ‚úÖ Works with both open and authenticated endpoints

Interactive Example
--------------------

For a comprehensive, hands-on demonstration of working with StatsBomb data, try the interactive Colab notebook.
The notebook walks you through loading data from the StatsBomb API, filtering it, and visualizing the results.
You can modify the code, experiment with different parameters, and see how the data change in real-time.

.. raw:: html

   <a href="https://colab.research.google.com/drive/1vctEMktiSri4zUhawT7Z3KauKprWkGtW?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
```### Tutorial: docs/matchflow/why.rst
```rst====================================================
Why Nested Data Isn't a Problem - It's the Point
====================================================

**TL;DR: Most football data pipelines flatten JSON into tables too early, losing structure and flexibility. Flow is a new engine that lets you explore and transform nested data directly - without premature normalization.**

In football (soccer) analytics, the default approach to working with data is to flatten it into tables. Whether it's passing networks, xG chains, or player event logs, we often reach for ``pandas`` or SQL to bring structure to chaos. But what if we're flattening too early - or even unnecessarily?

The ``Flow`` engine in ``penaltyblog`` takes a different path. Instead of reducing everything to rigid tables, it treats nested JSON as a first-class citizen, not a problem to fix, but a structure to embrace.

This article explores why embracing nested data opens up powerful new workflows, especially for clubs and analysts working with real-world, messy, event-based football data.

üåé The Nature of Football Data
===============================

Football data is inherently nested:

- A "pass" might contain a start and end location, a pressure flag, and a list of tags.
- A "shot" might include multiple qualifiers, an assist type, and a freeze frame of defenders.
- A "match" contains players, teams, events, substitutions, and metadata - all deeply structured.

When we flatten this data:

- We lose structure.
- We risk key collisions (e.g. player.name vs team.name).
- We make it harder to model and reason about the game.

Flatten too early, and you invite brittle pipelines and constant cleanup.

üå¨Ô∏è Why Nested Data is a Feature
=================================

1. It reflects the real world
-----------------------------

Nested structures mirror the natural hierarchy of football:

- Matches contain events
- Events have players, contexts, and outcomes
- Actions have tags, timestamps, and spatial data

Keeping this structure lets you work with the game as it's played, not just as rows in a table.

2. It's schema-flexible
-----------------------

Different providers (Opta, StatsBomb, Wyscout) use different formats. Trying to flatten these into a single table leads to endless exceptions.

A pipeline that embraces nesting can adapt:

.. code-block:: python

   flow.select("player.name", "location.x", "location.y")

Without caring if ``player`` is a dict or a flat field. This gives ``Flow`` the ability to **ingest, normalize, and transform** without overfitting.

3. It's analysis-friendly
-------------------------

Flattening forces premature decisions:

- Do I include all tags or just the first?
- How do I encode location - tuple, string, x/y?
- What if a freeze-frame includes 10 defenders?

Keeping the data nested lets you:

- Loop through freeze frames when needed
- Extract only meaningful tags
- Plot raw coordinates without munging

**You defer decisions until they actually matter.**

üß™ Why Not Just Use ``pandas.json_normalize()``?
=================================================

``pandas.json_normalize()`` is great for one-off tasks but in real pipelines, it quickly breaks down:

- It expects a consistent structure: nested fields that exist across every row.
- It can't easily handle mixed types or optional nesting (e.g. missing tags, variable-length freeze frames).
- Deep normalization requires fiddly recursive logic or multiple passes.
- You often end up with dozens of flattened columns like ``player.name``, ``player.id``, ``location.0``, ``location.1`` with no easy way to recombine them.

In short: ``pandas.json_normalize()`` is great for flattening once, but can be brittle, opaque, and hard to iterate with. ``Flow`` lets you stay close to the original structure, transform incrementally, and only flatten when you're ready.

üåü Flow: A Query Engine for Nested JSON
=========================================

**Flow is not a DataFrame - it's a stream-first, nested-data engine designed for irregular, event-based JSON.** Instead of flattening your data, it lets you query and transform nested records directly, without writing normalization boilerplate or discarding structure.

- Just point ``Flow`` at your folder of JSON files
- Chain transformations lazily (filter, assign, group_by)
- Select nested fields naturally

Output to dashboards, notebooks, or summaries without needing pandas.

.. code-block:: python

   from penaltyblog.matchflow import Flow, where_equals

   flow = (
       Flow.from_folder("data/events/")
       .filter(where_equals("type", "Shot"))
       .assign(xT=lambda r: model.predict(r))
       .select("player.name", "xT", "location")
       .to_json("shots.json")
   )

This turns your raw event data into a **queryable, schema-aware** stream, not a rigid table.

üìä When Flattening Still Helps
===============================

Of course, flattening still plays an important role - just not always at the beginning. Use it when:

- You're building reports or exports for BI tools
- You've standardized your schema
- You need fast vectorized ops (e.g. model training)

Even then, with ``Flow`` you can defer flattening until the end:

.. code-block:: python

   flow.filter(...).flatten().to_pandas()

üöÄ Final Thought: Let the Structure Work For You
=================================================

Football is complex and your data should be allowed to be, too.

With ``Flow``, you don't need to flatten first or second-guess your structure. You explore data as it is, shape it as needed, and only normalize when you're ready.

üß™ Try It Out
==============

If you've ever felt like your data tools were fighting the structure of football data, give Flow a try:

.. code-block:: bash

   pip install penaltyblog

Start with your StatsBomb data, or one of the included examples. Keep your data nested. Flatten only when you're ready.

I'd love feedback, edge cases, or ideas, especially if you break it. That's the whole point of a v1.
```### Tutorial: docs/implied/implied.rst
```rst=======================================
Implied Odds Probabilities (``implied``)
=======================================

This submodule provides a comprehensive toolkit for converting bookmaker odds into their underlying "true" probabilities. It achieves this by removing the bookmaker's margin (the overround) using various statistical methods.

The primary entry point is the ``calculate_implied()`` function, which handles all calculations and returns a structured data object.

Quick Start
===========

Here's a basic example of how to convert decimal odds into probabilities using the default ``multiplicative`` method.

.. code-block:: python

   import penaltyblog as pb

   # Odds for a Home Win, Draw, and Away Win
   odds = [2.7, 2.3, 4.4]

   result = pb.implied.calculate_implied(odds)

   print(f"Probabilities: {result.probabilities}")
   print(f"Margin: {result.margin:.4f}")
   print(f"Method Used: {result.method.value}")

.. code-block:: text

   Probabilities: [0.35873803615739097, 0.4211272598369373, 0.22013470400567173]
   Margin: 0.0324
   Method Used: multiplicative

Main Function
=============

All calculations are performed through this central function. It accepts various odds formats and allows you to specify the desired calculation method.

.. code-block:: python

   penaltyblog.implied.calculate_implied(
       odds: Union[List[float], List[str], OddsInput],
       method: Union[str, ImpliedMethod] = ImpliedMethod.MULTIPLICATIVE,
       odds_format: Union[str, OddsFormat] = OddsFormat.DECIMAL,
       market_names: Optional[List[str]] = None,
   ) -> ImpliedProbabilities

Description
-----------

Calculate implied probabilities from odds using the specified method.

**Parameters**

- **odds** (``List[float] | List[str] | OddsInput``): The odds to convert. Can be a list of values or an ``OddsInput`` object.
- **method** (``str | ImpliedMethod, optional``): The method to use. Defaults to ``"multiplicative"``.
- **odds_format** (``str | OddsFormat, optional``): The format of the provided odds. Defaults to ``"decimal"``.
- **market_names** (``List[str], optional``): Names for each market outcome.

**Returns**

``ImpliedProbabilities``: A type-safe container with the calculated probabilities and metadata.

Data Models
===========

The submodule uses type-safe dataclasses for handling odds input and probability output. This ensures your code is clear, predictable, and less prone to errors.

OddsInput
---------

The ``OddsInput`` class is used to standardize various odds formats (Decimal, American, Fractional) before calculation. While it's often used internally, you can instantiate it directly.

**Attributes**:

- **odds**: The list of original odds.
- **odds_format**: The format of the odds (e.g., ``OddsFormat.DECIMAL``).
- **market_names**: The names for each outcome.

**Methods**:

- ``to_decimal()``: Converts the stored odds to decimal format.

ImpliedProbabilities Output
---------------------------

The ``ImpliedProbabilities`` class is the return type for all calculations. It's a container holding the results and useful metadata.

**Attributes**:

- **probabilities**: A list of the calculated "true" probabilities.
- **margin**: The original margin (overround) from the bookmaker's odds.
- **method**: The method used for the calculation (e.g., ``ImpliedMethod.SHIN``).
- **market_names**: The names for each outcome.
- **method_params**: A dictionary containing any special parameters returned by the method (e.g., Shin's ``z`` or Power's ``k``).

**Properties**:

``probabilities_dict``: Returns the probabilities as a dictionary mapped to the market names.

Available Methods & Formats
============================

You can easily specify which calculation method to use and what format the input odds are in.

Calculation Methods
-------------------

The method parameter accepts a string or an ``ImpliedMethod`` enum member. Each method represents a different theory of how the bookmaker's margin is applied.

- ``MULTIPLICATIVE`` (default)
- ``ADDITIVE``
- ``POWER``
- ``SHIN``
- ``DIFFERENTIAL_MARGIN_WEIGHTING``
- ``ODDS_RATIO``
- ``LOGARITHMIC``

Odds Formats
------------

The odds_format parameter accepts a string or an ``OddsFormat`` enum member.

- ``DECIMAL`` (default)
- ``AMERICAN``
- ``FRACTIONAL``

Advanced Usage
==============

Using Different Methods and Formats
------------------------------------

Here's how to calculate probabilities from American odds using Shin's method. This example also shows how to access method-specific parameters from the result.

.. code-block:: python

   import penaltyblog as pb
   from penaltyblog.implied.models import ImpliedMethod, OddsFormat

   american_odds = ["+170", "+130", "+340"]
   market_names = ["Home", "Draw", "Away"]

   result = pb.implied.calculate_implied(
       odds=american_odds,
       method=ImpliedMethod.SHIN,
       odds_format=OddsFormat.AMERICAN,
       market_names=market_names,
   )

   print(f"Shin's Probabilities: {result.probabilities}")

   # Access method-specific parameters returned by some methods
   if result.method_params and "z" in result.method_params:
       print(f"Shin's z parameter: {result.method_params['z']:.4f}")

.. code-block:: text

   Shin's Probabilities: [0.35934391959159157, 0.42324384818283234, 0.21741223222458853]
   Shin's z parameter: 0.0162
```### Tutorial: docs/implied/index.rst
```rstImplied Odds
==============

.. raw:: html

   <a href="https://colab.research.google.com/drive/1o-tOetyWmSY_1WczN8WhWsl62Uz5T65F?usp=sharing" target="_blank">
      <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab">
   </a>
   <br><br>

Calculating implied odds from bookmaker odds is essential because bookmakers include a profit margin (overround) in their published odds, which distorts the true probabilities of match outcomes.

By removing this margin, bettors and analysts obtain more accurate estimates of the actual probabilities assigned by bookmakers.

These "implied odds" provide a clearer basis for comparing betting opportunities, evaluating the fairness of offered odds, and developing informed betting strategies or predictive models.

`penaltyblog` contains many functions for accurately extracting implied probabilities from bookmaker odds, featuring several algorithms, including Shin's method, to adjust for bookmaker margins (overrounds).

.. toctree::
   :maxdepth: 1
   :caption: Examples:

   implied
```### Tutorial: docs/generated/penaltyblog.models.BivariatePoissonGoalModel.rst
```rstÔªøpenaltyblog.models.BivariatePoissonGoalModel
============================================

.. currentmodule:: penaltyblog.models

.. autoclass:: BivariatePoissonGoalModel


   .. automethod:: __init__


   .. rubric:: Methods

   .. autosummary::

      ~BivariatePoissonGoalModel.__init__
      ~BivariatePoissonGoalModel.fit
      ~BivariatePoissonGoalModel.get_params
      ~BivariatePoissonGoalModel.load
      ~BivariatePoissonGoalModel.predict
      ~BivariatePoissonGoalModel.save





   .. rubric:: Attributes

   .. autosummary::

      ~BivariatePoissonGoalModel.params
```### Tutorial: docs/generated/penaltyblog.models.DixonColesGoalModel.rst
```rstÔªøpenaltyblog.models.DixonColesGoalModel
======================================

.. currentmodule:: penaltyblog.models

.. autoclass:: DixonColesGoalModel


   .. automethod:: __init__


   .. rubric:: Methods

   .. autosummary::

      ~DixonColesGoalModel.__init__
      ~DixonColesGoalModel.fit
      ~DixonColesGoalModel.get_params
      ~DixonColesGoalModel.load
      ~DixonColesGoalModel.predict
      ~DixonColesGoalModel.save





   .. rubric:: Attributes

   .. autosummary::

      ~DixonColesGoalModel.params
```### Tutorial: docs/generated/penaltyblog.models.FootballProbabilityGrid.rst
```rstÔªøpenaltyblog.models.FootballProbabilityGrid
==========================================

.. currentmodule:: penaltyblog.models

.. autoclass:: FootballProbabilityGrid


   .. automethod:: __init__


   .. rubric:: Methods

   .. autosummary::

      ~FootballProbabilityGrid.__init__
      ~FootballProbabilityGrid.asian_handicap
      ~FootballProbabilityGrid.total_goals





   .. rubric:: Attributes

   .. autosummary::

      ~FootballProbabilityGrid.away_win
      ~FootballProbabilityGrid.both_teams_to_score
      ~FootballProbabilityGrid.draw
      ~FootballProbabilityGrid.home_draw_away
      ~FootballProbabilityGrid.home_win
```### Tutorial: docs/generated/penaltyblog.models.NegativeBinomialGoalModel.rst
```rstÔªøpenaltyblog.models.NegativeBinomialGoalModel
============================================

.. currentmodule:: penaltyblog.models

.. autoclass:: NegativeBinomialGoalModel


   .. automethod:: __init__


   .. rubric:: Methods

   .. autosummary::

      ~NegativeBinomialGoalModel.__init__
      ~NegativeBinomialGoalModel.fit
      ~NegativeBinomialGoalModel.get_params
      ~NegativeBinomialGoalModel.load
      ~NegativeBinomialGoalModel.predict
      ~NegativeBinomialGoalModel.save





   .. rubric:: Attributes

   .. autosummary::

      ~NegativeBinomialGoalModel.params
```### Tutorial: docs/generated/penaltyblog.models.PoissonGoalsModel.rst
```rstÔªøpenaltyblog.models.PoissonGoalsModel
====================================

.. currentmodule:: penaltyblog.models

.. autoclass:: PoissonGoalsModel


   .. automethod:: __init__


   .. rubric:: Methods

   .. autosummary::

      ~PoissonGoalsModel.__init__
      ~PoissonGoalsModel.fit
      ~PoissonGoalsModel.get_params
      ~PoissonGoalsModel.load
      ~PoissonGoalsModel.predict
      ~PoissonGoalsModel.save





   .. rubric:: Attributes

   .. autosummary::

      ~PoissonGoalsModel.params
```### Tutorial: docs/generated/penaltyblog.models.WeibullCopulaGoalsModel.rst
```rstÔªøpenaltyblog.models.WeibullCopulaGoalsModel
==========================================

.. currentmodule:: penaltyblog.models

.. autoclass:: WeibullCopulaGoalsModel


   .. automethod:: __init__


   .. rubric:: Methods

   .. autosummary::

      ~WeibullCopulaGoalsModel.__init__
      ~WeibullCopulaGoalsModel.fit
      ~WeibullCopulaGoalsModel.get_params
      ~WeibullCopulaGoalsModel.load
      ~WeibullCopulaGoalsModel.predict
      ~WeibullCopulaGoalsModel.save





   .. rubric:: Attributes

   .. autosummary::

      ~WeibullCopulaGoalsModel.params
```### Tutorial: docs/generated/penaltyblog.models.ZeroInflatedPoissonGoalsModel.rst
```rstÔªøpenaltyblog.models.ZeroInflatedPoissonGoalsModel
================================================

.. currentmodule:: penaltyblog.models

.. autoclass:: ZeroInflatedPoissonGoalsModel


   .. automethod:: __init__


   .. rubric:: Methods

   .. autosummary::

      ~ZeroInflatedPoissonGoalsModel.__init__
      ~ZeroInflatedPoissonGoalsModel.fit
      ~ZeroInflatedPoissonGoalsModel.get_params
      ~ZeroInflatedPoissonGoalsModel.load
      ~ZeroInflatedPoissonGoalsModel.predict
      ~ZeroInflatedPoissonGoalsModel.save





   .. rubric:: Attributes

   .. autosummary::

      ~ZeroInflatedPoissonGoalsModel.params
```### Tutorial: docs/generated/penaltyblog.models.dixon_coles_weights.rst
```rstÔªøpenaltyblog.models.dixon\_coles\_weights
========================================

.. currentmodule:: penaltyblog.models

.. autofunction:: dixon_coles_weights
```### Tutorial: docs/generated/penaltyblog.models.goal_expectancy.rst
```rstÔªøpenaltyblog.models.goal\_expectancy
===================================

.. currentmodule:: penaltyblog.models

.. autofunction:: goal_expectancy
```
================================================================================
## Source Code SummaryMain source code for the library. This will be summarized.
### File: `penaltyblog/__init__.py`

### File: `penaltyblog/version.py`

### File: `penaltyblog/viz/__init__.py`

### File: `penaltyblog/viz/diagnostics.py`

- **Function**: `plot_trace(model, params=None, chains=True) -> go.Figure`
  - *Description*: Plot MCMC trace ("fuzzy caterpillar") for convergence diagnostics.
- **Function**: `plot_autocorr(model, params=None, max_lag=50) -> go.Figure`
  - *Description*: Plot autocorrelation function for MCMC parameters.
- **Function**: `plot_posterior(model, params=None, kind='density') -> go.Figure`
  - *Description*: Plot posterior distributions for model parameters.
- **Function**: `plot_convergence(model) -> go.Figure`
  - *Description*: Plot convergence diagnostics (R-hat and ESS) for all parameters.
- **Function**: `plot_diagnostics(model, params=None) -> go.Figure`
  - *Description*: Create a comprehensive diagnostic dashboard.
- **Function**: `_compute_autocorr(x, max_lag) -> np.ndarray`
  - *Description*: Compute autocorrelation function using FFT.
### File: `penaltyblog/viz/dimensions.py`

- **Class**: `PitchDimensions`
  - **Method**: `__init__(self, length, width, shapes=None, _scale_fn=None)`
    - *Description*: Initialize a PitchDimensions instance.
  - **Method**: `__repr__(self) -> str`
  - **Method**: `get_draw_length(self) -> float`
    - *Description*: Returns the draw length of the pitch.
  - **Method**: `get_draw_width(self) -> float`
    - *Description*: Returns the draw width of the pitch.
  - **Method**: `from_provider(cls, provider) -> 'PitchDimensions'`
    - *Description*: Returns a PitchDimensions instance for a known provider.
  - **Method**: `apply_coordinate_scaling(self, df, x='x', y='y') -> pd.DataFrame`
    - *Description*: Returns a new DataFrame with x,y scaled into the
  - **Method**: `scaled_shapes(self, target_length=None, target_width=None) -> Dict[str, Dict[str, float]]`
    - *Description*: Returns `self.shapes` with every number mapped into the
  - **Method**: `arc_radius(self, target_length=None) -> float`
    - *Description*: Returns the arc radius of the pitch.
  - **Method**: `apply_coordinate_scaling_raw(self, xs, ys) -> tuple[list[float], list[float]]`
    - *Description*: Scale x and y coordinate lists into the DRAW_LENGTH √ó DRAW_WIDTH space.
  - **Method**: `_scale_default(self, df, x, y) -> pd.DataFrame`
    - *Description*: Scales x and y coordinates using a simple linear scaling.
  - **Method**: `_scale_wyscout(self, df, x, y) -> pd.DataFrame`
    - *Description*: Scales x and y coordinates using Wyscout's coordinate system.
  - **Method**: `_scale_statsbomb(self, df, x, y) -> pd.DataFrame`
    - *Description*: Scales x and y coordinates using StatsBomb's coordinate system.
  - **Method**: `_scale_opta(self, df, x, y) -> pd.DataFrame`
    - *Description*: Scales x and y coordinates using Opta's coordinate system.
### File: `penaltyblog/viz/flow_support.py`

- **Function**: `normalize_path(path) -> str`
  - *Description*: Convert path expressions of the form location[0] into location.0, which
- **Function**: `resolve_path(record, path, default=None)`
  - *Description*: Resolve a dot-separated path in a record (which can be a dict, list, or tuple).
- **Function**: `to_records(data, fields=None) -> List[dict]`
  - *Description*: Convert a Flow, DataFrame, or list of dictionaries to a list of records.
### File: `penaltyblog/viz/pitch.py`

- **Function**: `_layered(default_layer)`
- **Class**: `Pitch`
  - **Method**: `__init__(self, provider='statsbomb', width=600, height=500, theme='minimal', orientation='horizontal', view='full', title=None, subtitle=None, subnote=None, show_axis=False, show_legend=False, show_spots=True)`
    - *Description*: Initialize a Pitch instance.
  - **Method**: `_apply_orientation_raw(self, xs, ys) -> tuple[list[float], list[float]]`
    - *Description*: Convert *lists* of x- and y-coordinates from the ‚Äúnative‚Äù horizontal
  - **Method**: `_rect(self, x0, y0, x1, y1, color) -> dict`
  - **Method**: `_circle(self, cx, cy, r, color) -> dict`
  - **Method**: `_add_layer(self, layer, item) -> None`
  - **Method**: `_apply_orientation(self, df, x='x', y='y') -> pd.DataFrame`
  - **Method**: `_prepare_hover(self, data, x, y, hover, tooltip_original=True)`
  - **Method**: `_compute_view_window(self) -> tuple[float, float, float, float]`
    - *Description*: Return axis limits (x0, x1, y0, y1) for the requested `view`,
  - **Method**: `_draw_base_pitch(self) -> None`
    - *Description*: Draws the base pitch using the theme's styling parameters. The pitch is
  - **Method**: `_draw_penalty_arcs(self) -> None`
    - *Description*: Draws the penalty arcs for both left and right penalty areas on the pitch.
  - **Method**: `_draw_spots(self) -> None`
  - **Method**: `set_layer_visibility(self, layer, visible=True) -> None`
    - *Description*: Set the visibility of a layer of traces and annotations.
  - **Method**: `remove_layer(self, name) -> None`
    - *Description*: Completely removes a layer from the figure and internal layer storage.
  - **Method**: `show(self) -> None`
    - *Description*: Render the Pitch figure in a Jupyter notebook or as an HTML file.
  - **Method**: `save(self, filename, format=None, scale=1.0, width=None, height=None) -> None`
    - *Description*: Save the figure to a file.
  - **Method**: `set_layer_order(self, order) -> None`
    - *Description*: Reorder plotting layers according to provided sequence.
  - **Method**: `_draw_titles_and_notes(self) -> None`
    - *Description*: Draws the title, subtitle, and subnote annotations on the plot using the
  - **Method**: `plot_scatter(self, data, x='x', y='y', hover=None, tooltip_original=True, size=10, color=None) -> go.Scatter`
    - *Description*: Plot a scatter of points on the pitch.
  - **Method**: `plot_heatmap(self, data, x='x', y='y', bins=(10, 8), show_colorbar=False, colorscale=None, opacity=None) -> go.Histogram2d`
    - *Description*: Plot a heatmap on the pitch.
  - **Method**: `plot_kde(self, data, x='x', y='y', grid_size=100, show_colorbar=False, colorscale=None, opacity=None) -> go.Heatmap`
    - *Description*: Plot a kernel density estimate (KDE) on the pitch.
  - **Method**: `plot_comets(self, data, x='x', y='y', x_end='x2', y_end='y2', color=None, width=6, segments=24, fade=True, hover=None, tooltip_original=False) -> List[go.Scatter]`
    - *Description*: Plot a comet trace on the pitch.
  - **Method**: `plot_arrows(self, data, x='x', y='y', x_end='x2', y_end='y2', hover=None) -> List[dict]`
    - *Description*: Plot arrows on the pitch to represent directional movement from a
### File: `penaltyblog/viz/theme.py`

- **Class**: `Theme`
  - **Method**: `__init__(self, name='minimal')`
    - *Description*: Initialize a Theme from a preset name.
  - **Method**: `pitch_color(self) -> str`
    - *Description*: The color of the pitch background.
  - **Method**: `line_color(self) -> str`
    - *Description*: The color of the pitch lines.
  - **Method**: `marker_color(self) -> str`
    - *Description*: The color of the pitch markers.
  - **Method**: `heatmap_colorscale(self) -> str`
    - *Description*: The color scale used for heatmaps.
  - **Method**: `heatmap_opacity(self) -> float`
    - *Description*: The opacity of the heatmap.
  - **Method**: `line_width(self) -> float`
    - *Description*: The width of the pitch lines.
  - **Method**: `marker_size(self) -> float`
    - *Description*: The size of the pitch markers.
  - **Method**: `spot_size(self) -> float`
    - *Description*: The size of the pitch spots.
  - **Method**: `font_family(self) -> str`
    - *Description*: The font family used for text.
  - **Method**: `hover_font_color(self) -> str`
    - *Description*: The color of the hover font.
  - **Method**: `hover_border_color(self) -> str`
    - *Description*: The color of the border of the hover box.
  - **Method**: `hover_font_family(self) -> str`
    - *Description*: The font family used for hover text.
  - **Method**: `hover_font_size(self) -> float`
    - *Description*: The font size of the hover text.
  - **Method**: `title_margin(self) -> float`
    - *Description*: The margin for the title.
  - **Method**: `subtitle_margin(self) -> float`
    - *Description*: The margin for the subtitle.
  - **Method**: `subnote_margin(self) -> float`
    - *Description*: The margin for the subnote.
  - **Method**: `subtitle_font_size(self) -> float`
    - *Description*: The font size for the subtitle.
  - **Method**: `subnote_font_size(self) -> float`
    - *Description*: The font size for the subnote.
  - **Method**: `hover_bgcolor(self) -> str`
  - **Method**: `from_dict(cls, style_dict, base='minimal') -> 'Theme'`
    - *Description*: Create a Theme instance from a dictionary of style settings.
### File: `penaltyblog/metrics/__init__.py`

### File: `penaltyblog/metrics/briar.py`

- **Function**: `multiclass_brier_score(y_prob, y_true) -> float`
  - *Description*: Calculates multiclass Brier score.
### File: `penaltyblog/metrics/ignorance.py`

- **Function**: `ignorance_score(y_prob, y_true) -> float`
  - *Description*: Calculates ignorance score, which is a measure of the uncertainty of a model's predictions.
### File: `penaltyblog/metrics/rps.py`

- **Function**: `rps_average(probs, outcomes) -> float`
  - *Description*: Computes the average Ranked Probability Score (RPS) for a batch of fixtures.
- **Function**: `rps_array(probs, outcomes) -> np.ndarray`
  - *Description*: Computes individual RPS values for each fixture.
- **Function**: `rps(probs, outcome) -> float`
  - *Description*: Calculate the Ranked Probability Score
### File: `penaltyblog/models/__init__.py`

### File: `penaltyblog/models/base_bayesian_model.py`

- **Class**: `BaseBayesianModel`
  - *Description*: Base class for Bayesian football models.
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, weights=None)`
    - *Description*: Initialize a Bayesian football model.
  - **Method**: `_map_trace_to_dict(self) -> None`
    - *Description*: Helper to convert raw matrix to user-friendly dict.
  - **Method**: `get_diagnostics(self, burn=0, thin=1) -> pd.DataFrame`
    - *Description*: Returns a DataFrame of R-hat and ESS for all parameters.
  - **Method**: `_get_tail_param_indices(self) -> Dict[str, int]`
    - *Description*: Return indices for model-specific trailing parameters.
  - **Method**: `plot_trace(self, params=None, chains=True)`
    - *Description*: Plot MCMC trace for convergence diagnostics.
  - **Method**: `plot_autocorr(self, params=None, max_lag=50)`
    - *Description*: Plot autocorrelation function for MCMC parameters.
  - **Method**: `plot_posterior(self, params=None, kind='density')`
    - *Description*: Plot posterior distributions for model parameters.
  - **Method**: `plot_convergence(self)`
    - *Description*: Plot convergence diagnostics (R-hat and ESS) for all parameters.
  - **Method**: `plot_diagnostics(self, params=None)`
    - *Description*: Create a comprehensive diagnostic dashboard.
### File: `penaltyblog/models/base_model.py`

- **Function**: `_get_cython_long_dtype()`
  - *Description*: Get the correct NumPy dtype that matches Cython's 'long' type.
- **Class**: `BaseGoalsModel`
  - *Description*: Base class for football (soccer) goals prediction models.
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, weights=None)`
    - *Description*: Initialise the BaseGoalsModel with match data.
  - **Method**: `_validate_inputs(self, n_matches)`
    - *Description*: Validate that input arrays have consistent lengths and valid values.
  - **Method**: `_setup_teams(self)`
    - *Description*: Build team lookup structures.
  - **Method**: `save(self, filepath)`
    - *Description*: Save the fitted model to disk via pickle.
  - **Method**: `load(cls, filepath) -> Any`
    - *Description*: Load a model from a pickle file.
  - **Method**: `_fit(self, loss_function, params, constraints, bounds, minimizer_options, jac=None)`
    - *Description*: Optimise model parameters using `scipy.optimize.minimize`.
  - **Method**: `fit(self, minimizer_options=None)`
    - *Description*: Fit the model to training data.
  - **Method**: `_predict(self, home_team, away_team) -> tuple[int, int]`
    - *Description*: Perform checks before predicting and return team indices.
  - **Method**: `predict(self, home_team, away_team, max_goals=15, normalize=True)`
    - *Description*: Predict outcome probabilities for a given fixture.
  - **Method**: `_compute_probabilities(self, home_idx, away_idx, max_goals, normalize=True)`
    - *Description*: Compute the probability grid for a fixture.
  - **Method**: `_get_param_names(self) -> list[str]`
    - *Description*: Return the parameter names for this model.
  - **Method**: `get_params(self) -> Dict[str, Any]`
    - *Description*: Get the fitted model parameters as a dictionary.
  - **Method**: `params(self) -> Dict[str, Any]`
    - *Description*: Fitted parameters as a property.
  - **Method**: `params_array(self) -> np.ndarray`
    - *Description*: Return a read-only copy of the fitted parameter vector.
  - **Method**: `param_indices(self) -> Dict[str, Any]`
    - *Description*: Return indices for named parameter groups in the parameter array.
  - **Method**: `_get_tail_param_indices(self) -> Dict[str, int]`
    - *Description*: Return indices for model-specific trailing parameters.
### File: `penaltyblog/models/bayesian_goal_model.py`

- **Class**: `BayesianGoalModel`
  - *Description*: Bayesian Football Model using Dixon-Coles methodology.
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, weights=None)`
    - *Description*: Initialize a Bayesian goal model.
  - **Method**: `_generate_start_positions(self, n_walkers, mle_params=None) -> np.ndarray`
    - *Description*: Generate starting positions for MCMC walkers.
  - **Method**: `fit(self, minimizer_options=None, n_samples=2000, burn=1000, n_chains=4, thin=1) -> None`
    - *Description*: Fit the model using parallel MCMC chains.
  - **Method**: `get_diagnostics(self, burn=0, thin=1) -> pd.DataFrame`
    - *Description*: Returns a DataFrame of R-hat and ESS for all parameters,
  - **Method**: `_get_initial_params(self) -> np.ndarray`
    - *Description*: Get initial parameters for MCMC sampling.
  - **Method**: `_compute_probabilities(self, home_idx, away_idx, max_goals, normalize=True) -> FootballProbabilityGrid`
    - *Description*: Compute posterior predictive probabilities for a fixture.
  - **Method**: `_get_param_names(self) -> List[str]`
    - *Description*: Return the parameter names for this model.
  - **Method**: `_get_tail_param_indices(self) -> Dict[str, int]`
    - *Description*: Return indices for model-specific trailing parameters.
### File: `penaltyblog/models/bivariate_poisson.py`

- **Class**: `BivariatePoissonGoalModel`
  - *Description*: Karlis & Ntzoufras Bivariate Poisson for soccer, with:
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, weights=None)`
    - *Description*: Initialises the BivariatePoissonGoalModel class.
  - **Method**: `__repr__(self) -> str`
  - **Method**: `_loss_function(self, params) -> float`
  - **Method**: `_gradient(self, params) -> NDArray`
    - *Description*: Compute the gradient of the negative log-likelihood.
  - **Method**: `fit(self, minimizer_options=None, use_gradient=True)`
    - *Description*: Fits the Bivariate Poisson model to the data.
  - **Method**: `_compute_probabilities(self, home_idx, away_idx, max_goals, normalize=True) -> FootballProbabilityGrid`
  - **Method**: `_get_param_names(self) -> list[str]`
  - **Method**: `_get_tail_param_indices(self) -> dict[str, int]`
  - **Method**: `get_params(self) -> ParamsOutput`
    - *Description*: Return the fitted parameters in a dictionary.
### File: `penaltyblog/models/custom_types.py`

### File: `penaltyblog/models/dixon_coles.py`

- **Class**: `DixonColesGoalModel`
  - *Description*: Dixon and Coles adjusted Poisson model for predicting outcomes of football
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, weights=None)`
    - *Description*: Dixon and Coles adjusted Poisson model for predicting outcomes of football
  - **Method**: `__repr__(self) -> str`
  - **Method**: `_get_param_names(self) -> list[str]`
  - **Method**: `_get_tail_param_indices(self) -> dict[str, int]`
  - **Method**: `_gradient(self, params)`
  - **Method**: `_loss_function(self, params) -> float`
    - *Description*: Internal method, not to called directly by the user
  - **Method**: `fit(self, minimizer_options=None, use_gradient=True)`
    - *Description*: Fits the model to the data and calculates the team strengths,
  - **Method**: `_compute_probabilities(self, home_idx, away_idx, max_goals, normalize=True) -> FootballProbabilityGrid`
### File: `penaltyblog/models/football_probability_grid.py`

- **Class**: `FootballProbabilityGrid`
  - *Description*: Probability grid over exact football (soccer) scores P(H=i, A=j).
  - **Method**: `__post_init__(self) -> None`
  - **Method**: `__repr__(self) -> str`
  - **Method**: `home_win(self) -> float`
    - *Description*: Probability of a home win (H > A).
  - **Method**: `draw(self) -> float`
    - *Description*: Probability of a draw (H = A).
  - **Method**: `away_win(self) -> float`
    - *Description*: Probability of an away win (A > H).
  - **Method**: `home_draw_away(self) -> List[float]`
    - *Description*: 1X2 probabilities as [P(Home), P(Draw), P(Away)].
  - **Method**: `btts_yes(self) -> float`
    - *Description*: Probability that both teams score (H > 0 and A > 0).
  - **Method**: `btts_no(self) -> float`
    - *Description*: Probability that NOT both teams score (at least one team scores 0).
  - **Method**: `double_chance_1x(self) -> float`
    - *Description*: Double chance 1X: P(Home or Draw).
  - **Method**: `double_chance_x2(self) -> float`
    - *Description*: Double chance X2: P(Draw or Away).
  - **Method**: `double_chance_12(self) -> float`
    - *Description*: Double chance 12: P(Home or Away).
  - **Method**: `draw_no_bet_home(self) -> float`
    - *Description*: Draw No Bet (Home) win probability, conditional on the bet not pushing.
  - **Method**: `draw_no_bet_away(self) -> float`
    - *Description*: Draw No Bet (Away) win probability, conditional on the bet not pushing.
  - **Method**: `totals(self, line) -> Tuple[float, float, float]`
    - *Description*: Compute Under/Push/Over probabilities for a totals line.
  - **Method**: `total_goals(self, over_under, strike) -> float`
    - *Description*: Backward-compatible Over/Under probability (without push).
  - **Method**: `asian_handicap_probs(self, side, line) -> Dict[str, float]`
    - *Description*: Asian handicap settlement probabilities for Win/Push/Lose.
  - **Method**: `asian_handicap(self, home_away, strike) -> float`
    - *Description*: Backward-compatible Asian handicap 'win' probability (no push).
  - **Method**: `exact_score(self, h, a) -> float`
    - *Description*: Probability of an exact scoreline.
  - **Method**: `home_goal_distribution(self) -> NDArray`
    - *Description*: Marginal distribution over home goals.
  - **Method**: `away_goal_distribution(self) -> NDArray`
    - *Description*: Marginal distribution over away goals.
  - **Method**: `total_goals_distribution(self) -> NDArray`
    - *Description*: Distribution over total goals T = H + A.
  - **Method**: `win_to_nil_home(self) -> float`
    - *Description*: Probability the home team wins to nil (A = 0 and H > 0).
  - **Method**: `win_to_nil_away(self) -> float`
    - *Description*: Probability the away team wins to nil (H = 0 and A > 0).
  - **Method**: `expected_points_home(self) -> float`
    - *Description*: Expected points for the home team under 3/1/0 scoring.
  - **Method**: `expected_points_away(self) -> float`
    - *Description*: Expected points for the away team under 3/1/0 scoring.
  - **Method**: `_sum_mask(self, key, mask) -> float`
    - *Description*: Sum grid entries under a boolean mask, with lightweight caching.
### File: `penaltyblog/models/goal_expectancy.py`

- **Function**: `goal_expectancy(home, draw, away, dc_adj=True, rho=0.001, minimizer_options=None) -> dict`
  - *Description*: Infer implied goal expectancies (mu_home, mu_away) from 1X2 probabilities.
### File: `penaltyblog/models/hierarchical_bayesian_goal_model.py`

- **Class**: `HierarchicalBayesianGoalModel`
  - *Description*: Advanced Bayesian Model with Hierarchical Priors.
  - **Method**: `fit(self, minimizer_options=None, n_samples=3000, burn=1500, n_chains=4, thin=1) -> None`
    - *Description*: Fit the hierarchical model using parallel MCMC chains.
  - **Method**: `_generate_hierarchical_starts(self, n_walkers, mle_params) -> np.ndarray`
    - *Description*: Generate starting positions including the 2 extra Sigma parameters.
  - **Method**: `_map_trace_to_dict(self) -> None`
    - *Description*: Map trace to dictionary including the new sigma parameters.
  - **Method**: `get_diagnostics(self, burn=0, thin=1) -> pd.DataFrame`
    - *Description*: Returns a DataFrame of R-hat and ESS for all parameters,
  - **Method**: `_get_param_names(self) -> List[str]`
    - *Description*: Return the parameter names for this model, including hierarchical sigmas.
  - **Method**: `_get_tail_param_indices(self) -> Dict[str, int]`
    - *Description*: Return indices for hierarchical-specific trailing parameters.
### File: `penaltyblog/models/negative_binomial.py`

- **Class**: `NegativeBinomialGoalModel`
  - *Description*: Negative Binomial model for predicting outcomes of football (soccer) matches
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, weights=None)`
    - *Description*: Initialises the NegativeBinomialGoalModel class.
  - **Method**: `__repr__(self)`
  - **Method**: `_get_param_names(self) -> list[str]`
  - **Method**: `_get_tail_param_indices(self) -> dict[str, int]`
  - **Method**: `_gradient(self, params)`
  - **Method**: `_loss_function(self, params) -> float`
    - *Description*: Calculates the negative log-likelihood of the Negative Binomial model.
  - **Method**: `fit(self, minimizer_options=None, use_gradient=True)`
    - *Description*: Fits the Negative Binomial model to the data.
  - **Method**: `_compute_probabilities(self, home_idx, away_idx, max_goals, normalize=True) -> FootballProbabilityGrid`
### File: `penaltyblog/models/poisson.py`

- **Class**: `PoissonGoalsModel`
  - *Description*: Poisson model for predicting outcomes of football (soccer) matches
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, weights=None)`
    - *Description*: Dixon and Coles adjusted Poisson model for predicting outcomes of football
  - **Method**: `__repr__(self) -> str`
  - **Method**: `_get_param_names(self) -> list[str]`
  - **Method**: `_get_tail_param_indices(self) -> dict[str, int]`
  - **Method**: `_gradient(self, params)`
  - **Method**: `_loss_function(self, params)`
    - *Description*: The loss function to be minimized.
  - **Method**: `fit(self, minimizer_options=None, use_gradient=True)`
    - *Description*: Fit the Poisson model using scipy.optimize.minimize.
  - **Method**: `_compute_probabilities(self, home_idx, away_idx, max_goals, normalize=True) -> FootballProbabilityGrid`
### File: `penaltyblog/models/utils.py`

- **Function**: `dixon_coles_weights(dates, xi=0.0018, base_date=None) -> NDArray`
  - *Description*: Calculates a decay curve based on the algorithm given by
### File: `penaltyblog/models/weibull_copula.py`

- **Class**: `WeibullCopulaGoalsModel`
  - *Description*: Weibull Copula model for predicting outcomes of football (soccer) matches
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, weights=None)`
    - *Description*: Initialises the WeibullCopulaGoalModel class.
  - **Method**: `__repr__(self) -> str`
  - **Method**: `_get_param_names(self) -> list[str]`
  - **Method**: `_get_tail_param_indices(self) -> dict[str, int]`
  - **Method**: `_loss_function(self, params) -> float`
  - **Method**: `_gradient_function(self, params) -> NDArray`
    - *Description*: Compute the gradient of the negative log-likelihood.
  - **Method**: `fit(self, minimizer_options=None, use_gradient=True)`
    - *Description*: Fits the Weibull Copula model to the data.
  - **Method**: `_compute_probabilities(self, home_idx, away_idx, max_goals, normalize=True) -> FootballProbabilityGrid`
### File: `penaltyblog/models/zero_inf_poisson.py`

- **Class**: `ZeroInflatedPoissonGoalsModel`
  - *Description*: Zero-Inflated Poisson Model for Football Goal Scoring
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, weights=None)`
    - *Description*: Initialises the ZeroInflatedPoissonGoalsModel class.
  - **Method**: `__repr__(self)`
  - **Method**: `_get_param_names(self) -> list[str]`
  - **Method**: `_get_tail_param_indices(self) -> dict[str, int]`
  - **Method**: `_loss_function(self, params) -> float`
  - **Method**: `_gradient(self, params) -> np.ndarray`
  - **Method**: `fit(self, minimizer_options=None, use_gradient=True)`
    - *Description*: Fit the Zero-Inflated Poisson model using scipy.optimize.minimize.
  - **Method**: `_compute_probabilities(self, home_idx, away_idx, max_goals, normalize=True) -> FootballProbabilityGrid`
### File: `penaltyblog/backtest/__init__.py`

### File: `penaltyblog/backtest/account.py`

- **Class**: `Account`
  - *Description*: Used to make and track bets made during the backtest
  - **Method**: `__init__(self, bankroll)`
    - *Description*: Parameters
  - **Method**: `place_bet(self, odds, stake, outcome)`
    - *Description*: Parameters
### File: `penaltyblog/backtest/backtest.py`

- **Class**: `Backtest`
  - *Description*: Used to backtest different betting strategies.
  - **Method**: `__init__(self, data, start_date, end_date, stop_at_negative=False)`
    - *Description*: Parameters
  - **Method**: `start(self, bankroll, logic, trainer=None)`
    - *Description*: Parameters
  - **Method**: `results(self) -> dict`
    - *Description*: Calculates the results of the backtest and returns them as a dict
### File: `penaltyblog/backtest/context.py`

- **Class**: `Context`
  - *Description*: Object passed into the `logic` and `trainer` functions. Contains
  - **Method**: `__init__(self, account, lookback, fixture, model=None)`
    - *Description*: Parameters
### File: `penaltyblog/utils/__init__.py`

### File: `penaltyblog/utils/deprecated.py`

- **Function**: `deprecated(reason=None)`
  - *Description*: Decorator to mark functions as deprecated. It will raise a DeprecationWarning
### File: `penaltyblog/ratings/__init__.py`

### File: `penaltyblog/ratings/colley.py`

- **Class**: `Colley`
  - *Description*: Calculates each team's Colley ratings
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away, include_draws=True, draw_weight=0.5)`
  - **Method**: `get_ratings(self) -> pd.DataFrame`
    - *Description*: Gets the Colley ratings
- **Function**: `_build_fixtures(goals_home, goals_away, teams_home, teams_away)`
- **Function**: `_solve_r(c, b)`
- **Function**: `_build_c_b(fixtures, teams, include_draws, draw_weight)`
### File: `penaltyblog/ratings/elo.py`

- **Class**: `Elo`
  - *Description*: Elo rating system implementation designed for football matches by including
  - **Method**: `__init__(self, k=20.0, home_field_advantage=100.0)`
    - *Description*: Initialize the Elo rating system with default parameters.
  - **Method**: `get_team_rating(self, team) -> float`
    - *Description*: Get the Elo rating for a team.
  - **Method**: `home_win_probability(self, home, away) -> float`
    - *Description*: Calculate the expected score for a match between two teams.
  - **Method**: `calculate_match_probabilities(self, home, away, draw_base=0.3, draw_width=200.0) -> Dict[str, float]`
    - *Description*: Predicts probabilities for home win, draw, away win.
  - **Method**: `update_ratings(self, home, away, result) -> None`
    - *Description*: Updates Elo ratings based on match result.
### File: `penaltyblog/ratings/massey.py`

- **Class**: `Massey`
  - *Description*: Calculates each team's Massey ratings
  - **Method**: `__init__(self, goals_home, goals_away, teams_home, teams_away)`
    - *Description*: Parameters
  - **Method**: `get_ratings(self) -> pd.DataFrame`
    - *Description*: Gets the Massey ratings
- **Function**: `_build_m(fixtures, teams)`
- **Function**: `_build_p(fixtures, teams)`
- **Function**: `_solve_ratings(m, p)`
- **Function**: `_solve_d(t, tr_f)`
- **Function**: `_build_t(fixtures, teams)`
- **Function**: `_build_f(fixtures, teams)`
### File: `penaltyblog/ratings/pi.py`

- **Class**: `PiRatingSystem`
  - *Description*: Pi-Rating system parameters based on
  - **Method**: `__init__(self, alpha=0.15, beta=0.1, k=0.75, sigma=1.0)`
    - *Description*: Initialize the Pi-Rating system parameters based on
  - **Method**: `initialize_team(self, team)`
    - *Description*: Initialize a team with a home and away rating of 0 if not already present.
  - **Method**: `expected_goal_difference(self, home_team, away_team) -> float`
    - *Description*: Calculate the expected goal difference based on current ratings.
  - **Method**: `diminishing_error(self, error) -> float`
    - *Description*: Apply diminishing returns to large score discrepancies.
  - **Method**: `update_ratings(self, home_team, away_team, observed_goal_difference, date=None)`
    - *Description*: Update pi-ratings based on the observed goal difference.
  - **Method**: `get_team_rating(self, team) -> float`
    - *Description*: Return the average rating of a team (home and away).
  - **Method**: `calculate_match_probabilities(self, home_team, away_team) -> dict`
    - *Description*: Calculate the probabilities of a home win, draw, and away win.
  - **Method**: `display_ratings(self)`
    - *Description*: Print the current team ratings.
### File: `penaltyblog/scrapers/__init__.py`

### File: `penaltyblog/scrapers/base_scrapers.py`

- **Class**: `BaseScraper`
  - *Description*: Base scraper that all scrapers inherit from
  - **Method**: `__init__(self, team_mappings=None)`
  - **Method**: `_check_competition(self, competition)`
  - **Method**: `list_competitions(cls) -> list`
  - **Method**: `_map_teams(self, df, columns) -> pd.DataFrame`
    - *Description*: Internal function to apply team mappings if they've been provided
- **Class**: `RequestsScraper`
  - *Description*: Base scraper that all request-based scrapers inherit from
  - **Method**: `__init__(self, team_mappings=None)`
  - **Method**: `get(self, url) -> str`
- **Class**: `TLSRequestsScraper`
  - *Description*: Base scraper for sites with Cloudflare protection.
  - **Method**: `__init__(self, team_mappings=None)`
  - **Method**: `get(self, url) -> str`
### File: `penaltyblog/scrapers/clubelo.py`

- **Class**: `ClubElo`
  - *Description*: Collects data from clubelo.com.com as pandas dataframes
  - **Method**: `__init__(self, team_mappings=None)`
  - **Method**: `_season_mapping(self, season)`
  - **Method**: `_column_name_mapping(self, df) -> pd.DataFrame`
    - *Description*: Internal function to rename columns to make consistent with other data sources
  - **Method**: `_convert_date(self, df)`
  - **Method**: `get_elo_by_date(self, date=None) -> pd.DataFrame`
    - *Description*: Get team's elo ratings on a specified date
  - **Method**: `get_elo_by_team(self, team) -> pd.DataFrame`
    - *Description*: Get team's historical elo ratings. Acceptable team names can be found using the ..
  - **Method**: `get_team_names(self) -> pd.DataFrame`
    - *Description*: Gets the names of all available teams through Club Elo
### File: `penaltyblog/scrapers/common.py`

- **Function**: `move_column_inplace(df, col, pos)`
  - *Description*: Reorder specific columns, taken from
- **Function**: `sanitize_columns(df, rename_mappings=None)`
  - *Description*: Make the columns names consistent, e.g.
- **Function**: `to_snake_case(name)`
  - *Description*: Taken from
- **Function**: `create_game_id(df)`
  - *Description*: Creates a unique id for each fixture based on datetime and team names
### File: `penaltyblog/scrapers/fbref.py`

- **Class**: `FBRef`
  - *Description*: Scrapes data from FBRef and returns as a pandas dataframes
  - **Method**: `__init__(self, competition, season, team_mappings=None)`
  - **Method**: `get(self, url) -> str`
    - *Description*: Override get method to add rate limiting.
  - **Method**: `_map_season(self, season) -> str`
    - *Description*: Internal function to map the season name
  - **Method**: `_convert_date(self, df)`
  - **Method**: `_rename_fixture_columns(self, df) -> pd.DataFrame`
    - *Description*: Internal function to rename columns to make consistent with other data sources
  - **Method**: `_drop_fixture_spacer_rows(self, df) -> pd.DataFrame`
    - *Description*: Internal function to drop the spacer rows from the fixtures df
  - **Method**: `_drop_unplayed_fixtures(self, df) -> pd.DataFrame`
    - *Description*: Internal function to drop the spacer rows from the fixtures df
  - **Method**: `_split_score(self, df) -> pd.DataFrame`
    - *Description*: Internal function to split the score column into goals_home and goals_away
  - **Method**: `_flatten_stats_col_names(self, df) -> pd.DataFrame`
    - *Description*: Internal function to flatten multi-level column names
  - **Method**: `_set_stat_col_types(self, df) -> pd.DataFrame`
    - *Description*: Internal function to set the data types for the stat columns
  - **Method**: `_player_ages(self, df) -> pd.DataFrame`
    - *Description*: Internal function to format the player ages
  - **Method**: `get_fixtures(self) -> pd.DataFrame`
    - *Description*: Gets the fixtures / results for the selected competition / season
  - **Method**: `list_stat_types(self) -> list`
  - **Method**: `get_stats(self, stat_type='standard') -> dict`
    - *Description*: Gets squad / player stats for the selected stat type
### File: `penaltyblog/scrapers/footballdata.py`

- **Class**: `FootballData`
  - *Description*: Scrapes data from football-data.co.uk as pandas dataframes
  - **Method**: `__init__(self, competition, season, team_mappings=None)`
  - **Method**: `_season_mapping(self, season)`
    - *Description*: Internal function to map season to football-data's format
  - **Method**: `_convert_date(self, df)`
  - **Method**: `get_fixtures(self) -> pd.DataFrame`
    - *Description*: Downloads the fixtures and returns them as a pandas data frame
### File: `penaltyblog/scrapers/team_mappings.py`

- **Function**: `get_example_team_name_mappings()`
### File: `penaltyblog/scrapers/understat.py`

- **Class**: `Understat`
  - *Description*: Scrapes data from understat and returns as a pandas dataframes
  - **Method**: `__init__(self, competition, season, team_mappings=None)`
  - **Method**: `_map_season(self, season) -> str`
    - *Description*: Internal function to map the season name
  - **Method**: `_convert_date(self, df)`
  - **Method**: `get_fixtures(self) -> pd.DataFrame`
    - *Description*: Gets the fixtures / results for the selected competition / season
  - **Method**: `get_shots(self, understat_id) -> pd.DataFrame`
    - *Description*: Gets the shots for the selected understat_id
  - **Method**: `get_fixture_info(self, understat_id) -> pd.DataFrame`
    - *Description*: Gets the match info for the selected understat_id
  - **Method**: `get_player_season(self, player_id) -> pd.DataFrame`
    - *Description*: Gets the season info for the selected player_id
  - **Method**: `get_player_shots(self, player_id) -> pd.DataFrame`
    - *Description*: Gets the shot data for the selected player_id
### File: `penaltyblog/betting/__init__.py`

### File: `penaltyblog/betting/arbitrage.py`

- **Class**: `ArbitrageHedgeResult`
  - *Description*: Structured result for arbitrage_hedge.
  - **Method**: `__iter__(self)`
    - *Description*: Allow unpacking like (hedge_stakes, profit) for backward compatibility.
- **Function**: `_validate_arbitrage_inputs(existing_stakes, existing_odds, hedge_odds, target_profit=None) -> None`
  - *Description*: Validate inputs for arbitrage hedge calculation.
- **Function**: `_solve_hedge_lp(existing_payouts, total_existing_stakes, hedge_odds, target_profit=None, allow_lay=False) -> Tuple[List[float], float, bool, Optional[str]]`
  - *Description*: Solve linear program to find optimal hedge stakes.
- **Function**: `_calculate_heuristic_hedges(existing_payouts, total_existing_stakes, hedge_odds, target_profit=None, tolerance=1e-10) -> Tuple[List[float], float]`
  - *Description*: Calculate hedge stakes using heuristic when LP fails.
- **Function**: `_calculate_partial_hedges(existing_stakes, existing_payouts, total_existing_stakes, hedge_odds, tolerance=1e-10) -> Tuple[List[float], float]`
  - *Description*: Calculate hedges for existing positions only (hedge_all=False).
- **Function**: `_redistribute_negative_stakes(raw_hedge_stakes, hedge_odds, allow_lay=False, tolerance=1e-10) -> List[float]`
  - *Description*: Convert negative stakes to positive stakes on other outcomes.
- **Function**: `_calculate_final_profit(existing_payouts, total_existing_stakes, practical_hedge_stakes, hedge_odds, tolerance=1e-10) -> float`
  - *Description*: Calculate the guaranteed profit with practical stakes.
- **Function**: `arbitrage_hedge(existing_stakes, existing_odds, hedge_odds, target_profit=None, hedge_all=True, allow_lay=False, tolerance=1e-10) -> ArbitrageHedgeResult`
  - *Description*: Calculate hedge bet sizes to guarantee profit or minimize loss from existing positions.
### File: `penaltyblog/betting/kelly.py`

- **Class**: `RiskMetrics`
  - *Description*: Comprehensive risk and return metrics for a betting strategy.
- **Class**: `KellyResult`
  - *Description*: Result of Kelly criterion calculation for a single bet.
- **Class**: `MultipleKellyResult`
  - *Description*: Result of Kelly criterion calculation for multiple bets.
- **Function**: `_validate_inputs(decimal_odds, true_prob, tolerance=1e-10) -> List[str]`
  - *Description*: Validate odds and probability inputs for Kelly calculations.
- **Function**: `_calculate_risk_metrics(stakes, decimal_odds, true_prob) -> RiskMetrics`
  - *Description*: Calculate comprehensive risk and return metrics for a betting strategy.
- **Function**: `kelly_criterion(decimal_odds, true_prob, fraction=1.0) -> KellyResult`
  - *Description*: Calculate optimal bet size using the Kelly Criterion with comprehensive analysis.
- **Function**: `multiple_kelly_criterion(decimal_odds, true_probs, fraction=1.0, max_total_stake=1.0, method='simultaneous', optimization_methods=['SLSQP', 'trust-constr'], tolerance=1e-10) -> MultipleKellyResult`
  - *Description*: Calculate optimal portfolio bet sizes using Kelly Criterion with comprehensive analysis.
### File: `penaltyblog/betting/odds.py`

- **Function**: `convert_odds(odds, odds_format, market_names=None) -> List[float]`
  - *Description*: Converts odds from a specified format to decimal odds.
### File: `penaltyblog/betting/value_bets.py`

- **Class**: `ValueBetResult`
  - *Description*: Result of value bet analysis for a single bet.
- **Class**: `MultipleValueBetResult`
  - *Description*: Result of value bet analysis for multiple bets.
- **Class**: `ArbitrageResult`
  - *Description*: Result of arbitrage opportunity analysis across multiple bookmakers.
- **Function**: `_calculate_implied_probability(decimal_odds) -> float`
  - *Description*: Calculate implied probability from decimal odds.
- **Function**: `_calculate_expected_value(decimal_odds, estimated_prob) -> float`
  - *Description*: Calculate expected value of a bet.
- **Function**: `_calculate_kelly_stake(decimal_odds, estimated_prob) -> float`
  - *Description*: Calculate optimal Kelly stake for a value bet.
- **Function**: `identify_value_bet(bookmaker_odds, estimated_probability, kelly_fraction=1.0, min_edge_threshold=0.0) -> Union[ValueBetResult, MultipleValueBetResult]`
  - *Description*: Identify value bets by comparing bookmaker odds to estimated true probabilities.
- **Function**: `calculate_bet_value(bookmaker_odds, estimated_probability) -> float`
  - *Description*: Calculate the expected value of a bet as a simple utility function.
- **Function**: `find_arbitrage_opportunities(bookmaker_odds_list, outcome_labels=None) -> ArbitrageResult`
  - *Description*: Find arbitrage opportunities across multiple bookmakers for the same event.
### File: `penaltyblog/fpl/__init__.py`

### File: `penaltyblog/fpl/fpl.py`

- **Function**: `get_current_gameweek() -> int`
  - *Description*: Gets the current active gameweek
- **Function**: `get_gameweek_info() -> pd.DataFrame`
  - *Description*: Fetches data on the weekly events, e.g. most captained player, highest scoring player etc
- **Function**: `get_player_id_mappings() -> pd.DataFrame`
  - *Description*: Fetches data mapping player names to IDs
- **Function**: `get_player_data() -> pd.DataFrame`
  - *Description*: Fetches top level data on all players, e.g. total points, total minutes played etc
- **Function**: `get_player_history(player_id) -> pd.DataFrame`
  - *Description*: Fetches player's history for current season
- **Function**: `get_rankings(page=1) -> pd.DataFrame`
  - *Description*: Fetches a given page of fpl rankings. Each page contains 50 results,
- **Function**: `get_entry_picks_by_gameweek(entry_id, gameweek=1) -> pd.DataFrame`
  - *Description*: Fetches the details for an entry's team on a given week
- **Function**: `get_entry_transfers(entry_id) -> Optional[pd.DataFrame]`
  - *Description*: Gets the transfer history for a given entry for the current season
- **Function**: `optimise_team(formation='2-5-5-3', budget=100) -> Tuple[dict, pd.DataFrame]`
  - *Description*: Gets the optimal team by maximising the total points based on formatation and budget
### File: `penaltyblog/matchflow/__init__.py`

### File: `penaltyblog/matchflow/aggregates.py`

- **Function**: `count(field=None)`
- **Function**: `count_nonnull(field)`
- **Function**: `sum_(field)`
- **Function**: `mean_(field)`
- **Function**: `min_(field)`
- **Function**: `max_(field)`
- **Function**: `std_(field)`
- **Function**: `median_(field)`
- **Function**: `range_(field)`
- **Function**: `iqr_(field)`
- **Function**: `percentile_(field, q)`
- **Function**: `mode_(field)`
- **Function**: `first_(field)`
- **Function**: `last_(field)`
- **Function**: `unique(field)`
- **Function**: `list_(field)`
- **Function**: `all_(field)`
- **Function**: `any_(field)`
- **Function**: `_safe_get(record, field)`
### File: `penaltyblog/matchflow/aggs_registry.py`

- **Class**: `AggRegistry`
  - **Method**: `__init__(self)`
  - **Method**: `register(self, name=None)`
  - **Method**: `get_factory(self, name)`
  - **Method**: `keys(self)`
- **Function**: `resolve_aggregator(value, alias)`
  - *Description*: Resolve an aggregator definition into a callable that accepts rows.
### File: `penaltyblog/matchflow/executor.py`

- **Function**: `is_materializing_op(op_name) -> bool`
  - *Description*: Returns True if the operation is expected to materialize or buffer records
- **Class**: `FlowExecutor`
  - **Method**: `__init__(self, plan)`
  - **Method**: `execute(self)`
### File: `penaltyblog/matchflow/flow.py`

- **Function**: `_handle_missing_dependency(path) -> None`
  - *Description*: Check if required cloud storage dependencies are installed and provide helpful error messages.
- **Class**: `Flow`
  - **Method**: `__init__(self, plan=None, optimize=False)`
  - **Method**: `__eq__(self, other)`
  - **Method**: `__iter__(self)`
  - **Method**: `__len__(self)`
  - **Method**: `__repr__(self)`
  - **Method**: `_next(self, op) -> 'Flow'`
  - **Method**: `from_folder(path, optimize=False, storage_options=None) -> 'Flow'`
    - *Description*: Create a Flow from a folder of records.
  - **Method**: `from_json(path, optimize=False, storage_options=None) -> 'Flow'`
    - *Description*: Lazily load a list of records from a JSON file.
  - **Method**: `from_jsonl(path, optimize=False, storage_options=None) -> 'Flow'`
    - *Description*: Lazily load records from a JSONL file.
  - **Method**: `from_glob(pattern, optimize=False, storage_options=None) -> 'Flow'`
    - *Description*: Create a Flow from a glob pattern.
  - **Method**: `from_list(records, optimize=False, storage_options=None) -> 'Flow'`
    - *Description*: Create a Flow from a list of records.
  - **Method**: `from_records(records, optimize=False) -> 'Flow'`
    - *Description*: Create a Flow from a list of records.
  - **Method**: `to_json(self, path, indent=4, storage_options=None)`
    - *Description*: Write the flow to a JSON file (as a list of records).
  - **Method**: `to_jsonl(self, path, storage_options=None)`
    - *Description*: Write the flow to a JSONL file (one record per line).
  - **Method**: `to_pandas(self) -> pd.DataFrame`
    - *Description*: Collect the flow into a pandas DataFrame.
  - **Method**: `count(self) -> int`
    - *Description*: Count the number of records in the flow.
  - **Method**: `is_empty(self) -> bool`
    - *Description*: Check if the flow yields any records without fully collecting it.
  - **Method**: `filter(self) -> 'Flow'`
  - **Method**: `assign(self) -> 'Flow'`
    - *Description*: Assign new fields to each record.
  - **Method**: `select(self) -> 'Flow'`
    - *Description*: Select specific fields from each record.
  - **Method**: `flatten(self) -> 'Flow'`
    - *Description*: Flatten nested dictionaries into a single-level dictionary using dot notation.
  - **Method**: `distinct(self) -> 'Flow'`
    - *Description*: Remove duplicate records.
  - **Method**: `rename(self)`
    - *Description*: Rename keys in each record according to mapping of old=new.
  - **Method**: `group_by(self) -> 'FlowGroup'`
    - *Description*: Group records by one or more fields.
  - **Method**: `grouped(self, key)`
    - *Description*: Group records by a single field.
  - **Method**: `summary(self, aggregators) -> 'Flow'`
    - *Description*: Supports:
  - **Method**: `sort_by(self) -> 'Flow'`
    - *Description*: Sort records by one or more fields.
  - **Method**: `limit(self, n) -> 'Flow'`
    - *Description*: Limit the number of records returned.
  - **Method**: `head(self, n=5) -> list`
    - *Description*: Runs the flow and returns the first n records.
  - **Method**: `show(self, n=5, format='table')`
    - *Description*: Print the first `n` records in a pretty format.
  - **Method**: `keys(self, limit=100) -> set[str]`
    - *Description*: Infer the schema of the flow.
  - **Method**: `drop(self) -> 'Flow'`
    - *Description*: Drop one or more fields from each record. Supports dot notation for nested fields.
  - **Method**: `dropna(self) -> 'Flow'`
    - *Description*: Drop records where any of the specified fields are None or missing.
  - **Method**: `concat(self) -> 'Flow'`
    - *Description*: Concatenate this flow with one or more other flows.
  - **Method**: `explode(self) -> 'Flow'`
    - *Description*: Explode one or more list fields into multiple records (in sync).
  - **Method**: `join(self, other, on=None, left_on=None, right_on=None, how='left', lsuffix='', rsuffix='_right', type_coercion='strict') -> 'Flow'`
    - *Description*: Join with another Flow.
  - **Method**: `split_array(self, field, into) -> 'Flow'`
    - *Description*: Split an array field into separate fields by index.
  - **Method**: `pivot(self, index, columns, values) -> 'Flow'`
    - *Description*: Pivot records: turn row values into columns.
  - **Method**: `cache(self) -> 'Flow'`
    - *Description*: Cache the records in memory.
  - **Method**: `explain(self, optimize=None, compare=False)`
    - *Description*: Print a readable version of the plan.
  - **Method**: `collect(self, optimize=None, progress=None, total_records=None) -> list`
    - *Description*: Collect all records from the flow.
  - **Method**: `schema(self, n=100) -> dict[str, type]`
    - *Description*: Infer the schema of the flow.
  - **Method**: `with_schema(self, schema, strict=False, drop_extra=False) -> 'Flow'`
    - *Description*: Cast fields to specified types/functions and optionally validate or prune fields.
  - **Method**: `cast(self) -> 'Flow'`
    - *Description*: Cast fields to specified types or functions.
  - **Method**: `sample_fraction(self, p, seed=None) -> 'Flow'`
    - *Description*: Lazily sample a fraction of records.
  - **Method**: `sample_n(self, n, seed=None) -> 'Flow'`
    - *Description*: Lazily sample n records using reservoir sampling.
  - **Method**: `map(self, func) -> 'Flow'`
    - *Description*: Apply a function to each record. Should return a full record. If the function returns None,
  - **Method**: `pipe(self, func) -> 'Flow'`
    - *Description*: Lazily apply a function to this Flow and return the resulting Flow.
  - **Method**: `query(self, expr)`
    - *Description*: Filter rows using query string
  - **Method**: `plot_plan(self, compare=False)`
    - *Description*: Visualize the flow plan.
  - **Method**: `profile(self, optimize=None, fmt='table')`
    - *Description*: Profile each step in the plan. Returns a report of
  - **Method**: `get_url(self) -> str`
    - *Description*: For a Flow created from an API source (e.g. Opta),
### File: `penaltyblog/matchflow/group.py`

- **Class**: `FlowGroup`
  - *Description*: A FlowGroup is a collection of records grouped by one or more keys.
  - **Method**: `__init__(self, plan, optimize=False)`
    - *Description*: Args:
  - **Method**: `__iter__(self)`
    - *Description*: Iterate over the groups.
  - **Method**: `summary(self, aggregators) -> Flow`
    - *Description*: Apply group-summary without eagerly optimizing previous steps.
  - **Method**: `sort_by(self) -> 'FlowGroup'`
    - *Description*: Sort the groups by one or more fields.
  - **Method**: `cumulative(self, field, alias=None) -> Flow`
    - *Description*: Apply group-cumulative without eagerly optimizing previous steps.
  - **Method**: `rolling_summary(self, window, aggregators, time_field=None, min_periods=1, step=None)`
    - *Description*: Lazily apply a rolling summary within each group in a FlowGroup.
  - **Method**: `time_bucket(self, freq, aggregators, time_field, label='left', bucket_name='bucket') -> Flow`
    - *Description*: Create fixed (non-overlapping) time buckets of size `freq` (e.g. "5m") and
  - **Method**: `select(self) -> 'FlowGroup'`
    - *Description*: Select specific fields from each record.
  - **Method**: `to_flow(self) -> Flow`
    - *Description*: Convert the FlowGroup to a Flow.
  - **Method**: `collect(self) -> List[Dict[str, Any]]`
    - *Description*: Collect the FlowGroup into a list of records.
  - **Method**: `plot_plan(self, compare=False)`
    - *Description*: Visualize the flow group plan.
  - **Method**: `explain(self, optimize=None, compare=False)`
    - *Description*: Explain the plan.
### File: `penaltyblog/matchflow/helpers.py`

- **Function**: `get_field(path, default=None) -> Callable[[Optional[dict[Any, Any]]], Any]`
  - *Description*: Safely access a nested field using dot notation.
- **Function**: `resolve_path(record, path, default=None)`
  - *Description*: Safely access a nested field using dot notation.
- **Function**: `get_index(path, index, default=None) -> Callable[[Optional[dict[Any, Any]]], Any]`
  - *Description*: Safely access an index in a nested list using dot-separated path.
- **Function**: `where_equals(path, value) -> Callable[[dict], bool]`
  - *Description*: Create a predicate that checks if a nested field equals a given value.
- **Function**: `where_in(path, values) -> Callable[[dict], bool]`
  - *Description*: Create a predicate that checks if a nested field is in a list of values.
- **Function**: `where_exists(path) -> Callable[[dict], bool]`
  - *Description*: Check if a nested field exists and is not None.
- **Function**: `where_not_none(path) -> Callable[[dict], bool]`
  - *Description*: Check if a nested field exists and is not None (alias of where_exists).
- **Function**: `combine_fields(out_field) -> Callable`
  - *Description*: Combine multiple fields into a single field.
- **Function**: `coalesce() -> Callable`
  - *Description*: Return the first non-None value from a list of paths.
- **Function**: `set_path(record, path, value)`
  - *Description*: Set a nested field using dot notation. Creates intermediate dicts.
- **Function**: `delete_path(record, path)`
  - *Description*: Delete a nested field using dot notation. Silently does nothing if path doesn't exist.
- **Function**: `explain_plan(raw_plan, optimized_plan=None, compare=False, indent=2)`
  - *Description*: Print a plan. If compare=True and optimized_plan is given,
- **Function**: `show_tabular(sample) -> None`
  - *Description*: Show a tabular representation of a sample of records.
### File: `penaltyblog/matchflow/opta_helpers.py`

- **Function**: `where_opta_event(event_name)`
  - *Description*: Creates a predicate to filter Opta events by their type NAME(s).
- **Function**: `where_opta_qualifier(qualifier_name, value=None)`
  - *Description*: Creates a predicate to filter Opta events based on the presence
- **Function**: `get_opta_mappings() -> dict`
  - *Description*: Returns the available Opta event and qualifier names and their IDs.
### File: `penaltyblog/matchflow/opta_mappings.py`

### File: `penaltyblog/matchflow/optimizer.py`

- **Class**: `FlowOptimizer`
  - *Description*: Optimizer for a flow plan.
  - **Method**: `__init__(self, plan)`
  - **Method**: `_is_order_sensitive(self, op) -> bool`
  - **Method**: `_blocks_filter_pushdown(self, op) -> bool`
  - **Method**: `optimize(self)`
  - **Method**: `_optimize_once(self, plan)`
  - **Method**: `_get_fields_used(self, step)`
  - **Method**: `_compute_required_fields(self, plan)`
  - **Method**: `_is_already_early_enough(self, plan, index)`
  - **Method**: `_pushdown_select_drop(self, plan)`
  - **Method**: `_annotate_moves(self, plan)`
  - **Method**: `_eliminate_redundant_steps(self, plan)`
  - **Method**: `_pushdown_filters(self, plan)`
  - **Method**: `_pushdown_limit(self, plan)`
  - **Method**: `_fuse_map_assign_filter(self, plan)`
  - **Method**: `_validate_rolling_has_sort(self, plan)`
### File: `penaltyblog/matchflow/plotting.py`

- **Function**: `_to_nx_graph(plan)`
- **Function**: `_vertical_layout(G, spacing=2.5)`
- **Function**: `plot_plan(plan, ax, title='')`
- **Function**: `plot_flow_plan(plan, optimize=False, compare=False, title_prefix='')`
  - *Description*: Helper to visualize a plan (single or compare mode), optionally optimizing.
### File: `penaltyblog/matchflow/predicates.py`

- **Class**: `Predicate`
  - **Method**: `__call__(self, record) -> bool`
  - **Method**: `__and__(self, other)`
  - **Method**: `__or__(self, other)`
  - **Method**: `__invert__(self)`
- **Class**: `FieldPredicate`
  - **Method**: `__init__(self, field, fn)`
  - **Method**: `__call__(self, record) -> bool`
  - **Method**: `__repr__(self)`
- **Class**: `NotPredicate`
  - **Method**: `__init__(self, pred)`
  - **Method**: `__call__(self, record) -> bool`
  - **Method**: `__repr__(self)`
- **Class**: `AndPredicate`
  - **Method**: `__init__(self)`
  - **Method**: `__call__(self, record) -> bool`
  - **Method**: `__repr__(self)`
- **Class**: `OrPredicate`
  - **Method**: `__init__(self)`
  - **Method**: `__call__(self, record) -> bool`
  - **Method**: `__repr__(self)`
### File: `penaltyblog/matchflow/predicates_helpers.py`

- **Function**: `_ensure_scalar_or_raise(v, field)`
- **Function**: `_ensure_comparable_or_raise(v, field, threshold)`
  - *Description*: Ensure that v and threshold are comparable types.
- **Function**: `_normalize_for_comparison(v, threshold)`
  - *Description*: Normalize values for comparison, handling date/datetime conversion.
- **Function**: `where_equals(field, value)`
- **Function**: `where_not_equals(field, value)`
- **Function**: `where_in(field, values)`
- **Function**: `where_not_in(field, values)`
- **Function**: `where_contains(field, substring)`
- **Function**: `where_startswith(field, prefix)`
- **Function**: `where_endswith(field, suffix)`
- **Function**: `where_exists(field)`
- **Function**: `where_is_null(field)`
- **Function**: `where_gt(field, threshold)`
- **Function**: `where_gte(field, threshold)`
- **Function**: `where_lt(field, threshold)`
- **Function**: `where_lte(field, threshold)`
- **Function**: `where_regex_match(field, pattern, flags=0)`
  - *Description*: Create a predicate that tests if a field matches a regex pattern.
- **Function**: `and_()`
- **Function**: `or_()`
- **Function**: `not_(pred)`
### File: `penaltyblog/matchflow/query.py`

- **Function**: `parse_query_expr(expr, local_vars) -> Callable`
  - *Description*: Parses a query string with @var references into a predicate.
- **Function**: `_parse_field_expr(node) -> Tuple[str, Callable | None]`
  - *Description*: Parses a node that can be a field or a simple method call on a field.
- **Function**: `_convert_ast(node, local_vars=None)`
  - *Description*: Convert an AST node into a Predicate.
- **Function**: `_extract_field(node)`
  - *Description*: Extract a field name from an AST node.
- **Function**: `_eval_literal(node, local_vars=None)`
  - *Description*: Evaluate a literal AST node, possibly resolving variables from `local_vars`.
### File: `penaltyblog/matchflow/contrib/__init__.py`

### File: `penaltyblog/matchflow/contrib/opta.py`

- **Function**: `_format_opta_datetime(dt) -> str`
  - *Description*: Format a datetime/date object or string into Opta's required Z-format.
- **Function**: `_format_opta_date(dt) -> str`
  - *Description*: Format a datetime/date object or string into Opta's required YYYY-MM-DD format.
- **Class**: `Opta`
  - *Description*: A lazy Flow builder for the Stats Perform (Opta) Soccer API.
  - **Method**: `DEFAULT_CREDS(self) -> dict`
    - *Description*: Get default credentials from environment variables.
  - **Method**: `BASE_URL(self) -> str`
    - *Description*: Get base URL from environment variables.
  - **Method**: `ASSET_TYPE(self) -> str`
    - *Description*: Get asset type (constant for now).
  - **Method**: `_step(self, source, optimize=False) -> 'Flow'`
    - *Description*: Internal helper to build a lazy Flow plan for Opta API requests.
  - **Method**: `tournament_calendars(self, status='all', competition_uuid=None, contestant_uuid=None, include_stages=False, include_coverage=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw tournament calendar data (Feed OT2).
  - **Method**: `venues(self, tournament_calendar_uuid=None, contestant_uuid=None, venue_uuid=None, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw venue data (Feed OT3).
  - **Method**: `areas(self, area_uuid=None, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw area data (Feed OT4).
  - **Method**: `tournament_schedule(self, tournament_calendar_uuid, coverage_level=None, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw tournament schedule data (Feed MA0).
  - **Method**: `matches(self, fixture_uuids=None, tournament_calendar_uuid=None, competition_uuids=None, contestant_uuid=None, opponent_uuid=None, contestant_position=None, date_from=None, date_to=None, delta_timestamp=None, live=True, lineups=False, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw match data (Feed MA1 - Basic).
  - **Method**: `match(self, fixture_uuid, live=False, lineups=False, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw data for a single match (Feed MA1 - Basic).
  - **Method**: `match_stats_player(self, fixture_uuids, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw player match stats data (Feed MA2 - Basic).
  - **Method**: `match_stats_team(self, fixture_uuids, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw team match stats data (Feed MA2 - Basic).
  - **Method**: `events(self, fixture_uuid, contestant_uuid=None, person_uuid=None, event_types=None, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw match events data (Feed MA3).
  - **Method**: `pass_matrix(self, fixture_uuid, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw pass matrix and average formation data (Feed MA4).
  - **Method**: `possession(self, fixture_uuid, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw possession and territorial advantage data (Feed MA5).
  - **Method**: `player_career(self, person_uuid=None, contestant_uuid=None, active=True, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw player career data (Feed PE2).
  - **Method**: `referees(self, person_uuid=None, tournament_calendar_uuid=None, stage_uuid=None, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw referee data (Feed PE3).
  - **Method**: `rankings(self, tournament_calendar_uuid, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw rankings data (Feed PE4).
  - **Method**: `injuries(self, person_uuid=None, tournament_calendar_uuid=None, contestant_uuid=None, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw player injury data (Feed PE7).
  - **Method**: `transfers(self, person_uuid=None, contestant_uuid=None, competition_uuid=None, tournament_calendar_uuid=None, start_date=None, end_date=None, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw player transfer data (Feed TM7).
  - **Method**: `teams(self, tournament_calendar_uuid=None, contestant_uuid=None, country_uuid=None, stage_uuid=None, series_uuid=None, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw team data (Feed TM1).
  - **Method**: `team_standings(self, tournament_calendar_uuid, stage_uuid=None, live=False, type=None, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw team standings data (Feed TM2).
  - **Method**: `squads(self, tournament_calendar_uuid=None, contestant_uuid=None, use_opta_names=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of raw squad data (Feed TM3).
  - **Method**: `player_season_stats(self, tournament_calendar_uuid, contestant_uuid, detailed=True, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of cumulative player stats for a season (Feed TM4).
  - **Method**: `team_season_stats(self, tournament_calendar_uuid, contestant_uuid=None, detailed=True, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of cumulative team stats for a season (Feed TM4).
  - **Method**: `contestant_participation(self, contestant_uuid=None, active=False, creds=None, proxies=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow of contestant participation data (Feed TM16).
### File: `penaltyblog/matchflow/contrib/statsbomb.py`

- **Class**: `StatsBomb`
  - **Method**: `DEFAULT_CREDS(self) -> dict`
    - *Description*: Get default credentials from environment variables.
  - **Method**: `_step(self, source, optimize=False) -> 'Flow'`
    - *Description*: Build a plan that represents a single StatsBomb source operation and
  - **Method**: `competitions(self, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow for competitions from StatsBomb.
  - **Method**: `matches(self, competition_id, season_id, creds=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow for matches from StatsBomb.
  - **Method**: `events(self, match_id, include_360_metrics=False, creds=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow for events from StatsBomb.
  - **Method**: `lineups(self, match_id, creds=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow for player lineups for a given match.
  - **Method**: `player_match_stats(self, match_id, creds=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow for per-player statistics for a single match.
  - **Method**: `player_season_stats(self, competition_id, season_id, creds=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow for per-player aggregated statistics for a season.
  - **Method**: `team_match_stats(self, match_id, creds=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow for team-level statistics for a single match.
  - **Method**: `team_season_stats(self, competition_id, season_id, creds=None, optimize=False) -> 'Flow'`
    - *Description*: Return a Flow for team-level aggregated statistics for a season.
### File: `penaltyblog/matchflow/steps/__init__.py`

### File: `penaltyblog/matchflow/steps/group.py`

- **Function**: `get_time_window_details(window, time_field) -> Tuple[bool, Optional[int], Optional[float], Optional[datetime], bool]`
  - *Description*: Determine the mode (count or time) and parse the window size.
- **Function**: `apply_group_rolling_summary(records, step) -> Iterator[dict[str, Any]]`
  - *Description*: Lazily apply a rolling summary within each group.
- **Function**: `parse_window_size(window_str) -> float`
  - *Description*: Parse a window size string like '5m', '10m', '1h', '30s', '1d' to seconds (float).
- **Function**: `apply_group_time_bucket(records, step) -> Iterator[dict[str, Any]]`
  - *Description*: Assign each record in a group to a fixed, non-overlapping time bin.
- **Function**: `apply_group_by(records, step) -> Iterator[dict[str, Any]]`
  - *Description*: Group records by one or more fields.
- **Function**: `apply_group_summary(records, step) -> Iterator[dict[str, Any]]`
  - *Description*: Apply a summary function to each group of records.
- **Function**: `apply_group_cumulative(records, step) -> Iterator[dict[str, Any]]`
  - *Description*: Apply a cumulative sum to a field for each group of records.
### File: `penaltyblog/matchflow/steps/source.py`

- **Function**: `_handle_missing_dependency(path) -> None`
  - *Description*: Check if required cloud storage dependencies are installed and provide helpful error messages.
- **Function**: `dispatch(step) -> Iterator[Dict[Any, Any]]`
- **Function**: `from_folder(step) -> Iterator[Dict[Any, Any]]`
  - *Description*: Create a Flow from a folder of JSON or JSONL files.
- **Function**: `from_json(step) -> Iterator[Dict[Any, Any]]`
  - *Description*: Create a Flow from a JSON file.
- **Function**: `from_jsonl(step) -> Iterator[Dict[Any, Any]]`
  - *Description*: Create a Flow from a JSONL file.
- **Function**: `from_glob(step) -> Iterator[Dict[Any, Any]]`
  - *Description*: Create a Flow from a glob pattern.
- **Function**: `from_concat(step) -> Iterator[Dict[Any, Any]]`
  - *Description*: Create a Flow from a list of plans.
### File: `penaltyblog/matchflow/steps/source_opta.py`

- **Function**: `from_opta(step) -> Iterator[Dict[Any, Any]]`
  - *Description*: Create a Flow from an Opta API endpoint, handling pagination.
- **Function**: `_handle_paginated_endpoint(client, source, url, params, headers) -> Iterator[Dict[str, Any]]`
  - *Description*: Handle paginated endpoints using the paginator.
- **Function**: `_handle_non_paginated_endpoint(client, source, url, params, headers, args) -> Iterator[Dict[str, Any]]`
  - *Description*: Handle non-paginated endpoints with appropriate parsing.
### File: `penaltyblog/matchflow/steps/source_statsbomb.py`

- **Function**: `from_statsbomb(step) -> Iterator[Dict[Any, Any]]`
  - *Description*: Create a Flow from a StatsBomb API endpoint.
### File: `penaltyblog/matchflow/steps/transform.py`

- **Function**: `_coerce_join_key(value, strategy='strict')`
  - *Description*: Coerce a join key value for consistent comparison across data types.
- **Function**: `apply_filter(records, step) -> RecordStream`
  - *Description*: Filter records based on a predicate.
- **Function**: `apply_assign(records, step) -> RecordStream`
  - *Description*: Assign new fields to each record.
- **Function**: `apply_select(records, step) -> RecordStream`
  - *Description*: Select specific fields from each record.
- **Function**: `_del_nested(d, parts) -> None`
  - *Description*: Delete a nested key from a dict given a list of parts.
- **Function**: `_set_nested(d, parts, value) -> None`
  - *Description*: Set a nested key in a dict given a list of parts.
- **Function**: `apply_rename(records, step) -> RecordStream`
  - *Description*: Rename fields in each record.
- **Function**: `apply_sort(records, step) -> RecordStream`
  - *Description*: Sort records based on a list of keys.
- **Function**: `_invert(value)`
- **Function**: `apply_limit(records, step) -> RecordStream`
  - *Description*: Limit the number of records.
- **Function**: `apply_drop(records, step) -> RecordStream`
  - *Description*: Drop specified fields from each record.
- **Function**: `apply_flatten(records, step) -> RecordStream`
  - *Description*: Flatten nested dictionaries into a single-level dictionary using dot notation.
- **Function**: `apply_distinct(records, step) -> RecordStream`
- **Function**: `_record_identity(record, keys)`
- **Function**: `_distinct_first(records, keys)`
- **Function**: `_distinct_last(records, keys)`
- **Function**: `apply_dropna(records, step) -> RecordStream`
  - *Description*: Drop records with missing values.
- **Function**: `apply_explode(records, step) -> RecordStream`
  - *Description*: Explode records based on a list of fields.
- **Function**: `apply_join(records, step) -> RecordStream`
  - *Description*: Join records based on a list of keys. Dispatcher function that selects the appropriate join strategy.
- **Function**: `_apply_sort_merge_join(records, step) -> RecordStream`
  - *Description*: Sort-merge join implementation for memory-efficient joins on pre-sorted data.
- **Function**: `_apply_hash_join(records, step) -> RecordStream`
  - *Description*: Hash join implementation for joining records.
- **Function**: `apply_split_array(records, step) -> RecordStream`
  - *Description*: Split an array into multiple records.
- **Function**: `apply_pivot(records, step) -> RecordStream`
  - *Description*: Pivot records based on a list of index fields.
- **Function**: `apply_summary(records, step) -> RecordStream`
  - *Description*: Apply a summary function to the records.
- **Function**: `apply_sample_fraction(records, step) -> RecordStream`
  - *Description*: Sample a fraction of the records.
- **Function**: `apply_sample_n(records, step) -> RecordStream`
  - *Description*: Sample a fixed number of records.
- **Function**: `apply_map(records, step) -> RecordStream`
  - *Description*: Apply a function to each record.
- **Function**: `apply_fused(records, step) -> RecordStream`
  - *Description*: Apply a fused sequence of map/assign/filter operations.
### File: `penaltyblog/matchflow/steps/utils.py`

- **Function**: `fast_get_field(record, parts) -> Any`
  - *Description*: Retrieve a nested value from a mapping or list using a pre-split path.
- **Function**: `get_field(record, path) -> Any`
  - *Description*: Retrieve a nested value from a mapping or list using dot-notation.
- **Function**: `get_index(field, index) -> Callable[[dict], Any]`
  - *Description*: Returns a function that extracts the `index`th value from a list field (dot path).
- **Function**: `set_nested_field(record, path, value) -> None`
  - *Description*: Set a nested field in a record using dot notation.
- **Function**: `flatten_dict(d, parent_key='', sep='.') -> dict`
  - *Description*: Flatten a nested dictionary into a single-level dictionary using dot notation.
- **Function**: `schema(records, sample_size=50) -> dict`
  - *Description*: Get the schema of a list of records.
- **Function**: `unify_types(types) -> type`
  - *Description*: Unify a set of types into a single type.
- **Function**: `reservoir_sample(iterable, k, seed=None) -> list`
  - *Description*: Sample a fixed number of records from an iterable using the reservoir sampling algorithm.
### File: `penaltyblog/matchflow/steps/opta/__init__.py`

### File: `penaltyblog/matchflow/steps/opta/client.py`

- **Class**: `OptaClient`
  - *Description*: HTTP client for making requests to the Opta API.
  - **Method**: `__init__(self, proxies=None)`
    - *Description*: Initialize the Opta client.
  - **Method**: `session(self) -> requests.Session`
    - *Description*: Get or create a requests session.
  - **Method**: `validate_credentials(self, creds) -> None`
    - *Description*: Validate that required credentials are present.
  - **Method**: `make_request(self, url, params=None, headers=None) -> Dict[str, Any]`
    - *Description*: Make a GET request to the Opta API.
  - **Method**: `close(self) -> None`
    - *Description*: Close the session.
  - **Method**: `__enter__(self)`
    - *Description*: Context manager entry.
  - **Method**: `__exit__(self, exc_type, exc_val, exc_tb)`
    - *Description*: Context manager exit.
### File: `penaltyblog/matchflow/steps/opta/config.py`

### File: `penaltyblog/matchflow/steps/opta/endpoints.py`

- **Class**: `OptaEndpointBuilder`
  - *Description*: Builds URLs and parameters for different Opta API endpoints.
  - **Method**: `__init__(self, base_url, asset_type, auth_key)`
    - *Description*: Initialize endpoint builder.
  - **Method**: `build_request_details(self, source, args) -> Tuple[str, Dict[str, Any]]`
    - *Description*: Build URL and parameters for a specific endpoint.
  - **Method**: `_build_endpoint_path(self, source, config, args) -> str`
    - *Description*: Build the endpoint path from configuration and arguments.
  - **Method**: `_extract_path_params(self, source, args) -> Dict[str, str]`
    - *Description*: Extract path parameters from arguments for a specific source.
  - **Method**: `_build_parameters(self, source, args) -> Dict[str, Any]`
    - *Description*: Build query parameters from arguments.
### File: `penaltyblog/matchflow/steps/opta/exceptions.py`

- **Class**: `OptaAPIError`
  - *Description*: Base exception for Opta API errors.
- **Class**: `OptaAuthenticationError`
  - *Description*: Raised when authentication fails (missing/invalid credentials).
- **Class**: `OptaRequestError`
  - *Description*: Raised when HTTP request fails (network issues, 4xx/5xx errors).
- **Class**: `OptaParsingError`
  - *Description*: Raised when response parsing fails.
- **Class**: `OptaConfigurationError`
  - *Description*: Raised when configuration is invalid.
### File: `penaltyblog/matchflow/steps/opta/paginator.py`

- **Class**: `OptaPaginator`
  - *Description*: Handles pagination for Opta API endpoints.
  - **Method**: `__init__(self, client)`
    - *Description*: Initialize paginator.
  - **Method**: `fetch_paginated_data(self, source, base_url, base_params, headers) -> Iterator[Dict[str, Any]]`
    - *Description*: Fetch data from a paginated endpoint.
  - **Method**: `_extract_records_from_page(self, source, data) -> List[Dict[str, Any]]`
    - *Description*: Extract records list from a paginated response.
  - **Method**: `is_paginated(source, args) -> bool`
    - *Description*: Check if a source is paginated.
### File: `penaltyblog/matchflow/steps/opta/parsers.py`

- **Function**: `flatten_stats(stats_list, key_name='type') -> Dict[str, Any]`
  - *Description*: Converts a list of {'key_name': 'name', 'value': 'val'} into a flat dict.
- **Function**: `extract_player_stats(match) -> Iterator[Dict[str, Any]]`
  - *Description*: Un-nests player stats from a MA2 match record.
- **Function**: `extract_team_stats(match) -> Iterator[Dict[str, Any]]`
  - *Description*: Un-nests team stats from a MA2 match record.
- **Function**: `extract_match_events(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Un-nests match events from a MA3 feed response.
- **Function**: `extract_season_player_stats(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Un-nests player seasonal stats from a TM4 response.
- **Function**: `extract_season_team_stats(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Un-nests team seasonal stats from a TM4 response.
- **Function**: `parse_tournament_schedule(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse tournament schedule (MA0) response.
- **Function**: `parse_match_basic(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse basic match (MA1) response.
- **Function**: `extract_contestant_participation(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Un-nests contestant participation from a TM16 response.
- **Function**: `parse_match_stats_basic(data, include_players=True) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse match stats (MA2) response.
- **Function**: `parse_match_stats_player(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse match player stats (MA2) response - only player stats.
- **Function**: `parse_match_stats_team(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse match team stats (MA2) response - only team stats.
- **Function**: `parse_area_specific(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse specific area (OT4) response.
- **Function**: `parse_player_career_person(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse specific player career (PE2) response.
- **Function**: `parse_injuries_person(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse specific player injuries (PE7) response from path parameter.
- **Function**: `parse_injuries_query(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse player injuries (PE7) response from query parameters.
- **Function**: `parse_transfers(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse player transfers (TM7) response.
- **Function**: `parse_rankings(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse rankings (PE4) response.
- **Function**: `parse_pass_matrix(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse pass matrix and average formation (MA4) response.
- **Function**: `parse_possession(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse possession and territorial advantage (MA5) response.
- **Function**: `parse_referees(data) -> Iterator[Dict[str, Any]]`
  - *Description*: Parse referees (PE3) response.
### File: `penaltyblog/bayes/__init__.py`

### File: `penaltyblog/bayes/diagnostics.py`

- **Function**: `compute_diagnostics(sampler, burn=0, thin=1, rho_threshold=0.05)`
  - *Description*: Computes R-hat and ESS for a fitted DiffEvolEnsembleSampler.
- **Function**: `_gelman_rubin(chain_data)`
  - *Description*: Calculates the classic Gelman-Rubin statistic (R-hat).
- **Function**: `_effective_sample_size(chain_data, rho_threshold=0.05)`
  - *Description*: Approximates ESS using autocorrelation.
- **Function**: `_autocorr(x)`
  - *Description*: Compute autocorrelation function using FFT for speed.
### File: `penaltyblog/bayes/sampler_api.py`

- **Function**: `_is_function_picklable(func) -> bool`
  - *Description*: Check if a function can be pickled.
- **Function**: `_worker_proxy(chain_instance) -> 'Chain'`
  - *Description*: Multiprocessing helper.
- **Class**: `Chain`
  - *Description*: Represents a single independent MCMC chain (ensemble).
  - **Method**: `__init__(self, id, seed, start_pos, data_dict, log_prob_wrapper_func, n_steps, de_move_fraction=0.8, validate_picklable=False)`
    - *Description*: Initializes the Chain.
  - **Method**: `_execute(self) -> 'Chain'`
    - *Description*: Internal method run by the subprocess.
  - **Method**: `get_samples(self, burn, thin) -> np.ndarray`
    - *Description*: Returns flattened samples for this specific chain.
  - **Method**: `trim_samples(self, burn, thin) -> np.ndarray`
    - *Description*: Discard burn-in samples and apply thinning to the raw trace.
- **Class**: `EnsembleSampler`
  - *Description*: Manages parallel execution of independent MCMC chains.
  - **Method**: `__init__(self, n_chains, n_cores, log_prob_wrapper_func, data_dict)`
    - *Description*: Initializes the EnsembleSampler.
  - **Method**: `run_mcmc(self, start_positions, n_samples, burn, de_move_fraction=0.8) -> None`
    - *Description*: Run the sampling across multiple chains in parallel.
  - **Method**: `get_posterior(self, burn=0, thin=1) -> np.ndarray`
    - *Description*: Aggregates samples from all chains.
  - **Method**: `trim_samples(self, burn, thin=1) -> np.ndarray`
    - *Description*: Trims burn-in and applies thinning to all chains, returning the combined posterior.
### File: `penaltyblog/implied/__init__.py`

### File: `penaltyblog/implied/implied.py`

- **Function**: `calculate_implied(odds, method=ImpliedMethod.MULTIPLICATIVE, odds_format=OddsFormat.DECIMAL, market_names=None) -> ImpliedProbabilities`
  - *Description*: Calculate implied probabilities from odds using the specified method.
- **Function**: `_multiplicative(odds, market_names=None) -> ImpliedProbabilities`
  - *Description*: Calculate implied probabilities using the multiplicative method.
- **Function**: `_additive(odds, market_names=None) -> ImpliedProbabilities`
  - *Description*: Calculate implied probabilities using the additive method.
- **Function**: `_power(odds, market_names=None) -> ImpliedProbabilities`
  - *Description*: Calculate implied probabilities using the power method.
- **Function**: `_shin(odds, market_names=None) -> ImpliedProbabilities`
  - *Description*: Calculate implied probabilities using Shin's method (1992, 1993).
- **Function**: `_differential_margin_weighting(odds, market_names=None) -> ImpliedProbabilities`
  - *Description*: Calculate implied probabilities using differential margin weighting.
- **Function**: `_odds_ratio(odds, market_names=None) -> ImpliedProbabilities`
  - *Description*: Calculate implied probabilities using Keith Cheung's odds ratio method.
- **Function**: `_logarithmic(odds, market_names=None) -> ImpliedProbabilities`
  - *Description*: Logarithmic method for overround removal using an additive shift.
### File: `penaltyblog/implied/models.py`

- **Class**: `OddsFormat`
  - *Description*: Supported odds formats.
- **Class**: `ImpliedMethod`
  - *Description*: Available methods for calculating implied probabilities.
- **Class**: `ImpliedProbabilities`
  - *Description*: Type-safe container for implied probability calculations.
  - **Method**: `__post_init__(self)`
    - *Description*: Validate probabilities sum approximately to 1.0.
  - **Method**: `as_percentages(self) -> List[float]`
    - *Description*: Return probabilities as percentages.
  - **Method**: `most_likely_index(self) -> int`
    - *Description*: Return index of most likely outcome.
  - **Method**: `most_likely_probability(self) -> float`
    - *Description*: Return probability of most likely outcome.
  - **Method**: `most_likely_name(self) -> Optional[str]`
    - *Description*: Return name of most likely outcome if market_names provided.
  - **Method**: `least_likely_index(self) -> int`
    - *Description*: Return index of least likely outcome.
  - **Method**: `least_likely_probability(self) -> float`
    - *Description*: Return probability of least likely outcome.
  - **Method**: `least_likely_name(self) -> Optional[str]`
    - *Description*: Return name of least likely outcome if market_names provided.
  - **Method**: `get_probability_by_name(self, name) -> float`
    - *Description*: Get probability by outcome name.
  - **Method**: `to_dict(self) -> Dict[str, Any]`
    - *Description*: Convert to legacy dict format for backward compatibility.
  - **Method**: `__getitem__(self, key) -> float`
    - *Description*: Allow indexing by position or name for backward compatibility.
  - **Method**: `__len__(self) -> int`
    - *Description*: Return number of probabilities.
- **Class**: `OddsInput`
  - *Description*: Type-safe input for odds with format specification.
  - **Method**: `to_decimal(self) -> List[float]`
    - *Description*: Convert odds to decimal format.
  - **Method**: `_american_to_decimal(american) -> float`
    - *Description*: Convert American odds to decimal.
  - **Method**: `_fractional_to_decimal(fractional) -> float`
    - *Description*: Convert fractional odds (e.g., '5/2') to decimal.

================================================================================
## Test SummaryUnit and integration tests. This will be summarized.
### File: `test/__init__.py`

### File: `test/conftest.py`

- **Function**: `vcr_config()`
- **Function**: `fixtures()`
- **Function**: `cleanup_multiprocessing()`
  - *Description*: Automatically clean up any remaining child processes after each test.
### File: `test/test_arbitrage_edge_cases.py`

- **Class**: `TestArbitrageHedgeEdgeCases`
  - *Description*: Test edge cases and input validation for arbitrage_hedge function.
  - **Method**: `test_empty_inputs_raise_error(self)`
    - *Description*: Test that empty input lists raise ValueError.
  - **Method**: `test_mismatched_input_lengths_raise_error(self)`
    - *Description*: Test that mismatched input list lengths raise ValueError.
  - **Method**: `test_invalid_existing_odds_raise_error(self)`
    - *Description*: Test that odds <= 1.0 raise ValueError.
  - **Method**: `test_invalid_hedge_odds_raise_error(self)`
    - *Description*: Test that hedge odds <= 1.0 raise ValueError.
  - **Method**: `test_negative_stakes_raise_error(self)`
    - *Description*: Test that negative existing stakes raise ValueError.
  - **Method**: `test_infinite_target_profit_raises_error(self)`
    - *Description*: Test that infinite target profit raises ValueError.
  - **Method**: `test_single_outcome_market(self)`
    - *Description*: Test behavior with single outcome (degenerate case).
  - **Method**: `test_all_zero_stakes(self)`
    - *Description*: Test behavior when all existing stakes are zero.
  - **Method**: `test_extreme_odds_high(self)`
    - *Description*: Test behavior with very high odds.
  - **Method**: `test_extreme_odds_low(self)`
    - *Description*: Test behavior with odds close to 1.0.
  - **Method**: `test_very_small_stakes(self)`
    - *Description*: Test behavior with very small stake amounts.
  - **Method**: `test_large_stakes(self)`
    - *Description*: Test behavior with very large stake amounts.
  - **Method**: `test_custom_tolerance(self)`
    - *Description*: Test behavior with custom tolerance parameter.
  - **Method**: `test_infeasible_target_profit(self)`
    - *Description*: Test behavior when target profit is infeasible.
  - **Method**: `test_negative_target_profit(self)`
    - *Description*: Test behavior with negative target profit (accepting loss).
  - **Method**: `test_hedge_all_false_with_zero_stakes(self)`
    - *Description*: Test hedge_all=False when some stakes are zero.
  - **Method**: `test_allow_lay_true_preserves_negative_stakes(self)`
    - *Description*: Test that allow_lay=True preserves negative stakes in practical_hedge_stakes.
  - **Method**: `test_profit_consistency_across_outcomes(self)`
    - *Description*: Test that profits are consistent across all outcomes (within tolerance).
  - **Method**: `test_backward_compatibility_unpacking(self)`
    - *Description*: Test that the result can still be unpacked for backward compatibility.
  - **Method**: `test_result_attributes_present(self)`
    - *Description*: Test that all expected attributes are present in the result.
  - **Method**: `test_lp_diagnostic_information(self)`
    - *Description*: Test that LP diagnostic information is properly exposed.
- **Class**: `TestNumericalStability`
  - *Description*: Test numerical stability improvements.
  - **Method**: `test_very_close_to_zero_values(self)`
    - *Description*: Test handling of values very close to zero.
  - **Method**: `test_tolerance_affects_calculations(self)`
    - *Description*: Test that tolerance parameter affects calculations.
### File: `test/test_arbitrage_lp.py`

- **Function**: `test_lp_equalizes_profits_three_way()`
- **Function**: `test_infeasible_target_sets_lp_success_false()`
- **Function**: `test_allow_lay_returns_negative_raw_when_allowed()`
### File: `test/test_backtest.py`

- **Function**: `test_backtest_simple()`
- **Function**: `test_backtest_trainer()`
### File: `test/test_bayesian_burn.py`

- **Function**: `test_bayesian_automatic_burn_thinning()`
### File: `test/test_bayesian_goal_model.py`

- **Function**: `test_bayesian_goal_model_initialization(fixtures)`
  - *Description*: Test that BayesianGoalModel can be initialized correctly.
- **Function**: `test_bayesian_goal_model_fit(fixtures)`
  - *Description*: Test that the model fits correctly and produces expected outputs.
- **Function**: `test_bayesian_goal_model_home_advantage_and_rho(fixtures)`
  - *Description*: Test that home_advantage and rho parameters are correctly estimated.
- **Function**: `test_bayesian_goal_model_get_params(fixtures)`
  - *Description*: Test that get_params returns all expected parameters.
- **Function**: `test_bayesian_goal_model_predictions(fixtures)`
  - *Description*: Test that prediction functionality works correctly.
- **Function**: `test_bayesian_goal_model_diagnostics(fixtures)`
  - *Description*: Test that diagnostics are computed correctly.
- **Function**: `test_bayesian_goal_model_unfitted_raises_error(fixtures)`
  - *Description*: Test that unfitted model raises appropriate errors.
- **Function**: `test_bayesian_goal_model_plot_trace(fixtures)`
  - *Description*: Test that plot_trace method works correctly.
- **Function**: `test_bayesian_goal_model_plot_autocorr(fixtures)`
  - *Description*: Test that plot_autocorr method works correctly.
- **Function**: `test_bayesian_goal_model_plot_posterior(fixtures)`
  - *Description*: Test that plot_posterior method works correctly.
- **Function**: `test_bayesian_goal_model_plot_convergence(fixtures)`
  - *Description*: Test that plot_convergence method works correctly.
- **Function**: `test_bayesian_goal_model_plot_diagnostics(fixtures)`
  - *Description*: Test that plot_diagnostics method works correctly.
- **Function**: `test_bayesian_goal_model_param_names(fixtures)`
  - *Description*: Test that _get_param_names returns correct parameter names.
- **Function**: `test_bayesian_goal_model_param_indices(fixtures)`
  - *Description*: Test that _get_tail_param_indices returns correct indices.
- **Function**: `test_bayesian_goal_model_params_array(fixtures)`
  - *Description*: Test that params_array property works correctly.
- **Function**: `test_bayesian_goal_model_params_property(fixtures)`
  - *Description*: Test that params property works correctly.
- **Function**: `test_bayesian_goal_model_trace_mapping(fixtures)`
  - *Description*: Test that _map_trace_to_dict correctly maps trace.
- **Function**: `test_bayesian_goal_model_custom_fit_parameters(fixtures)`
  - *Description*: Test fitting with custom sample parameters.
- **Function**: `test_bayesian_goal_model_dimension(fixtures)`
  - *Description*: Test that the model has the correct parameter dimension.
- **Function**: `test_bayesian_goal_model_save_load(fixtures, tmp_path)`
  - *Description*: Test that the model can be saved and loaded.
- **Function**: `test_bayesian_goal_model_predict_with_max_goals(fixtures)`
  - *Description*: Test prediction with custom max_goals parameter.
- **Function**: `test_bayesian_goal_model_predict_without_normalization(fixtures)`
  - *Description*: Test prediction without normalization.
- **Function**: `test_bayesian_goal_model_with_unknown_teams_raises_error(fixtures)`
  - *Description*: Test that prediction with unknown teams raises an error.
- **Function**: `test_bayesian_goal_model_average_lambdas(fixtures)`
  - *Description*: Test that prediction returns expected lambda values.
- **Function**: `test_bayesian_goal_model_team_map(fixtures)`
  - *Description*: Test that team_map is correctly initialized.
- **Function**: `test_bayesian_goal_model_comparison_with_poisson(fixtures)`
  - *Description*: Test that Bayesian model has more parameters than Poisson model.
### File: `test/test_betting_advanced.py`

- **Class**: `TestMultipleKelly`
  - *Description*: Test the multiple Kelly criterion function.
  - **Method**: `test_basic_multiple_kelly(self)`
    - *Description*: Test basic multiple Kelly calculation.
  - **Method**: `test_independent_vs_simultaneous(self)`
    - *Description*: Test different optimization methods.
  - **Method**: `test_max_total_stake_constraint(self)`
    - *Description*: Test that max total stake constraint is respected.
  - **Method**: `test_fraction_scaling(self)`
    - *Description*: Test that fraction parameter scales results correctly.
  - **Method**: `test_no_value_bets(self)`
    - *Description*: Test behavior when no bets have positive expected value.
  - **Method**: `test_validation_errors(self)`
    - *Description*: Test input validation.
- **Class**: `TestArbitrageHedge`
  - *Description*: Test the arbitrage hedging function.
  - **Method**: `test_basic_two_way_hedge(self)`
    - *Description*: Test basic two-way arbitrage hedge.
  - **Method**: `test_multiple_existing_positions(self)`
    - *Description*: Test hedging with multiple existing positions.
  - **Method**: `test_target_profit(self)`
    - *Description*: Test hedging with a specific target profit.
  - **Method**: `test_hedge_all_vs_selective(self)`
    - *Description*: Test difference between hedging all outcomes vs only existing positions.
  - **Method**: `test_no_existing_stakes(self)`
    - *Description*: Test behavior when there are no existing stakes.
  - **Method**: `test_validation_errors(self)`
    - *Description*: Test input validation for arbitrage hedge.
- **Class**: `TestIntegrationScenarios`
  - *Description*: Test realistic betting scenarios.
  - **Method**: `test_premier_league_match_scenario(self)`
    - *Description*: Test a realistic Premier League match betting scenario.
  - **Method**: `test_tennis_match_hedge_scenario(self)`
    - *Description*: Test a realistic tennis match hedging scenario.
  - **Method**: `test_arbitrage_opportunity(self)`
    - *Description*: Test a pure arbitrage opportunity across different bookmakers.
### File: `test/test_elo.py`

- **Function**: `test_initial_team_rating()`
- **Function**: `test_home_win_probability()`
- **Function**: `test_calculate_match_probabilities()`
- **Function**: `test_update_ratings_home_win()`
- **Function**: `test_update_ratings_draw()`
- **Function**: `test_update_ratings_away_win()`
- **Function**: `test_invalid_result()`
- **Function**: `test_custom_k_factor()`
- **Function**: `test_custom_home_field_advantage()`
### File: `test/test_flow.py`

- **Function**: `data()`
- **Function**: `record()`
- **Function**: `data2()`
- **Function**: `scalar_record()`
- **Function**: `list_record()`
- **Function**: `dict_record()`
- **Function**: `list_of_dicts_record()`
- **Function**: `test_plan(data)`
- **Function**: `test_flow_plan_structure(data)`
- **Function**: `test_rename(data)`
- **Function**: `test_deeply_nested_rename()`
- **Function**: `test_sort_by_ascending()`
- **Function**: `test_sort_by_descending()`
- **Function**: `test_sort_by_mixed_directions()`
- **Function**: `test_limit_records()`
- **Function**: `test_drop_fields()`
- **Function**: `test_select_preserves_structure()`
- **Function**: `test_flatten_nested_record()`
- **Function**: `test_distinct_keep_last()`
- **Function**: `test_distinct_keep_first()`
- **Function**: `test_dropna_specific_fields()`
- **Function**: `test_dropna_any_top_level()`
- **Function**: `test_explode_flat()`
- **Function**: `test_explode_nested()`
- **Function**: `test_explode_multiple_fields()`
- **Function**: `test_left_join()`
- **Function**: `test_join_with_conflicting_keys()`
- **Function**: `test_inner_join()`
- **Function**: `test_right_join()`
- **Function**: `test_outer_join()`
- **Function**: `test_anti_join()`
- **Function**: `test_join_different_key_names()`
- **Function**: `test_join_custom_suffixes()`
- **Function**: `test_join_multiple_keys()`
- **Function**: `test_join_validation_errors()`
- **Function**: `test_join_empty_datasets()`
- **Function**: `test_join_no_suffix_right_precedence()`
  - *Description*: Test that when rsuffix is empty, left values take precedence for overlapping fields
- **Function**: `test_type_coercion_strict()`
  - *Description*: Test strict type coercion (default behavior)
- **Function**: `test_type_coercion_auto()`
  - *Description*: Test auto type coercion for smart numeric matching
- **Function**: `test_type_coercion_string()`
  - *Description*: Test string type coercion for universal string matching
- **Function**: `test_type_coercion_inner_join()`
  - *Description*: Test type coercion with inner join
- **Function**: `test_type_coercion_outer_join()`
  - *Description*: Test type coercion with outer join
- **Function**: `test_type_coercion_anti_join()`
  - *Description*: Test type coercion with anti join
- **Function**: `test_type_coercion_multiple_keys()`
  - *Description*: Test type coercion with multiple join keys
- **Function**: `test_type_coercion_different_key_names()`
  - *Description*: Test type coercion with different key names (left_on/right_on)
- **Function**: `test_type_coercion_with_none_values()`
  - *Description*: Test type coercion behavior with None values
- **Function**: `test_type_coercion_validation()`
  - *Description*: Test that invalid type coercion strategy raises error
- **Function**: `test_type_coercion_edge_cases()`
  - *Description*: Test edge cases for type coercion
- **Function**: `test_split_array_to_fields()`
- **Function**: `test_pivot_basic()`
- **Function**: `test_ungrouped_summary()`
- **Function**: `test_invalid_summary_output()`
- **Function**: `test_count(data2)`
- **Function**: `test_count_nonnull()`
- **Function**: `test_sum_(data2)`
- **Function**: `test_mean_(data2)`
- **Function**: `test_min_(data2)`
- **Function**: `test_max_(data2)`
- **Function**: `test_std_(data2)`
- **Function**: `test_median_(data2)`
- **Function**: `test_range_(data2)`
- **Function**: `test_iqr_(data2)`
- **Function**: `test_percentile_(data2)`
- **Function**: `test_mode_()`
- **Function**: `test_first_last(data2)`
- **Function**: `test_unique()`
- **Function**: `test_list_()`
- **Function**: `test_all_()`
- **Function**: `test_all_any(data2)`
- **Function**: `test_nested_field_access(data2)`
- **Function**: `test_empty_data()`
- **Function**: `test_groupby_summary_with_sum()`
- **Function**: `test_summary_on_nested_field()`
- **Function**: `test_groupby_summary_on_nested_fields()`
- **Function**: `test_summary_with_custom_callable()`
- **Function**: `test_flow_summary_with_callable_and_field()`
- **Function**: `test_group_summary_with_callable_and_field()`
- **Function**: `test_summary_with_invalid_tuple_format()`
- **Function**: `test_schema_inference_flat_fields()`
- **Function**: `test_cast_fields_to_types()`
- **Function**: `test_from_json_lazy(tmp_path)`
- **Function**: `test_from_jsonl_lazy(tmp_path)`
- **Function**: `test_to_json_and_jsonl(tmp_path)`
- **Function**: `test_to_pandas()`
- **Function**: `test_sample_fraction_deterministic()`
- **Function**: `test_sample_fraction_zero()`
- **Function**: `test_sample_fraction_one()`
- **Function**: `test_map_basic()`
- **Function**: `test_map_drop_none()`
- **Function**: `test_map_raises_on_non_dict()`
- **Function**: `test_map_raises_on_none_when_strict()`
- **Function**: `test_pipe_is_lazy()`
- **Function**: `test_keys_flat_records()`
- **Function**: `test_keys_nested_records()`
- **Function**: `test_keys_with_limit()`
- **Function**: `test_keys_empty_flow()`
- **Function**: `test_is_empty_true()`
- **Function**: `test_is_empty_false()`
- **Function**: `test_is_empty_lazy_behavior()`
- **Function**: `test_where_equals(record)`
- **Function**: `test_where_in(record)`
- **Function**: `test_where_gt(record)`
- **Function**: `test_where_exists_and_null(record)`
- **Function**: `test_where_contains(record)`
- **Function**: `test_and_predicate(record)`
- **Function**: `test_or_predicate(record)`
- **Function**: `test_not_predicate(record)`
- **Function**: `test_missing_field_safe()`
- **Function**: `test_where_in_scalar(scalar_record)`
- **Function**: `test_where_in_list(list_record)`
- **Function**: `test_where_in_raises_on_dict(dict_record)`
- **Function**: `test_where_in_raises_on_list_of_dicts(list_of_dicts_record)`
- **Function**: `test_where_not_in_scalar(scalar_record)`
- **Function**: `test_where_not_in_list(list_record)`
- **Function**: `test_where_not_in_raises_on_dict(dict_record)`
- **Function**: `test_where_not_in_raises_on_list_of_dicts(list_of_dicts_record)`
- **Function**: `test_where_equals_scalar(scalar_record)`
- **Function**: `test_where_equals_missing_field(scalar_record)`
- **Function**: `test_where_gt_pass()`
- **Function**: `test_where_gt_missing_field(scalar_record)`
- **Function**: `test_where_gt_invalid_type_ignored(dict_record)`
- **Function**: `test_where_exists(scalar_record)`
- **Function**: `test_where_is_null(scalar_record)`
- **Function**: `test_with_schema_basic_cast()`
- **Function**: `test_with_schema_nested_field()`
- **Function**: `test_with_schema_strict_mode_raises()`
- **Function**: `test_with_schema_fallback_on_error()`
- **Function**: `test_with_schema_drop_extra_fields()`
- **Function**: `test_without_schema_drop_extra_fields()`
### File: `test/test_flow_cloud_storage.py`

- **Function**: `test_storage_options_parameter_acceptance()`
  - *Description*: Test that all from_* methods accept storage_options parameter.
- **Function**: `test_storage_options_are_optional()`
  - *Description*: Test that storage_options parameter is optional.
- **Function**: `test_handle_missing_dependency_s3()`
  - *Description*: Test dependency checking for S3 paths.
- **Function**: `test_handle_missing_dependency_gcs()`
  - *Description*: Test dependency checking for GCS paths.
- **Function**: `test_handle_missing_dependency_azure()`
  - *Description*: Test dependency checking for Azure paths.
- **Function**: `test_handle_missing_dependency_local_path()`
  - *Description*: Test that local paths don't trigger dependency checks.
- **Function**: `test_handle_missing_dependency_multiple_protocols()`
  - *Description*: Test dependency checking for various protocols.
- **Function**: `test_backwards_compatibility_with_existing_api()`
  - *Description*: Test that existing code without storage_options still works.
- **Function**: `test_storage_options_integration_with_fsspec()`
  - *Description*: Test that storage_options are passed correctly to fsspec.
- **Function**: `test_cloud_storage_method_signatures(method_name, file_extension)`
  - *Description*: Test that cloud storage methods have correct signatures.
- **Function**: `test_folder_and_glob_methods_with_storage_options()`
  - *Description*: Test that from_folder and from_glob handle storage_options correctly.
- **Function**: `test_mixed_local_and_cloud_paths()`
  - *Description*: Test that the system handles mixed local and cloud paths appropriately.
- **Function**: `test_docstring_examples_are_valid()`
  - *Description*: Test that the examples in docstrings are syntactically valid.
### File: `test/test_flow_glob.py`

- **Function**: `write_json_file(path, data)`
- **Function**: `write_jsonl_file(path, records)`
- **Function**: `test_from_glob_reads_json_and_jsonl_files()`
- **Function**: `test_from_glob_ignores_non_json_files()`
- **Function**: `test_from_glob_reads_single_dict_record()`
### File: `test/test_flow_glob_cloud_storage.py`

- **Function**: `test_from_glob_with_gs_protocol()`
  - *Description*: Test that from_glob works correctly with gs:// protocol.
- **Function**: `test_from_glob_with_s3_protocol()`
  - *Description*: Test that from_glob works correctly with s3:// protocol.
- **Function**: `test_from_glob_path_reconstruction()`
  - *Description*: Test that paths are correctly reconstructed when fsspec.glob returns relative paths.
- **Function**: `test_from_glob_error_handling()`
  - *Description*: Test that from_glob handles errors correctly.
- **Function**: `test_from_glob_local_file_paths()`
  - *Description*: Test that from_glob works correctly with local file paths.
- **Function**: `test_from_glob_skips_directories()`
  - *Description*: Test that from_glob skips directories.
- **Function**: `test_from_glob_with_flow_class()`
  - *Description*: Test that Flow.from_glob works correctly with cloud storage paths.
### File: `test/test_flow_helpers.py`

- **Function**: `test_get_field_flat()`
- **Function**: `test_get_index_flat()`
- **Function**: `test_get_field_basic()`
- **Function**: `test_get_field_missing()`
- **Function**: `test_get_field_non_dict()`
- **Function**: `test_get_index_basic()`
- **Function**: `test_get_index_out_of_bounds()`
- **Function**: `test_get_index_non_list()`
- **Function**: `test_where_equals_flat()`
- **Function**: `test_where_in_flat()`
- **Function**: `test_where_exists_flat()`
- **Function**: `test_where_not_none_flat()`
- **Function**: `test_where_equals_true()`
- **Function**: `test_where_equals_false()`
- **Function**: `test_where_in_true()`
- **Function**: `test_where_in_false()`
- **Function**: `test_where_exists_true()`
- **Function**: `test_where_exists_false()`
- **Function**: `test_where_not_none_true()`
- **Function**: `test_where_not_none_false()`
- **Function**: `test_combine_fields_flat()`
- **Function**: `test_coalesce_flat()`
- **Function**: `test_combine_fields_basic()`
- **Function**: `test_combine_fields_with_join()`
- **Function**: `test_combine_fields_missing()`
- **Function**: `test_coalesce_first()`
- **Function**: `test_coalesce_second()`
- **Function**: `test_coalesce_default()`
- **Function**: `test_fast_get_field_simple_dict()`
- **Function**: `test_fast_get_field_missing_key()`
- **Function**: `test_fast_get_field_list_index()`
- **Function**: `test_fast_get_field_list_index_out_of_bounds()`
- **Function**: `test_fast_get_field_nested_list()`
- **Function**: `test_fast_get_field_not_a_dict()`
- **Function**: `test_fast_get_field_list_then_dict()`
- **Function**: `test_fast_get_field_invalid_type_for_index()`
- **Function**: `test_get_index_basic_utils()`
- **Function**: `test_get_index_out_of_bounds_utils()`
- **Function**: `test_get_index_not_a_list()`
- **Function**: `test_get_index_missing_field()`
- **Function**: `test_get_index_nested_path()`
### File: `test/test_flow_optimizer.py`

- **Function**: `test_fuse_map_filter()`
- **Function**: `test_single_filter_not_fused()`
- **Function**: `test_non_fusible_ops_untouched()`
- **Function**: `test_multiple_assigns_and_filter_fused()`
- **Function**: `apply_limit_pass(plan)`
  - *Description*: Utility to run only _pushdown_limit on the plan.
- **Function**: `test_limit_pushes_over_stateless_ops()`
- **Function**: `test_limit_not_pushed_over_join()`
- **Function**: `test_limit_not_pushed_over_filter()`
- **Function**: `test_limit_not_pushed_if_not_possible()`
- **Function**: `test_limit_inserted_once()`
- **Function**: `test_multiple_limits_only_outer_remains()`
- **Function**: `test_optimizer_pushdown_select()`
- **Function**: `test_pushdown_filters_respects_blocking_ops()`
- **Function**: `dummy_pred(r)`
- **Function**: `test_pushdown_filters_always_before_summary()`
### File: `test/test_flow_query.py`

- **Function**: `make_flow()`
- **Function**: `test_query_equals()`
- **Function**: `test_query_greater_than()`
- **Function**: `test_query_combined_and()`
- **Function**: `test_query_combined_or()`
- **Function**: `test_query_not()`
- **Function**: `test_query_in_list()`
- **Function**: `test_query_not_in()`
- **Function**: `test_query_invalid_syntax()`
- **Function**: `test_query_unsupported_expr()`
- **Function**: `test_query_len_string()`
- **Function**: `test_query_len_list()`
- **Function**: `test_query_len_on_non_len_field()`
- **Function**: `test_query_chained_comparisons()`
- **Function**: `test_query_dot_notation()`
- **Function**: `test_query_contains()`
- **Function**: `test_query_startswith()`
- **Function**: `test_query_endswith()`
- **Function**: `test_query_lower_equals()`
- **Function**: `test_query_upper_not_equals()`
- **Function**: `test_query_lower_in_list()`
- **Function**: `test_query_upper_not_in_list()`
- **Function**: `test_query_case_transform_on_non_string()`
- **Function**: `test_query_case_transform_unsupported_comparison()`
- **Function**: `test_query_case_transform_as_predicate()`
- **Function**: `test_query_is_null()`
- **Function**: `test_query_is_not_null()`
- **Function**: `make_date_flow()`
- **Function**: `test_query_datetime_literal_greater_than()`
  - *Description*: Test filtering with datetime() literal
- **Function**: `test_query_date_literal_greater_than()`
  - *Description*: Test filtering with date() literal
- **Function**: `test_query_date_variable()`
  - *Description*: Test filtering with date variable using @syntax
- **Function**: `test_query_date_and_numeric_combined()`
  - *Description*: Test combining date and numeric filters
- **Function**: `test_query_date_null_handling()`
  - *Description*: Test that null dates are handled properly
- **Function**: `test_query_date_less_than()`
  - *Description*: Test date less than comparison
- **Function**: `test_query_date_equals()`
  - *Description*: Test exact date matching
- **Function**: `test_query_datetime_vs_date_comparison()`
  - *Description*: Test that datetime and date objects can be compared
- **Function**: `test_query_date_type_mismatch_error()`
  - *Description*: Test that incompatible type comparisons raise helpful errors
- **Function**: `test_query_regex_basic()`
  - *Description*: Test basic regex matching
- **Function**: `test_query_regex_pattern()`
  - *Description*: Test regex pattern matching
- **Function**: `test_query_regex_match_alias()`
  - *Description*: Test .match() as an alias for .regex()
- **Function**: `test_query_regex_with_flags()`
  - *Description*: Test regex with flags (case insensitive)
- **Function**: `test_query_regex_on_non_string()`
  - *Description*: Test regex on non-string field (should convert to string)
- **Function**: `test_query_regex_on_null()`
  - *Description*: Test regex on null value (should not match)
- **Function**: `test_query_regex_invalid_pattern()`
  - *Description*: Test invalid regex pattern raises ValueError
- **Function**: `test_query_regex_no_args()`
  - *Description*: Test regex with no arguments raises ValueError
### File: `test/test_flowgroup.py`

- **Function**: `test_group_summary()`
- **Function**: `test_group_cumulative()`
- **Function**: `test_row_based_rolling_sum()`
- **Function**: `test_time_bucket_with_missing_time_field()`
- **Function**: `test_time_bucket_with_non_datetime_field()`
- **Function**: `test_time_bucket_invalid_frequency_string()`
- **Function**: `test_time_bucket_empty_group_after_filtering()`
- **Function**: `test_time_bucket_mixed_valid_invalid_time_fields()`
- **Function**: `test_time_bucket_boundary_conditions()`
- **Function**: `test_time_bucket_large_time_gaps()`
- **Function**: `test_time_bucket_multiple_aggregators()`
- **Function**: `test_time_bucket_negative_time_values()`
- **Function**: `test_time_bucket_non_uniform_time_intervals()`
- **Function**: `test_time_bucket_with_custom_bucket_name()`
- **Function**: `test_time_bucket_multiple_groups()`
- **Function**: `test_time_bucket_empty_input()`
- **Function**: `test_time_bucket_all_missing_time_field()`
- **Function**: `test_time_bucket_non_uniform_buckets()`
- **Function**: `test_time_bucket_numeric_time_field()`
- **Function**: `test_time_bucket_custom_aggregator()`
- **Function**: `test_time_bucket_with_right_label()`
### File: `test/test_football_probability_grid.py`

- **Function**: `sample_grid()`
  - *Description*: A simple 3x3 probability grid for testing.
- **Function**: `normalized_grid()`
  - *Description*: A 3x3 probability grid that sums to 1.0.
- **Function**: `unnormalized_grid()`
  - *Description*: A 3x3 probability grid that doesn't sum to 1.0.
- **Class**: `TestFootballProbabilityGridInitialization`
  - *Description*: Test initialization and validation of FootballProbabilityGrid.
  - **Method**: `test_basic_initialization(self, normalized_grid)`
    - *Description*: Test basic initialization with valid parameters.
  - **Method**: `test_normalization_enabled(self, unnormalized_grid)`
    - *Description*: Test initialization with normalization enabled.
  - **Method**: `test_normalization_disabled(self, unnormalized_grid)`
    - *Description*: Test initialization with normalization disabled.
  - **Method**: `test_invalid_matrix_empty(self)`
    - *Description*: Test that empty matrix raises ValueError.
  - **Method**: `test_invalid_matrix_1d(self)`
    - *Description*: Test that 1D matrix raises ValueError.
  - **Method**: `test_negative_probabilities(self)`
    - *Description*: Test that negative probabilities raise ValueError.
  - **Method**: `test_zero_sum_normalization_error(self)`
    - *Description*: Test that zero-sum matrix raises error when normalization is requested.
- **Class**: `TestCoreMarkets`
  - *Description*: Test core betting market calculations (1X2, etc.).
  - **Method**: `test_1x2_markets(self, normalized_grid)`
    - *Description*: Test home win, draw, and away win probabilities.
  - **Method**: `test_1x2_calculation_correctness(self)`
    - *Description*: Test that 1X2 calculations are mathematically correct.
  - **Method**: `test_both_teams_to_score(self, normalized_grid)`
    - *Description*: Test both teams to score (BTTS) market.
  - **Method**: `test_btts_calculation_correctness(self)`
    - *Description*: Test BTTS calculation correctness.
- **Class**: `TestDoubleChanceMarkets`
  - *Description*: Test double chance markets (1X, X2, 12).
  - **Method**: `test_double_chance_markets(self, normalized_grid)`
    - *Description*: Test all double chance market calculations.
  - **Method**: `test_draw_no_bet(self, normalized_grid)`
    - *Description*: Test Draw No Bet markets.
  - **Method**: `test_draw_no_bet_edge_case(self)`
    - *Description*: Test Draw No Bet when draw probability is 1 (edge case).
- **Class**: `TestTotalsMarkets`
  - *Description*: Test over/under totals markets.
  - **Method**: `test_totals_with_push(self, normalized_grid)`
    - *Description*: Test totals calculation including push probabilities.
  - **Method**: `test_total_goals_backward_compatibility(self, normalized_grid)`
    - *Description*: Test backward-compatible total_goals method.
  - **Method**: `test_totals_calculation_correctness(self)`
    - *Description*: Test totals calculations are mathematically correct.
- **Class**: `TestAsianHandicapMarkets`
  - *Description*: Test Asian handicap markets.
  - **Method**: `test_asian_handicap_probs(self, normalized_grid)`
    - *Description*: Test Asian handicap with win/push/lose probabilities.
  - **Method**: `test_asian_handicap_quarter_lines(self, normalized_grid)`
    - *Description*: Test Asian handicap with quarter lines (split stakes).
  - **Method**: `test_asian_handicap_backward_compatibility(self, normalized_grid)`
    - *Description*: Test backward-compatible asian_handicap method.
  - **Method**: `test_asian_handicap_error_handling(self, normalized_grid)`
    - *Description*: Test Asian handicap error handling.
- **Class**: `TestExactScoresAndDistributions`
  - *Description*: Test exact score probabilities and goal distributions.
  - **Method**: `test_exact_score(self, normalized_grid)`
    - *Description*: Test exact score probabilities.
  - **Method**: `test_goal_distributions(self, normalized_grid)`
    - *Description*: Test marginal goal distributions.
- **Class**: `TestSpecialMarkets`
  - *Description*: Test special markets like win to nil, expected points.
  - **Method**: `test_win_to_nil(self, normalized_grid)`
    - *Description*: Test win to nil probabilities.
  - **Method**: `test_expected_points(self, normalized_grid)`
    - *Description*: Test expected points calculations (3-1-0 system).
- **Class**: `TestNormalizationFeature`
  - *Description*: Test the new normalization feature.
  - **Method**: `test_normalization_functionality(self, unnormalized_grid)`
    - *Description*: Test that normalization works correctly.
  - **Method**: `test_already_normalized_grid(self, normalized_grid)`
    - *Description*: Test that already normalized grids work correctly with normalize=True.
  - **Method**: `test_normalization_preserves_markets(self, unnormalized_grid)`
    - *Description*: Test that normalization preserves relative market probabilities.
- **Class**: `TestCachingAndPerformance`
  - *Description*: Test internal caching mechanism and performance aspects.
  - **Method**: `test_caching_mechanism(self, normalized_grid)`
    - *Description*: Test that caching works correctly for repeated calculations.
  - **Method**: `test_index_grids_created(self, normalized_grid)`
    - *Description*: Test that index grids are properly created for vectorized operations.
- **Class**: `TestStringRepresentation`
  - *Description*: Test string representation of FootballProbabilityGrid.
  - **Method**: `test_repr_content(self, normalized_grid)`
    - *Description*: Test that __repr__ contains expected information.
  - **Method**: `test_repr_formatting(self, normalized_grid)`
    - *Description*: Test that __repr__ has proper formatting.
- **Function**: `test_grid()`
  - *Description*: Legacy test updated with better assertions.
- **Function**: `test_str()`
  - *Description*: Legacy test for string representation.
### File: `test/test_fpl.py`

### File: `test/test_goal_expectancy.py`

- **Function**: `balanced_probs()`
  - *Description*: Balanced probabilities for a fairly even match.
- **Function**: `home_favored_probs()`
  - *Description*: Probabilities where home team is strongly favored.
- **Function**: `away_favored_probs()`
  - *Description*: Probabilities where away team is strongly favored.
- **Function**: `unnormalized_probs()`
  - *Description*: Probabilities that don't sum to 1.0 (overround).
- **Class**: `TestGoalExpectancyBasicFunctionality`
  - *Description*: Test basic functionality and core features.
  - **Method**: `test_basic_functionality(self, away_favored_probs)`
    - *Description*: Test basic functionality with default parameters.
  - **Method**: `test_return_details_false(self, balanced_probs)`
    - *Description*: Test return_details=False excludes detailed information.
  - **Method**: `test_dixon_coles_adjustment(self, balanced_probs)`
    - *Description*: Test Dixon-Coles adjustment functionality.
  - **Method**: `test_rho_parameter(self, balanced_probs)`
    - *Description*: Test different rho values in Dixon-Coles adjustment.
- **Class**: `TestGoalExpectancyInputValidation`
  - *Description*: Test input validation and error handling.
  - **Method**: `test_negative_probabilities(self)`
    - *Description*: Test that negative probabilities raise ValueError.
  - **Method**: `test_probabilities_greater_than_one(self)`
    - *Description*: Test that probabilities > 1 raise ValueError.
  - **Method**: `test_edge_case_probabilities(self)`
    - *Description*: Test edge cases with extreme probabilities.
  - **Method**: `test_invalid_objective(self, balanced_probs)`
    - *Description*: Test that invalid objective raises ValueError.
- **Class**: `TestGoalExpectancyDeoverround`
  - *Description*: Test deoverround functionality.
  - **Method**: `test_deoverround_functionality(self, unnormalized_probs)`
    - *Description*: Test that deoverround properly normalizes probabilities.
  - **Method**: `test_deoverround_zero_sum_error(self)`
    - *Description*: Test that zero-sum probabilities with remove_overround=True raise error.
  - **Method**: `test_deoverround_preserves_ratios(self, unnormalized_probs)`
    - *Description*: Test that remove_overround preserves relative probability ratios.
- **Class**: `TestGoalExpectancyObjectiveFunctions`
  - *Description*: Test different objective functions.
  - **Method**: `test_brier_objective(self, balanced_probs)`
    - *Description*: Test Brier score (MSE) objective function.
  - **Method**: `test_cross_entropy_objective(self, balanced_probs)`
    - *Description*: Test cross-entropy objective function.
  - **Method**: `test_objective_comparison(self, balanced_probs)`
    - *Description*: Test that different objectives give different results.
- **Class**: `TestGoalExpectancyOptimizationParameters`
  - *Description*: Test optimization-related parameters.
  - **Method**: `test_max_goals_parameter(self, balanced_probs)`
    - *Description*: Test different max_goals values.
  - **Method**: `test_method_parameter(self, balanced_probs)`
    - *Description*: Test different optimization methods.
  - **Method**: `test_bounds_parameter(self, balanced_probs)`
    - *Description*: Test custom bounds parameter.
  - **Method**: `test_x0_initial_guess(self, balanced_probs)`
    - *Description*: Test custom initial guess parameter.
  - **Method**: `test_minimizer_options(self, balanced_probs)`
    - *Description*: Test minimizer_options parameter.
- **Class**: `TestGoalExpectancyDixonColesOptions`
  - *Description*: Test Dixon-Coles specific parameters.
  - **Method**: `test_renormalize_after_dc_true(self, balanced_probs)`
    - *Description*: Test renormalize_after_dc=True (default).
  - **Method**: `test_renormalize_after_dc_false(self, balanced_probs)`
    - *Description*: Test renormalize_after_dc=False.
  - **Method**: `test_dc_with_different_rho_values(self, balanced_probs)`
    - *Description*: Test Dixon-Coles with various rho values.
- **Class**: `TestGoalExpectancyResultConsistency`
  - *Description*: Test consistency and mathematical properties of results.
  - **Method**: `test_predicted_probabilities_consistency(self, balanced_probs)`
    - *Description*: Test that predicted probabilities are mathematically consistent.
  - **Method**: `test_mass_property(self, balanced_probs)`
    - *Description*: Test that grid mass is reasonable.
  - **Method**: `test_error_decreases_with_better_fit(self)`
    - *Description*: Test that error decreases when we have better initial conditions.
  - **Method**: `test_expectancy_reasonableness(self, home_favored_probs, away_favored_probs)`
    - *Description*: Test that goal expectancies make intuitive sense.
- **Class**: `TestGoalExpectancyEdgeCases`
  - *Description*: Test edge cases and corner scenarios.
  - **Method**: `test_extreme_probabilities(self)`
    - *Description*: Test with extreme probability distributions.
  - **Method**: `test_very_low_scoring_game(self)`
    - *Description*: Test scenario that should result in very low scoring expectations.
  - **Method**: `test_high_scoring_game(self)`
    - *Description*: Test scenario suggesting a high-scoring game.
- **Function**: `test_goal_expectancy()`
  - *Description*: Legacy test updated with better assertions.
- **Function**: `test_goal_expectancy_minimizer_options()`
  - *Description*: Legacy test for minimizer options.
- **Function**: `test_goal_expectancy_dc_adj()`
  - *Description*: Legacy test for Dixon-Coles adjustment.
### File: `test/test_hierarchical_bayesian_goal_model.py`

- **Function**: `test_hierarchical_bayesian_model_initialization(fixtures)`
  - *Description*: Test that HierarchicalBayesianGoalModel can be initialized correctly.
- **Function**: `test_hierarchical_bayesian_model_fit(fixtures)`
  - *Description*: Test that the model fits correctly and produces expected outputs.
- **Function**: `test_hierarchical_bayesian_model_sigma_parameters(fixtures)`
  - *Description*: Test that hierarchical sigma parameters are correctly estimated.
- **Function**: `test_hierarchical_bayesian_model_get_params(fixtures)`
  - *Description*: Test that get_params returns all expected parameters.
- **Function**: `test_hierarchical_bayesian_model_predictions(fixtures)`
  - *Description*: Test that prediction functionality works correctly.
- **Function**: `test_hierarchical_bayesian_model_diagnostics(fixtures)`
  - *Description*: Test that diagnostics are computed correctly including sigma parameters.
- **Function**: `test_hierarchical_bayesian_model_unfitted_raises_error(fixtures)`
  - *Description*: Test that unfitted model raises appropriate errors.
- **Function**: `test_hierarchical_bayesian_model_plot_trace(fixtures)`
  - *Description*: Test that plot_trace method works correctly.
- **Function**: `test_hierarchical_bayesian_model_plot_autocorr(fixtures)`
  - *Description*: Test that plot_autocorr method works correctly.
- **Function**: `test_hierarchical_bayesian_model_plot_posterior(fixtures)`
  - *Description*: Test that plot_posterior method works correctly.
- **Function**: `test_hierarchical_bayesian_model_plot_convergence(fixtures)`
  - *Description*: Test that plot_convergence method works correctly.
- **Function**: `test_hierarchical_bayesian_model_plot_diagnostics(fixtures)`
  - *Description*: Test that plot_diagnostics method works correctly.
- **Function**: `test_hierarchical_bayesian_model_param_names(fixtures)`
  - *Description*: Test that _get_param_names returns correct parameter names.
- **Function**: `test_hierarchical_bayesian_model_param_indices(fixtures)`
  - *Description*: Test that _get_tail_param_indices returns correct indices.
- **Function**: `test_hierarchical_bayesian_model_params_array(fixtures)`
  - *Description*: Test that params_array property works correctly.
- **Function**: `test_hierarchical_bayesian_model_params_property(fixtures)`
  - *Description*: Test that params property works correctly.
- **Function**: `test_hierarchical_bayesian_model_trace_mapping(fixtures)`
  - *Description*: Test that _map_trace_to_dict correctly maps trace including sigma parameters.
- **Function**: `test_hierarchical_bayesian_model_custom_fit_parameters(fixtures)`
  - *Description*: Test fitting with custom sample parameters.
- **Function**: `test_hierarchical_bayesian_model_comparison_with_standard_bayesian(fixtures)`
  - *Description*: Test that hierarchical model has additional parameters compared to standard Bayesian model.
- **Function**: `test_hierarchical_bayesian_model_dimension(fixtures)`
  - *Description*: Test that the model has the correct parameter dimension.
- **Function**: `test_hierarchical_bayesian_model_save_load(fixtures, tmp_path)`
  - *Description*: Test that the model can be saved and loaded.
### File: `test/test_implied.py`

- **Class**: `TestOddsInput`
  - *Description*: Test the OddsInput helper class.
  - **Method**: `test_decimal_odds_conversion(self)`
    - *Description*: Test decimal odds pass through unchanged.
  - **Method**: `test_american_odds_conversion(self)`
    - *Description*: Test American odds conversion to decimal.
  - **Method**: `test_fractional_odds_conversion(self)`
    - *Description*: Test fractional odds conversion to decimal.
  - **Method**: `test_invalid_fractional_format(self)`
    - *Description*: Test error handling for invalid fractional odds.
- **Class**: `TestImpliedProbabilities`
  - *Description*: Test the ImpliedProbabilities dataclass.
  - **Method**: `test_valid_probabilities(self)`
    - *Description*: Test creating valid probabilities object.
  - **Method**: `test_invalid_probability_sum(self)`
    - *Description*: Test validation of probability sums.
  - **Method**: `test_backward_compatibility_indexing(self)`
    - *Description*: Test list-like access for backward compatibility.
  - **Method**: `test_with_market_names(self)`
    - *Description*: Test probabilities with market names.
  - **Method**: `test_most_likely_methods(self)`
    - *Description*: Test most/least likely outcome detection.
  - **Method**: `test_get_probability_by_name(self)`
    - *Description*: Test getting probability by outcome name.
  - **Method**: `test_get_probability_by_name_errors(self)`
    - *Description*: Test error cases for get_probability_by_name.
  - **Method**: `test_market_names_length_validation(self)`
    - *Description*: Test validation of market names length.
  - **Method**: `test_to_dict_conversion(self)`
    - *Description*: Test conversion to legacy dict format.
- **Class**: `TestCalculateImplied`
  - *Description*: Test the main calculate_implied function.
  - **Method**: `test_multiplicative_method(self)`
    - *Description*: Test multiplicative method calculation.
  - **Method**: `test_all_methods_produce_valid_results(self)`
    - *Description*: Test that all methods produce valid probability distributions.
  - **Method**: `test_string_method_parameter(self)`
    - *Description*: Test using string method names.
  - **Method**: `test_invalid_method(self)`
    - *Description*: Test error handling for invalid methods.
  - **Method**: `test_different_odds_formats(self)`
    - *Description*: Test calculation with different odds formats.
  - **Method**: `test_odds_input_object(self)`
    - *Description*: Test using OddsInput object.
  - **Method**: `test_with_market_names(self)`
    - *Description*: Test calculate_implied with market names.
  - **Method**: `test_two_way_market(self)`
    - *Description*: Test calculate_implied with two-way market.
  - **Method**: `test_many_outcomes_market(self)`
    - *Description*: Test calculate_implied with many outcomes.
  - **Method**: `test_asian_handicap_market(self)`
    - *Description*: Test calculate_implied with Asian handicap market.
- **Class**: `TestMethodParameters`
  - *Description*: Test method-specific parameters.
  - **Method**: `test_power_method_parameters(self)`
    - *Description*: Test that power method returns k parameter.
  - **Method**: `test_shin_method_parameters(self)`
    - *Description*: Test that Shin method returns z parameter.
  - **Method**: `test_odds_ratio_method_parameters(self)`
    - *Description*: Test that odds ratio method returns c parameter.
  - **Method**: `test_logarithmic_method_parameters(self)`
    - *Description*: Test that logarithmic method returns c parameter.
### File: `test/test_kelly_criterion.py`

- **Function**: `test_kelly_criterion()`
  - *Description*: Test basic Kelly criterion calculation.
- **Function**: `test_kelly_criterion_fraction()`
  - *Description*: Test Kelly criterion with fraction scaling.
- **Function**: `test_kelly_criterion_unfavorable()`
  - *Description*: Test Kelly criterion with unfavorable odds.
- **Function**: `test_kelly_criterion_warnings()`
  - *Description*: Test that warnings are generated appropriately.
- **Function**: `test_input_validation_errors()`
  - *Description*: Test input validation raises appropriate errors.
- **Function**: `test_low_probability_warnings()`
  - *Description*: Test warnings for very low probabilities.
- **Function**: `test_kelly_criterion_array_inputs()`
  - *Description*: Test kelly_criterion with numpy array inputs.
- **Function**: `test_multiple_kelly_basic()`
  - *Description*: Test basic multiple Kelly criterion functionality.
- **Function**: `test_multiple_kelly_input_validation()`
  - *Description*: Test input validation for multiple Kelly criterion.
- **Function**: `test_multiple_kelly_constraints()`
  - *Description*: Test constraint handling in multiple Kelly criterion.
- **Function**: `test_multiple_kelly_fraction_scaling()`
  - *Description*: Test fraction scaling in multiple Kelly criterion.
- **Function**: `test_multiple_kelly_edge_cases()`
  - *Description*: Test edge cases for multiple Kelly criterion.
- **Function**: `test_multiple_kelly_optimization_fallback()`
  - *Description*: Test optimization fallback scenarios.
- **Function**: `test_multiple_kelly_comprehensive_metrics()`
  - *Description*: Test comprehensive metrics from multiple Kelly results.
- **Function**: `test_risk_metrics_scalar_edge_cases()`
  - *Description*: Test risk metrics with scalar inputs and edge cases to cover lines 181-183, 277.
- **Function**: `test_optimization_edge_cases()`
  - *Description*: Test optimization edge cases to cover lines 491, 507, 518, 576-578, 595-596.
### File: `test/test_metrics_briar.py`

- **Function**: `test_perfect_predictions()`
- **Function**: `test_uniform_predictions()`
- **Function**: `test_wrong_but_confident_predictions()`
- **Function**: `test_partial_confidence_predictions()`
- **Function**: `test_numpy_shapes()`
### File: `test/test_metrics_ignorance.py`

- **Function**: `test_basic_case()`
- **Function**: `test_perfect_predictions()`
- **Function**: `test_uniform_predictions()`
- **Function**: `test_zero_probability_handling()`
- **Function**: `test_multiple_samples_same_prediction()`
- **Function**: `test_input_as_numpy_arrays()`
### File: `test/test_metrics_rps.py`

- **Function**: `test_rps()`
### File: `test/test_model_bayesian.py`

- **Function**: `test_bayesian_model(fixtures)`
- **Function**: `test_hierarchical_bayesian_model(fixtures)`
- **Function**: `test_bayesian_plots(fixtures)`
### File: `test/test_model_bivariate.py`

- **Function**: `test_poisson_model(fixtures)`
- **Function**: `test_bivariate_minimizer_options(fixtures)`
- **Function**: `test_unfitted_raises_error(fixtures)`
- **Function**: `test_unfitted_repr(fixtures)`
- **Function**: `test_bivariate_with_gradient_enabled(fixtures)`
  - *Description*: Test that the model fits successfully with gradient enabled.
- **Function**: `test_bivariate_with_gradient_disabled(fixtures)`
  - *Description*: Test that the model fits successfully with gradient disabled.
- **Function**: `test_bivariate_gradient_vs_no_gradient_consistency(fixtures)`
  - *Description*: Test that gradient and non-gradient methods produce similar results.
- **Function**: `test_bivariate_gradient_function_correctness(fixtures)`
  - *Description*: Test that gradient function returns correctly shaped output.
- **Function**: `test_bivariate_gradient_numerical_consistency()`
  - *Description*: Test gradient against numerical differentiation.
- **Function**: `test_bivariate_default_gradient_behavior(fixtures)`
  - *Description*: Test that gradient is used by default.
- **Function**: `test_bivariate_correlation_parameter_bounds()`
  - *Description*: Test that correlation parameter produces reasonable lambda3 values.
### File: `test/test_model_dixon_coles.py`

- **Function**: `test_dc_model(fixtures)`
- **Function**: `test_dixon_coles_minimizer_options(fixtures)`
- **Function**: `test_unfitted_raises_error(fixtures)`
- **Function**: `test_unfitted_repr(fixtures)`
- **Function**: `test_dixon_coles_with_gradient_enabled(fixtures)`
  - *Description*: Test that the Dixon-Coles model works correctly with gradient enabled (default behavior).
- **Function**: `test_dixon_coles_with_gradient_disabled(fixtures)`
  - *Description*: Test that the Dixon-Coles model works correctly with gradient disabled.
- **Function**: `test_dixon_coles_gradient_vs_no_gradient_consistency(fixtures)`
  - *Description*: Test that gradient and no-gradient approaches produce similar results.
- **Function**: `test_dixon_coles_gradient_function_correctness(fixtures)`
  - *Description*: Test that the gradient function produces reasonable gradients.
- **Function**: `test_dixon_coles_default_gradient_behavior(fixtures)`
  - *Description*: Test that gradient is enabled by default.
### File: `test/test_model_negaive_binomial.py`

- **Function**: `test_negative_binomial_model(fixtures)`
- **Function**: `test_negative_binomial_minimizer_options(fixtures)`
- **Function**: `test_unfitted_raises_error(fixtures)`
- **Function**: `test_unfitted_repr(fixtures)`
- **Function**: `test_negative_binomial_with_gradient_enabled(fixtures)`
  - *Description*: Test that the negative binomial model works correctly with gradient enabled (default behavior).
- **Function**: `test_negative_binomial_with_gradient_disabled(fixtures)`
  - *Description*: Test that the negative binomial model works correctly with gradient disabled.
- **Function**: `test_negative_binomial_gradient_vs_no_gradient_consistency(fixtures)`
  - *Description*: Test that gradient and no-gradient approaches produce similar results.
- **Function**: `test_negative_binomial_gradient_function_correctness(fixtures)`
  - *Description*: Test that the gradient function produces reasonable gradients.
- **Function**: `test_negative_binomial_gradient_numerical_consistency(fixtures)`
  - *Description*: Test that analytical gradient matches numerical gradient using scipy.optimize.check_grad.
- **Function**: `test_negative_binomial_default_gradient_behavior(fixtures)`
  - *Description*: Test that gradient is enabled by default.
- **Function**: `test_negative_binomial_dispersion_parameter_bounds(fixtures)`
  - *Description*: Test that dispersion parameter stays within reasonable bounds.
### File: `test/test_model_poisson.py`

- **Function**: `test_poisson_model(fixtures)`
- **Function**: `test_poisson_minimizer_options(fixtures)`
- **Function**: `test_unfitted_raises_error(fixtures)`
- **Function**: `test_unfitted_repr(fixtures)`
- **Function**: `test_poisson_with_gradient_enabled(fixtures)`
  - *Description*: Test that the model works correctly with gradient enabled (default behavior).
- **Function**: `test_poisson_with_gradient_disabled(fixtures)`
  - *Description*: Test that the model works correctly with gradient disabled.
- **Function**: `test_gradient_vs_no_gradient_consistency(fixtures)`
  - *Description*: Test that gradient and no-gradient approaches produce similar results.
- **Function**: `test_gradient_function_correctness(fixtures)`
  - *Description*: Test that the gradient function produces reasonable gradients.
- **Function**: `test_poisson_gradient_numerical_consistency(fixtures)`
  - *Description*: Test that analytical gradient matches numerical gradient using scipy.optimize.check_grad.
- **Function**: `test_default_gradient_behavior(fixtures)`
  - *Description*: Test that gradient is enabled by default.
### File: `test/test_model_weibull.py`

- **Function**: `test_poisson_model(fixtures)`
- **Function**: `test_weibull_minimizer_options(fixtures)`
- **Function**: `test_unfitted_raises_error(fixtures)`
- **Function**: `test_unfitted_repr(fixtures)`
### File: `test/test_model_weibull_copula.py`

- **Class**: `TestWeibullCopulaGoalsModel`
  - *Description*: Test suite for WeibullCopulaGoalsModel.
  - **Method**: `setup_method(self)`
    - *Description*: Set up test data for each test method.
  - **Method**: `test_model_initialization(self)`
    - *Description*: Test that model initializes correctly.
  - **Method**: `test_gradient_accuracy(self)`
    - *Description*: Test gradient accuracy against numerical differentiation.
  - **Method**: `test_model_fitting_without_gradients(self)`
    - *Description*: Test model fitting without using gradients.
  - **Method**: `test_model_fitting_with_gradients(self)`
    - *Description*: Test model fitting using analytical gradients.
  - **Method**: `test_gradient_vs_no_gradient_consistency(self)`
    - *Description*: Test that gradient and non-gradient optimization give similar results.
  - **Method**: `test_gradient_default_behavior(self)`
    - *Description*: Test that gradients are used by default.
  - **Method**: `test_prediction_functionality(self)`
    - *Description*: Test model prediction capabilities.
  - **Method**: `test_model_representation(self)`
    - *Description*: Test model string representation.
  - **Method**: `test_gradient_function_output_shape(self)`
    - *Description*: Test that gradient function returns correct shape.
  - **Method**: `test_parameter_bounds_respected(self)`
    - *Description*: Test that fitted parameters respect the defined bounds.
  - **Method**: `test_model_with_different_max_goals(self)`
    - *Description*: Test model behavior with different max_goals settings.
  - **Method**: `test_loss_and_gradient_consistency(self)`
    - *Description*: Test that loss decreases when gradient points in descent direction.
- **Function**: `test_weibull_copula_comprehensive_validation()`
  - *Description*: Comprehensive validation test for WeibullCopulaGoalsModel.
### File: `test/test_model_zip.py`

- **Function**: `test_poisson_model(fixtures)`
- **Function**: `test_zip_minimizer_options(fixtures)`
- **Function**: `test_unfitted_raises_error(fixtures)`
- **Function**: `test_unfitted_repr(fixtures)`
- **Function**: `test_zip_with_gradient_enabled(fixtures)`
  - *Description*: Test that the Zero-Inflated Poisson model works correctly with gradient enabled (default behavior).
- **Function**: `test_zip_with_gradient_disabled(fixtures)`
  - *Description*: Test that the Zero-Inflated Poisson model works correctly with gradient disabled.
- **Function**: `test_zip_gradient_vs_no_gradient_consistency(fixtures)`
  - *Description*: Test that gradient and no-gradient approaches produce similar results.
- **Function**: `test_zip_gradient_function_correctness(fixtures)`
  - *Description*: Test that the gradient function produces reasonable gradients.
- **Function**: `test_zip_gradient_numerical_consistency(fixtures)`
  - *Description*: Test that analytical gradient matches numerical gradient using scipy.optimize.check_grad.
- **Function**: `test_zip_default_gradient_behavior(fixtures)`
  - *Description*: Test that gradient is enabled by default.
- **Function**: `test_zip_zero_inflation_parameter_bounds(fixtures)`
  - *Description*: Test that zero inflation parameter stays within reasonable bounds.
### File: `test/test_odds.py`

- **Function**: `test_convert_odds_american()`
  - *Description*: Test conversion from American odds
- **Function**: `test_convert_odds_fractional()`
  - *Description*: Test conversion from fractional odds
- **Function**: `test_convert_odds_decimal()`
  - *Description*: Test conversion from decimal odds (should be idempotent)
- **Function**: `test_convert_odds_enum()`
  - *Description*: Test conversion using OddsFormat enum
- **Function**: `test_convert_odds_invalid_format()`
  - *Description*: Test that an invalid format raises a ValueError
### File: `test/test_opta_client.py`

- **Class**: `TestOptaClient`
  - *Description*: Test cases for OptaClient class.
  - **Method**: `test_init_without_proxies(self)`
    - *Description*: Test OptaClient initialization without proxies.
  - **Method**: `test_init_with_proxies(self)`
    - *Description*: Test OptaClient initialization with proxies.
  - **Method**: `test_session_property_creates_session(self)`
    - *Description*: Test that session property creates a new session.
  - **Method**: `test_session_property_returns_existing_session(self)`
    - *Description*: Test that session property returns existing session.
  - **Method**: `test_session_property_with_proxies(self)`
    - *Description*: Test that session property configures proxies.
  - **Method**: `test_validate_credentials_valid(self)`
    - *Description*: Test credential validation with valid credentials.
  - **Method**: `test_validate_credentials_missing_auth_key(self)`
    - *Description*: Test credential validation with missing auth_key.
  - **Method**: `test_validate_credentials_missing_rt_mode(self)`
    - *Description*: Test credential validation with missing rt_mode.
  - **Method**: `test_validate_credentials_empty_values(self)`
    - *Description*: Test credential validation with empty values.
  - **Method**: `test_validate_credentials_none_values(self)`
    - *Description*: Test credential validation with None values.
  - **Method**: `test_make_request_success(self, mock_get)`
    - *Description*: Test successful API request.
  - **Method**: `test_make_request_with_params_and_headers(self, mock_get)`
    - *Description*: Test API request with parameters and headers.
  - **Method**: `test_make_request_404_error(self, mock_get)`
    - *Description*: Test 404 error handling.
  - **Method**: `test_make_request_http_error(self, mock_get)`
    - *Description*: Test HTTP error handling.
  - **Method**: `test_make_request_connection_error(self, mock_get)`
    - *Description*: Test connection error handling.
  - **Method**: `test_make_request_timeout_error(self, mock_get)`
    - *Description*: Test timeout error handling.
  - **Method**: `test_make_request_json_decode_error(self, mock_get)`
    - *Description*: Test JSON decode error handling.
  - **Method**: `test_make_request_api_error(self, mock_get)`
    - *Description*: Test API error response handling.
  - **Method**: `test_close_session_exists(self)`
    - *Description*: Test closing an existing session.
  - **Method**: `test_close_no_session(self)`
    - *Description*: Test closing when no session exists.
  - **Method**: `test_context_manager_success(self)`
    - *Description*: Test context manager functionality.
  - **Method**: `test_context_manager_with_exception(self)`
    - *Description*: Test context manager with exception.
  - **Method**: `test_session_reuse_after_close(self)`
    - *Description*: Test that new session is created after close.
### File: `test/test_opta_config.py`

- **Class**: `TestOptaConfig`
  - *Description*: Test cases for Opta configuration constants.
  - **Method**: `test_non_paginated_sources_is_set(self)`
    - *Description*: Test that NON_PAGINATED_SOURCES is a set.
  - **Method**: `test_non_paginated_sources_contains_expected_values(self)`
    - *Description*: Test that NON_PAGINATED_SOURCES contains expected endpoint types.
  - **Method**: `test_default_pagination_constants(self)`
    - *Description*: Test default pagination constants.
  - **Method**: `test_endpoint_configs_structure(self)`
    - *Description*: Test that ENDPOINT_CONFIGS has proper structure.
  - **Method**: `test_endpoint_configs_tournament_calendars(self)`
    - *Description*: Test tournament_calendars endpoint configuration.
  - **Method**: `test_endpoint_configs_match_stats_supports_multi(self)`
    - *Description*: Test that match_stats (player and team) supports multi-fixture.
  - **Method**: `test_parameter_mappings_structure(self)`
    - *Description*: Test that PARAMETER_MAPPINGS has proper structure.
  - **Method**: `test_parameter_mappings_contains_expected_sources(self)`
    - *Description*: Test that PARAMETER_MAPPINGS contains expected sources.
  - **Method**: `test_parameter_mappings_matches_basic_completeness(self)`
    - *Description*: Test matches_basic parameter mapping completeness.
  - **Method**: `test_response_parsers_structure(self)`
    - *Description*: Test that RESPONSE_PARSERS has proper structure.
  - **Method**: `test_response_parsers_contains_expected_sources(self)`
    - *Description*: Test that RESPONSE_PARSERS contains expected sources.
  - **Method**: `test_pagination_response_keys_structure(self)`
    - *Description*: Test that PAGINATION_RESPONSE_KEYS has proper structure.
  - **Method**: `test_pagination_response_keys_contains_expected_sources(self)`
    - *Description*: Test that PAGINATION_RESPONSE_KEYS contains expected sources.
  - **Method**: `test_pagination_response_keys_nested_paths(self)`
    - *Description*: Test that nested key paths are properly formatted.
  - **Method**: `test_endpoint_config_path_templates(self)`
    - *Description*: Test that all path templates are properly formatted.
  - **Method**: `test_parameter_mapping_consistency(self)`
    - *Description*: Test that parameter mappings are consistent with endpoint configs.
  - **Method**: `test_response_parser_consistency(self)`
    - *Description*: Test that response parsers are consistent with endpoint configs.
  - **Method**: `test_pagination_keys_consistency(self)`
    - *Description*: Test that pagination response keys are consistent with endpoint configs.
  - **Method**: `test_non_paginated_sources_consistency(self)`
    - *Description*: Test that non-paginated sources are consistent with endpoint configs.
  - **Method**: `test_tournament_calendars_status_variants_paths(self)`
    - *Description*: Test tournament_calendars status variants produce valid paths.
  - **Method**: `test_config_values_are_immutable(self)`
    - *Description*: Test that configuration constants are not accidentally modified.
### File: `test/test_opta_contrib.py`

- **Function**: `test_opta_events_plan()`
  - *Description*: Tests that the 'events' method builds the correct plan.
- **Function**: `test_opta_tournament_schedule_plan()`
  - *Description*: Tests that the 'tournament_schedule' method builds the correct plan.
- **Function**: `test_opta_match_plan()`
  - *Description*: Tests that the 'match' method builds the correct plan.
- **Function**: `test_opta_matches_plan_params()`
  - *Description*: Tests that the 'matches' method handles complex parameters correctly.
- **Function**: `test_opta_match_stats_player_plan()`
  - *Description*: Tests that the 'match_stats_player' method builds the correct plan.
- **Function**: `test_opta_match_stats_team_plan()`
  - *Description*: Tests that the 'match_stats_team' method builds the correct plan.
- **Function**: `test_opta_player_season_stats_plan()`
  - *Description*: Tests that 'player_season_stats' builds the correct plan.
- **Function**: `test_opta_proxies_passed_to_plan()`
  - *Description*: Tests that the 'proxies' param is passed through to the plan args.
- **Function**: `test_opta_teams_plan()`
  - *Description*: Tests that the 'teams' method builds the correct plan.
- **Function**: `test_opta_squads_plan()`
  - *Description*: Tests that the 'squads' method builds the correct plan.
- **Function**: `test_opta_tournament_calendars_plan()`
  - *Description*: Tests that the 'tournament_calendars' method builds the correct plan.
- **Function**: `test_opta_team_season_stats_plan()`
  - *Description*: Tests that 'team_season_stats' builds the correct plan.
- **Function**: `test_opta_matches_comprehensive_parameters()`
  - *Description*: Tests that 'matches' method handles all parameters correctly.
- **Function**: `test_opta_events_event_types()`
  - *Description*: Tests that 'events' method handles event_types parameter correctly.
- **Function**: `test_opta_custom_credentials_and_proxies()`
  - *Description*: Tests that custom credentials and proxies are passed through correctly.
- **Function**: `test_opta_optimize_parameter()`
  - *Description*: Tests that the optimize parameter is passed through correctly.
- **Function**: `test_format_opta_datetime()`
  - *Description*: Tests the _format_opta_datetime helper function.
- **Function**: `test_opta_tournament_calendars_all_parameters()`
  - *Description*: Tests tournament_calendars with all parameter combinations.
- **Function**: `test_opta_contestant_participation_plan()`
  - *Description*: Tests that the 'contestant_participation' method builds the correct plan.
- **Function**: `test_opta_areas_plan()`
  - *Description*: Tests that the 'areas' method builds the correct plan.
- **Function**: `test_opta_venues_plan()`
  - *Description*: Tests that the 'venues' method builds the correct plan.
- **Function**: `test_opta_player_career_plan()`
  - *Description*: Tests that the 'player_career' method builds the correct plan.
- **Function**: `test_opta_injuries_plan()`
  - *Description*: Tests that the 'injuries' method builds the correct plan.
- **Function**: `test_opta_referees_plan()`
  - *Description*: Tests that the 'referees' method builds the correct plan.
- **Function**: `test_opta_transfers_plan()`
  - *Description*: Tests that the 'transfers' method builds the correct plan.
### File: `test/test_opta_endpoints.py`

- **Class**: `TestOptaEndpointBuilder`
  - *Description*: Test cases for OptaEndpointBuilder class.
  - **Method**: `test_init(self)`
    - *Description*: Test OptaEndpointBuilder initialization.
  - **Method**: `test_build_request_details_unknown_source(self)`
    - *Description*: Test build_request_details with unknown source.
  - **Method**: `test_build_request_details_tournament_calendars_active(self)`
    - *Description*: Test tournament_calendars with active status.
  - **Method**: `test_build_request_details_tournament_calendars_all(self)`
    - *Description*: Test tournament_calendars with all status.
  - **Method**: `test_build_request_details_tournament_schedule(self)`
    - *Description*: Test tournament_schedule endpoint.
  - **Method**: `test_build_request_details_tournament_schedule_missing_uuid(self)`
    - *Description*: Test tournament_schedule with missing tournament_calendar_uuid.
  - **Method**: `test_build_request_details_match_basic(self)`
    - *Description*: Test match_basic endpoint.
  - **Method**: `test_build_request_details_match_basic_missing_uuid(self)`
    - *Description*: Test match_basic with missing fixture_uuid.
  - **Method**: `test_build_request_details_match_events(self)`
    - *Description*: Test match_events endpoint.
  - **Method**: `test_build_request_details_match_events_missing_uuid(self)`
    - *Description*: Test match_events with missing fixture_uuid.
  - **Method**: `test_build_request_details_match_stats_player(self)`
    - *Description*: Test match_stats_player endpoint.
  - **Method**: `test_build_request_details_match_stats_team(self)`
    - *Description*: Test match_stats_team endpoint.
  - **Method**: `test_build_request_details_matches_basic(self)`
    - *Description*: Test matches_basic endpoint.
  - **Method**: `test_build_request_details_teams(self)`
    - *Description*: Test teams endpoint.
  - **Method**: `test_build_request_details_squads(self)`
    - *Description*: Test squads endpoint.
  - **Method**: `test_build_request_details_player_season_stats(self)`
    - *Description*: Test player_season_stats endpoint.
  - **Method**: `test_build_request_details_team_season_stats(self)`
    - *Description*: Test team_season_stats endpoint.
  - **Method**: `test_build_parameters_boolean_conversion(self)`
    - *Description*: Test boolean parameter conversion to yes/no.
  - **Method**: `test_build_parameters_list_conversion(self)`
    - *Description*: Test list parameter conversion to comma-separated strings.
  - **Method**: `test_build_parameters_event_types_list(self)`
    - *Description*: Test event_types list conversion.
  - **Method**: `test_build_parameters_none_values_filtered(self)`
    - *Description*: Test that None values are filtered out of parameters.
  - **Method**: `test_build_request_details_tournament_calendars_extra_params(self)`
    - *Description*: Test tournament_calendars with extra parameters.
  - **Method**: `test_extract_path_params_tournament_schedule(self)`
    - *Description*: Test _extract_path_params for tournament_schedule.
  - **Method**: `test_extract_path_params_match_basic(self)`
    - *Description*: Test _extract_path_params for match_basic.
  - **Method**: `test_extract_path_params_match_events(self)`
    - *Description*: Test _extract_path_params for match_events.
  - **Method**: `test_build_parameters_default_format(self)`
    - *Description*: Test that _fmt=json is always included.
  - **Method**: `test_build_request_details_empty_args(self)`
    - *Description*: Test build_request_details with minimal args.
### File: `test/test_opta_exceptions.py`

- **Class**: `TestOptaAPIError`
  - *Description*: Test cases for OptaAPIError base exception.
  - **Method**: `test_inheritance(self)`
    - *Description*: Test that OptaAPIError inherits from Exception.
  - **Method**: `test_instantiation_without_message(self)`
    - *Description*: Test OptaAPIError instantiation without message.
  - **Method**: `test_instantiation_with_message(self)`
    - *Description*: Test OptaAPIError instantiation with message.
  - **Method**: `test_instantiation_with_args(self)`
    - *Description*: Test OptaAPIError instantiation with multiple args.
  - **Method**: `test_exception_chaining(self)`
    - *Description*: Test exception chaining with OptaAPIError.
- **Class**: `TestOptaAuthenticationError`
  - *Description*: Test cases for OptaAuthenticationError.
  - **Method**: `test_inheritance(self)`
    - *Description*: Test that OptaAuthenticationError inherits from OptaAPIError.
  - **Method**: `test_instantiation_without_message(self)`
    - *Description*: Test OptaAuthenticationError instantiation without message.
  - **Method**: `test_instantiation_with_message(self)`
    - *Description*: Test OptaAuthenticationError instantiation with message.
  - **Method**: `test_exception_chaining(self)`
    - *Description*: Test exception chaining with OptaAuthenticationError.
  - **Method**: `test_catch_as_base_exception(self)`
    - *Description*: Test that OptaAuthenticationError can be caught as OptaAPIError.
- **Class**: `TestOptaRequestError`
  - *Description*: Test cases for OptaRequestError.
  - **Method**: `test_inheritance(self)`
    - *Description*: Test that OptaRequestError inherits from OptaAPIError.
  - **Method**: `test_instantiation_without_message(self)`
    - *Description*: Test OptaRequestError instantiation without message.
  - **Method**: `test_instantiation_with_message(self)`
    - *Description*: Test OptaRequestError instantiation with message.
  - **Method**: `test_exception_chaining(self)`
    - *Description*: Test exception chaining with OptaRequestError.
  - **Method**: `test_catch_as_base_exception(self)`
    - *Description*: Test that OptaRequestError can be caught as OptaAPIError.
- **Class**: `TestOptaParsingError`
  - *Description*: Test cases for OptaParsingError.
  - **Method**: `test_inheritance(self)`
    - *Description*: Test that OptaParsingError inherits from OptaAPIError.
  - **Method**: `test_instantiation_without_message(self)`
    - *Description*: Test OptaParsingError instantiation without message.
  - **Method**: `test_instantiation_with_message(self)`
    - *Description*: Test OptaParsingError instantiation with message.
  - **Method**: `test_exception_chaining(self)`
    - *Description*: Test exception chaining with OptaParsingError.
  - **Method**: `test_catch_as_base_exception(self)`
    - *Description*: Test that OptaParsingError can be caught as OptaAPIError.
- **Class**: `TestOptaConfigurationError`
  - *Description*: Test cases for OptaConfigurationError.
  - **Method**: `test_inheritance(self)`
    - *Description*: Test that OptaConfigurationError inherits from OptaAPIError.
  - **Method**: `test_instantiation_without_message(self)`
    - *Description*: Test OptaConfigurationError instantiation without message.
  - **Method**: `test_instantiation_with_message(self)`
    - *Description*: Test OptaConfigurationError instantiation with message.
  - **Method**: `test_exception_chaining(self)`
    - *Description*: Test exception chaining with OptaConfigurationError.
  - **Method**: `test_catch_as_base_exception(self)`
    - *Description*: Test that OptaConfigurationError can be caught as OptaAPIError.
- **Class**: `TestExceptionHierarchy`
  - *Description*: Test cases for exception hierarchy and relationships.
  - **Method**: `test_all_exceptions_inherit_from_base(self)`
    - *Description*: Test that all custom exceptions inherit from OptaAPIError.
  - **Method**: `test_exception_type_checking(self)`
    - *Description*: Test exception type checking with isinstance.
  - **Method**: `test_exception_catching_specificity(self)`
    - *Description*: Test that exceptions can be caught with appropriate specificity.
  - **Method**: `test_exception_message_formatting(self)`
    - *Description*: Test exception message formatting with different input types.
  - **Method**: `test_exception_repr(self)`
    - *Description*: Test exception __repr__ method.
  - **Method**: `test_multiple_exception_inheritance(self)`
    - *Description*: Test that exceptions can inherit from multiple levels.
  - **Method**: `test_exception_attributes(self)`
    - *Description*: Test that exceptions have expected attributes.
  - **Method**: `test_exception_with_none_cause(self)`
    - *Description*: Test exception with explicit None cause.
### File: `test/test_opta_integration.py`

- **Function**: `test_fetch_tournament_calendars_active()`
- **Function**: `test_fetch_tournament_calendars_all()`
- **Function**: `test_fetch_tournament_calendars_authorized()`
- **Function**: `test_venue_tmcl()`
- **Function**: `test_venue_contestant()`
- **Function**: `test_venue_venue()`
- **Function**: `test_areas_all()`
- **Function**: `test_areas_area()`
- **Function**: `test_tournament_schedule_tcml()`
- **Function**: `test_matches_tmcl()`
- **Function**: `test_matches_single_fixture()`
- **Function**: `test_matches_multiple_fixtures()`
- **Function**: `test_matches_contestant()`
- **Function**: `test_matches_contestant_home()`
- **Function**: `test_matches_contestant_date_str()`
- **Function**: `test_matches_lineups()`
- **Function**: `test_matches_contestant_date_error()`
- **Function**: `test_matches_contestant_date_dt()`
- **Function**: `test_parser_ma1_match_basic()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> parse_match_basic
- **Function**: `test_parser_ma1_match_lineups()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> parse_match_basic
- **Function**: `test_parser_ma1_match_not_lineups()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> parse_match_basic
- **Function**: `test_parser_ma1_match_not_live()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> parse_match_basic
- **Function**: `test_fetch_match_events()`
- **Function**: `test_parser_ma2_match_stats_players()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> parse_match_stats_player
- **Function**: `test_parser_ma2_match_stats_players_multiple()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> parse_match_stats_player
- **Function**: `test_parser_ma2_match_stats_teams()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> parse_match_stats_team
- **Function**: `test_parser_ma2_match_stats_teams_multiple()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> parse_match_stats_team
- **Function**: `test_parser_ma0_tournament_schedule()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> parse_tournament_schedule
- **Function**: `test_parser_ma3_match_events()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> extract_match_events
- **Function**: `test_parser_ma3_match_events_contestant()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> extract_match_events
- **Function**: `test_parser_ma3_match_events_person()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> extract_match_events
- **Function**: `test_parser_tm4_player_season_stats()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> extract_season_player_stats
- **Function**: `test_parser_tm4_team_season_stats()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> extract_season_team_stats
- **Function**: `test_parser_tm16_contestant_participation()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> extract_contestant_participation
- **Function**: `test_parser_tm16_contestant_participation_multiple()`
  - *Description*: Tests: _handle_non_paginated_endpoint -> extract_contestant_participation
- **Function**: `test_dynamic_pagination_transfers_paginated()`
  - *Description*: Tests: is_paginated('transfers', ...) == True
- **Function**: `test_dynamic_pagination_transfers_paginated_tmcl()`
  - *Description*: Tests: is_paginated('transfers', ...) == True
- **Function**: `test_dynamic_pagination_transfers_paginated_dates()`
  - *Description*: Tests: is_paginated('transfers', ...) == True with valid date parameters
- **Function**: `test_dynamic_pagination_transfers_non_paginated()`
  - *Description*: Tests: is_paginated('transfers', ...) == False
- **Function**: `test_params_tournament_calendars_status()`
  - *Description*: Tests: 'status' param in tournament_calendars
- **Function**: `test_params_events_by_type()`
  - *Description*: Tests: 'event_types' param in events
- **Function**: `test_error_handling_404_not_found()`
  - *Description*: Tests: OptaClient.make_request for 404
- **Function**: `test_error_handling_auth_failure(monkeypatch)`
  - *Description*: Tests: OptaClient.make_request for auth error
- **Function**: `test_transfers_validation_invalid_date_combinations()`
  - *Description*: Tests: transfers() method validation for invalid parameter combinations
- **Function**: `test_transfers_validation_no_filters()`
  - *Description*: Tests: transfers() method validation when no filters are provided
- **Function**: `test_transfers_validation_valid_combinations()`
  - *Description*: Tests: transfers() method should accept valid parameter combinations
- **Function**: `test_player_career_person()`
  - *Description*: Tests: player_career() with person_uuid (non-paginated)
- **Function**: `test_player_career_contestant()`
  - *Description*: Tests: player_career() with contestant_uuid (paginated)
- **Function**: `test_player_career_contestant_inactive()`
  - *Description*: Tests: player_career() with contestant_uuid and active=False
- **Function**: `test_player_career_opta_names()`
  - *Description*: Tests: player_career() with use_opta_names=True
- **Function**: `test_player_career_validation()`
  - *Description*: Tests: player_career() parameter validation
- **Function**: `test_teams_tournament_calendar()`
  - *Description*: Tests: teams() with tournament_calendar_uuid
- **Function**: `test_teams_contestant()`
  - *Description*: Tests: teams() with contestant_uuid
- **Function**: `test_teams_validation()`
  - *Description*: Tests: teams() parameter validation
- **Function**: `test_squads_tournament_calendar()`
  - *Description*: Tests: squads() with tournament_calendar_uuid
- **Function**: `test_squads_contestant()`
  - *Description*: Tests: squads() with contestant_uuid
- **Function**: `test_squads_opta_names()`
  - *Description*: Tests: squads() with use_opta_names=True
- **Function**: `test_squads_validation()`
  - *Description*: Tests: squads() parameter validation
- **Function**: `test_referees_person()`
  - *Description*: Tests: referees() with person_uuid
- **Function**: `test_referees_tournament_calendar()`
  - *Description*: Tests: referees() with tournament_calendar_uuid
- **Function**: `test_referees_opta_names()`
  - *Description*: Tests: referees() with use_opta_names=True
- **Function**: `test_referees_validation()`
  - *Description*: Tests: referees() parameter validation
- **Function**: `test_tournament_schedule_coverage_level_single()`
  - *Description*: Tests: tournament_schedule() with single coverage_level
- **Function**: `test_tournament_schedule_coverage_level_list()`
  - *Description*: Tests: tournament_schedule() with list of coverage_levels
- **Function**: `test_tournament_schedule_opta_names()`
  - *Description*: Tests: tournament_schedule() with use_opta_names=True
- **Function**: `test_matches_competition_uuids()`
  - *Description*: Tests: matches() with competition_uuids parameter
- **Function**: `test_matches_opponent_uuid()`
  - *Description*: Tests: matches() with opponent_uuid parameter
- **Function**: `test_matches_contestant_position_away()`
  - *Description*: Tests: matches() with contestant_position="away"
- **Function**: `test_matches_delta_timestamp()`
  - *Description*: Tests: matches() with delta_timestamp parameter
- **Function**: `test_tournament_calendars_competition_uuid()`
  - *Description*: Tests: tournament_calendars() with competition_uuid parameter
- **Function**: `test_tournament_calendars_contestant_uuid()`
  - *Description*: Tests: tournament_calendars() with contestant_uuid parameter
- **Function**: `test_tournament_calendars_include_coverage()`
  - *Description*: Tests: tournament_calendars() with include_coverage=True
- **Function**: `test_events_event_types_single()`
  - *Description*: Tests: events() with single event_type
- **Function**: `test_events_opta_names()`
  - *Description*: Tests: events() with use_opta_names=True
- **Function**: `test_rankings_tmcl()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_rankings_tmcl_opta_names()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_pass_matrix()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_pass_matrix_opta_names()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_possession()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_possession_opta_names()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_live()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_total()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_home()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_away()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_form_total()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_form_home()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_form_away()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_half_time_total()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_half_time_home()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_half_time_away()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_attendance()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_over_under()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_relegation()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
- **Function**: `test_team_standings_championship()`
  - *Description*: Tests: rankings() with tournament_calendar_uuid
### File: `test/test_opta_paginator.py`

- **Class**: `TestOptaPaginator`
  - *Description*: Test cases for OptaPaginator class.
  - **Method**: `test_init(self)`
    - *Description*: Test OptaPaginator initialization.
  - **Method**: `test_is_paginated_true(self)`
    - *Description*: Test is_paginated returns True for paginated sources.
  - **Method**: `test_is_paginated_false(self)`
    - *Description*: Test is_paginated returns False for non-paginated sources.
  - **Method**: `test_fetch_paginated_data_success(self)`
    - *Description*: Test successful paginated data fetching.
  - **Method**: `test_fetch_paginated_data_empty_response(self)`
    - *Description*: Test paginated data fetching with empty response.
  - **Method**: `test_fetch_paginated_data_no_records_key(self)`
    - *Description*: Test paginated data fetching when no records key found.
  - **Method**: `test_fetch_paginated_data_request_exception(self)`
    - *Description*: Test paginated data fetching with request exception.
  - **Method**: `test_extract_records_from_page_simple_key(self)`
    - *Description*: Test _extract_records_from_page with simple key.
  - **Method**: `test_extract_records_from_page_nested_key(self)`
    - *Description*: Test _extract_records_from_page with nested key.
  - **Method**: `test_extract_records_from_page_multiple_keys_first_match(self)`
    - *Description*: Test _extract_records_from_page with multiple keys, first matches.
  - **Method**: `test_extract_records_from_page_multiple_keys_second_match(self)`
    - *Description*: Test _extract_records_from_page with multiple keys, second matches.
  - **Method**: `test_extract_records_from_page_no_records(self)`
    - *Description*: Test _extract_records_from_page with no records found.
  - **Method**: `test_extract_records_from_page_non_list_value(self)`
    - *Description*: Test _extract_records_from_page when key exists but value is not a list.
  - **Method**: `test_extract_records_from_page_nested_path_missing_intermediate(self)`
    - *Description*: Test _extract_records_from_page with missing intermediate key in nested path.
  - **Method**: `test_extract_records_from_page_nested_path_wrong_type(self)`
    - *Description*: Test _extract_records_from_page with wrong type in nested path.
  - **Method**: `test_extract_records_from_page_unknown_source(self)`
    - *Description*: Test _extract_records_from_page with unknown source.
  - **Method**: `test_extract_records_from_page_exception_handling(self)`
    - *Description*: Test _extract_records_from_page exception handling.
  - **Method**: `test_extract_records_from_page_tournament_calendars(self)`
    - *Description*: Test _extract_records_from_page for tournament_calendars source.
  - **Method**: `test_extract_records_from_page_teams(self)`
    - *Description*: Test _extract_records_from_page for teams source.
  - **Method**: `test_extract_records_from_page_teams_fallback(self)`
    - *Description*: Test _extract_records_from_page for teams source with fallback.
  - **Method**: `test_extract_records_from_page_squads(self)`
    - *Description*: Test _extract_records_from_page for squads source.
  - **Method**: `test_extract_records_from_page_squads_fallback(self)`
    - *Description*: Test _extract_records_from_page for squads source with fallback.
  - **Method**: `test_fetch_paginated_data_single_page(self)`
    - *Description*: Test fetching a single page of data.
  - **Method**: `test_fetch_paginated_data_exact_page_size(self)`
    - *Description*: Test paginated data fetching with exact page size match.
  - **Method**: `test_fetch_paginated_data_parameters_preserved(self)`
    - *Description*: Test that base parameters are preserved in pagination requests.
### File: `test/test_opta_parsers.py`

- **Class**: `TestFlattenStats`
  - *Description*: Test cases for flatten_stats function.
  - **Method**: `test_flatten_stats_basic(self)`
    - *Description*: Test basic stats flattening.
  - **Method**: `test_flatten_stats_with_name_key(self)`
    - *Description*: Test stats flattening with 'name' key.
  - **Method**: `test_flatten_stats_with_float_conversion(self)`
    - *Description*: Test stats flattening with float conversion.
  - **Method**: `test_flatten_stats_with_invalid_float(self)`
    - *Description*: Test stats flattening with invalid float values.
  - **Method**: `test_flatten_stats_empty_list(self)`
    - *Description*: Test stats flattening with empty list.
  - **Method**: `test_flatten_stats_missing_keys(self)`
    - *Description*: Test stats flattening with missing keys.
  - **Method**: `test_flatten_stats_none_values(self)`
    - *Description*: Test stats flattening with None values.
- **Class**: `TestExtractPlayerStats`
  - *Description*: Test cases for extract_player_stats function.
  - **Method**: `test_extract_player_stats_basic(self)`
    - *Description*: Test basic player stats extraction.
  - **Method**: `test_extract_player_stats_multiple_teams(self)`
    - *Description*: Test player stats extraction with multiple teams.
  - **Method**: `test_extract_player_stats_no_stats(self)`
    - *Description*: Test player stats extraction with no stats.
  - **Method**: `test_extract_player_stats_empty_lineup(self)`
    - *Description*: Test player stats extraction with empty lineup.
  - **Method**: `test_extract_player_stats_missing_live_data(self)`
    - *Description*: Test player stats extraction with missing liveData.
- **Class**: `TestExtractTeamStats`
  - *Description*: Test cases for extract_team_stats function.
  - **Method**: `test_extract_team_stats_basic(self)`
    - *Description*: Test basic team stats extraction.
  - **Method**: `test_extract_team_stats_multiple_teams(self)`
    - *Description*: Test team stats extraction with multiple teams.
  - **Method**: `test_extract_team_stats_no_stats(self)`
    - *Description*: Test team stats extraction with no stats.
- **Class**: `TestExtractMatchEvents`
  - *Description*: Test cases for extract_match_events function.
  - **Method**: `test_extract_match_events_basic(self)`
    - *Description*: Test basic match events extraction.
  - **Method**: `test_extract_match_events_nested_structure(self)`
    - *Description*: Test match events extraction with nested structure.
  - **Method**: `test_extract_match_events_no_events(self)`
    - *Description*: Test match events extraction with no events.
  - **Method**: `test_extract_match_events_missing_live_data(self)`
    - *Description*: Test match events extraction with missing liveData.
- **Class**: `TestExtractSeasonPlayerStats`
  - *Description*: Test cases for extract_season_player_stats function.
  - **Method**: `test_extract_season_player_stats_basic(self)`
    - *Description*: Test basic season player stats extraction.
  - **Method**: `test_extract_season_player_stats_multiple_players(self)`
    - *Description*: Test season player stats extraction with multiple players.
  - **Method**: `test_extract_season_player_stats_no_player_data(self)`
    - *Description*: Test season player stats extraction with no player data.
- **Class**: `TestExtractSeasonTeamStats`
  - *Description*: Test cases for extract_season_team_stats function.
  - **Method**: `test_extract_season_team_stats_basic(self)`
    - *Description*: Test basic season team stats extraction.
  - **Method**: `test_extract_season_team_stats_with_nested_players(self)`
    - *Description*: Test season team stats extraction with nested player data.
  - **Method**: `test_extract_season_team_stats_no_team_data(self)`
    - *Description*: Test season team stats extraction with no team data.
- **Class**: `TestParseTournamentSchedule`
  - *Description*: Test cases for parse_tournament_schedule function.
  - **Method**: `test_parse_tournament_schedule_basic(self)`
    - *Description*: Test basic tournament schedule parsing.
  - **Method**: `test_parse_tournament_schedule_empty_dates(self)`
    - *Description*: Test tournament schedule parsing with empty match dates.
  - **Method**: `test_parse_tournament_schedule_no_matches_in_date(self)`
    - *Description*: Test tournament schedule parsing with no matches in date.
- **Class**: `TestParseMatchBasic`
  - *Description*: Test cases for parse_match_basic function.
  - **Method**: `test_parse_match_basic(self)`
    - *Description*: Test basic match parsing.
- **Class**: `TestParseMatchStatsBasic`
  - *Description*: Test cases for parse_match_stats_basic function.
  - **Method**: `test_parse_match_stats_basic_single_match(self)`
    - *Description*: Test match stats parsing with single match.
  - **Method**: `test_parse_match_stats_basic_single_match_no_players(self)`
    - *Description*: Test match stats parsing with single match, no players.
  - **Method**: `test_parse_match_stats_basic_multiple_matches(self)`
    - *Description*: Test match stats parsing with multiple matches.
  - **Method**: `test_parse_match_stats_basic_empty_data(self)`
    - *Description*: Test match stats parsing with empty data.
### File: `test/test_opta_source.py`

- **Function**: `load_sample_json(filename)`
  - *Description*: Loads a sample JSON file from the tests/data/opta directory.
- **Function**: `test_build_request_events()`
  - *Description*: Tests OptaEndpointBuilder for MA3 Events.
- **Function**: `test_build_request_matches_filters()`
  - *Description*: Tests OptaEndpointBuilder for MA1 with multiple filters.
- **Function**: `test_build_request_calendars_active()`
  - *Description*: Tests OptaEndpointBuilder for OT2 special URL.
- **Function**: `test_from_opta_non_paginated(mock_OptaClient)`
  - *Description*: Tests a single non-paginated feed (e.g., MA3 Events).
- **Function**: `test_from_opta_paginated(mock_OptaPaginator)`
  - *Description*: Tests a paginated feed (e.g., OT2) and flattens the items.
- **Function**: `test_from_opta_proxies(mock_OptaClient)`
  - *Description*: Tests that the proxies dict is correctly passed to the session.
- **Function**: `test_from_opta_ma2_player_parsing_logic(mock_OptaClient)`
  - *Description*: Tests that MA2 (match_stats_player) calls correct helper.
- **Function**: `test_from_opta_ma2_team_parsing_logic(mock_OptaClient)`
  - *Description*: Tests that MA2 (match_stats_team) calls correct helper.
### File: `test/test_params_api.py`

- **Function**: `sample_data()`
  - *Description*: Create sample match data for testing.
- **Class**: `TestParamsArrayProperty`
  - *Description*: Tests for the params_array property.
  - **Method**: `test_params_array_returns_copy(self, sample_data)`
    - *Description*: params_array should return a copy, not a reference.
  - **Method**: `test_params_array_modification_does_not_affect_model(self, sample_data)`
    - *Description*: Modifying params_array should not affect the model.
  - **Method**: `test_params_array_raises_when_not_fitted(self, sample_data)`
    - *Description*: params_array should raise ValueError when model is not fitted.
  - **Method**: `test_params_array_length_matches_n_params(self, sample_data)`
    - *Description*: params_array length should match n_params after fitting.
- **Class**: `TestParamIndicesMethod`
  - *Description*: Tests for the param_indices method.
  - **Method**: `test_param_indices_contains_attack_defense_slices(self, sample_data)`
    - *Description*: param_indices should contain attack and defense slices.
  - **Method**: `test_param_indices_slices_are_correct(self, sample_data)`
    - *Description*: Attack and defense slices should match expected ranges.
  - **Method**: `test_param_indices_raises_when_not_fitted(self, sample_data)`
    - *Description*: param_indices should raise ValueError when model is not fitted.
- **Class**: `TestPoissonParamIndices`
  - *Description*: Tests for Poisson model parameter indices.
  - **Method**: `test_poisson_tail_indices(self, sample_data)`
    - *Description*: Poisson should have home_advantage at -1.
- **Class**: `TestDixonColesParamIndices`
  - *Description*: Tests for Dixon-Coles model parameter indices.
  - **Method**: `test_dixon_coles_tail_indices(self, sample_data)`
    - *Description*: DixonColes should have home_advantage at -2 and rho at -1.
- **Class**: `TestNegativeBinomialParamIndices`
  - *Description*: Tests for Negative Binomial model parameter indices.
  - **Method**: `test_negative_binomial_tail_indices(self, sample_data)`
    - *Description*: NegativeBinomial should have home_advantage at -2 and dispersion at -1.
- **Class**: `TestZeroInflatedPoissonParamIndices`
  - *Description*: Tests for Zero-Inflated Poisson model parameter indices.
  - **Method**: `test_zip_tail_indices(self, sample_data)`
    - *Description*: ZIP should have home_advantage at -2 and zero_inflation at -1.
- **Class**: `TestBivariateParamIndices`
  - *Description*: Tests for Bivariate Poisson model parameter indices.
  - **Method**: `test_bivariate_tail_indices(self, sample_data)`
    - *Description*: Bivariate should have home_advantage at -2 and correlation at -1.
- **Class**: `TestWeibullCopulaParamIndices`
  - *Description*: Tests for Weibull Copula model parameter indices.
  - **Method**: `test_weibull_copula_tail_indices(self, sample_data)`
    - *Description*: WeibullCopula should have home_advantage at -3, shape at -2, kappa at -1.
- **Class**: `TestParamIndicesConsistency`
  - *Description*: Tests that param_indices matches actual parameter layout.
  - **Method**: `test_poisson_indices_match_param_names(self, sample_data)`
    - *Description*: Verify Poisson indices match the documented param_names.
  - **Method**: `test_dixon_coles_indices_match_param_names(self, sample_data)`
    - *Description*: Verify DixonColes indices match the documented param_names.
  - **Method**: `test_negative_binomial_indices_match_param_names(self, sample_data)`
    - *Description*: Verify NegativeBinomial indices match the documented param_names.
  - **Method**: `test_zip_indices_match_param_names(self, sample_data)`
    - *Description*: Verify ZIP indices match the documented param_names.
  - **Method**: `test_bivariate_indices_match_param_names(self, sample_data)`
    - *Description*: Verify Bivariate indices match the documented param_names.
  - **Method**: `test_weibull_copula_indices_match_param_names(self, sample_data)`
    - *Description*: Verify WeibullCopula indices match the documented param_names.
- **Class**: `TestParamsArrayIntegration`
  - *Description*: Integration tests demonstrating real-world usage patterns.
  - **Method**: `test_extract_team_parameters_with_indices(self, sample_data)`
    - *Description*: Demonstrate extracting team-specific parameters using indices.
  - **Method**: `test_apply_factor_to_parameters(self, sample_data)`
    - *Description*: Demonstrate applying factors to parameters (climate adjustment use case).
  - **Method**: `test_consistent_indices_across_fits(self, sample_data)`
    - *Description*: Indices should be consistent across multiple fits.
### File: `test/test_pi_ratings.py`

- **Function**: `pi_rating()`
  - *Description*: Fixture to initialize the PiRatingSystem instance for tests.
- **Function**: `test_initialize_team(pi_rating)`
  - *Description*: Test if team ratings are correctly initialized.
- **Function**: `test_expected_goal_difference(pi_rating)`
  - *Description*: Test expected goal difference calculation.
- **Function**: `test_diminishing_error(pi_rating)`
  - *Description*: Test diminishing error function.
- **Function**: `test_update_ratings(pi_rating)`
  - *Description*: Test if team ratings update correctly after a match.
- **Function**: `test_calculate_probabilities(pi_rating)`
  - *Description*: Test probability calculations for a match.
- **Function**: `test_get_team_rating(pi_rating)`
  - *Description*: Test retrieving the average team rating.
- **Function**: `test_display_ratings(capsys, pi_rating)`
  - *Description*: Test that the display function prints correct output.
### File: `test/test_pitch.py`

- **Function**: `default_pitch()`
  - *Description*: Fixture providing a default Pitch instance with StatsBomb dimensions.
- **Function**: `custom_pitch()`
  - *Description*: Fixture providing a Pitch instance with custom parameters.
- **Function**: `sample_dataframe()`
  - *Description*: Fixture providing a sample DataFrame for plotting tests.
- **Class**: `TestPitchInitialization`
  - *Description*: Tests for Pitch class initialization.
  - **Method**: `test_default_initialization(self, default_pitch)`
    - *Description*: Test that Pitch initializes with default parameters.
  - **Method**: `test_custom_initialization(self, custom_pitch)`
    - *Description*: Test that Pitch initializes with custom parameters.
  - **Method**: `test_custom_dimensions_initialization(self)`
    - *Description*: Test that Pitch initializes with custom PitchDimensions instance.
  - **Method**: `test_invalid_view_raises_error(self)`
    - *Description*: Test that invalid view parameter raises ValueError.
- **Class**: `TestPitchLayerManagement`
  - *Description*: Tests for layer management methods.
  - **Method**: `test_add_layer(self, default_pitch, sample_dataframe)`
    - *Description*: Test that _add_layer adds items to the specified layer.
  - **Method**: `test_set_layer_visibility(self, default_pitch)`
    - *Description*: Test that set_layer_visibility shows/hides layers.
  - **Method**: `test_remove_layer(self, default_pitch)`
    - *Description*: Test that remove_layer removes a layer completely.
  - **Method**: `test_set_layer_order(self, default_pitch)`
    - *Description*: Test that set_layer_order reorders layers correctly.
- **Class**: `TestPitchPlottingMethods`
  - *Description*: Tests for plotting methods.
  - **Method**: `test_plot_scatter(self, default_pitch, sample_dataframe)`
    - *Description*: Test that plot_scatter returns a Scatter trace and adds it to the 'scatter' layer.
  - **Method**: `test_plot_heatmap(self, default_pitch, sample_dataframe)`
    - *Description*: Test that plot_heatmap returns a Histogram2d trace and adds it to the 'heatmap' layer.
  - **Method**: `test_plot_kde(self, default_pitch, sample_dataframe)`
    - *Description*: Test that plot_kde returns a Heatmap trace and adds it to the 'kde' layer.
  - **Method**: `test_plot_comets(self, default_pitch)`
    - *Description*: Test that plot_comets returns a list of Scatter traces and adds them to the 'comets' layer.
  - **Method**: `test_plot_arrows(self, default_pitch)`
    - *Description*: Test that plot_arrows returns a list of annotation dicts and adds them to the 'arrows' layer.
- **Class**: `TestPitchSaveMethod`
  - *Description*: Tests for the save method of the Pitch class.
  - **Method**: `test_save_method_exists(self, default_pitch)`
    - *Description*: Test that the save method exists and is callable.
  - **Method**: `test_save_format_inference(self, default_pitch, file_format, monkeypatch, tmp_path)`
    - *Description*: Test that the save method correctly infers the format from the file extension.
  - **Method**: `test_save_explicit_format(self, default_pitch, monkeypatch, tmp_path)`
    - *Description*: Test that the save method uses the explicitly provided format.
  - **Method**: `test_save_invalid_extension(self, default_pitch, tmp_path)`
    - *Description*: Test that the save method raises ValueError for unrecognized file extensions.
  - **Method**: `test_save_custom_dimensions(self, default_pitch, monkeypatch)`
    - *Description*: Test that the save method uses custom dimensions when provided.
  - **Method**: `test_save_default_dimensions(self, default_pitch, monkeypatch)`
    - *Description*: Test that the save method uses the pitch's dimensions when not provided.
  - **Method**: `test_save_additional_kwargs(self, default_pitch, monkeypatch)`
    - *Description*: Test that the save method passes additional kwargs to write_image.
### File: `test/test_poisson_weighted_gradient.py`

- **Function**: `test_poisson_gradient_with_weights(fixtures)`
  - *Description*: Test that the Poisson gradient correctly uses weights.
- **Function**: `test_poisson_gradient_weighted_vs_unweighted_consistency(fixtures)`
  - *Description*: Test that gradient with uniform weights matches unweighted gradient.
- **Function**: `test_poisson_gradient_numerical_check_with_weights(fixtures)`
  - *Description*: Test that analytical gradient matches numerical gradient when using weights.
- **Function**: `test_poisson_gradient_zero_weights(fixtures)`
  - *Description*: Test that gradient handles zero weights correctly.
- **Function**: `test_poisson_gradient_extreme_weights(fixtures)`
  - *Description*: Test that gradient handles extreme weight values correctly.
### File: `test/test_ratings_colley.py`

- **Function**: `test_colley(fixtures)`
### File: `test/test_ratings_massey.py`

- **Function**: `test_massey(fixtures)`
### File: `test/test_sampler_api.py`

- **Function**: `dummy_log_prob(params, data)`
  - *Description*: Simple multivariate normal log-prob.
- **Function**: `log_prob_inf(params, data)`
  - *Description*: Test that the sampler handles -inf and +inf gracefully.
- **Function**: `log_prob_nan(params, data)`
  - *Description*: Test that the sampler handles NaN returning from log_prob_func.
- **Function**: `log_prob_simple(params, data)`
  - *Description*: Test with extreme parameter values.
- **Function**: `log_prob_extreme(params, data)`
  - *Description*: Test with extreme log-probability values.
- **Function**: `log_prob_plus_inf(params, data)`
  - *Description*: Test that the sampler handles +inf log-probabilities.
- **Function**: `log_prob_small(params, data)`
  - *Description*: Test with very small parameter values.
- **Function**: `log_prob_high_dim(params, data)`
  - *Description*: Test with high dimensions.
- **Function**: `test_ensemble_sampler_validation()`
  - *Description*: Test input validation in EnsembleSampler.
- **Function**: `test_sampler_execution()`
  - *Description*: Test that the sampler actually runs and returns results.
- **Function**: `test_chain_get_samples_error()`
  - *Description*: Test that get_samples raises error if chain hasn't run.
- **Function**: `test_ensemble_sampler_posterior_error()`
  - *Description*: Test that get_posterior raises error if sampler hasn't run.
- **Function**: `test_sampler_handles_inf()`
  - *Description*: Test that the sampler handles -inf and +inf gracefully.
- **Function**: `test_sampler_handles_nan()`
  - *Description*: Test that the sampler handles NaN returning from log_prob_func.
- **Function**: `test_sampler_extreme_parameters()`
  - *Description*: Test with extreme parameter values.
- **Function**: `test_sampler_extreme_log_probs()`
  - *Description*: Test with extreme log-probability values.
- **Function**: `test_sampler_handles_plus_inf()`
  - *Description*: Test that the sampler handles +inf log-probabilities.
- **Function**: `test_sampler_small_log_probs()`
  - *Description*: Test with very small parameter values.
- **Function**: `test_sampler_high_dim()`
  - *Description*: Test with high dimensions.
### File: `test/test_sampler_numerical.py`

- **Function**: `log_prob_inf(params, data)`
  - *Description*: Test that the sampler handles -inf and +inf gracefully.
- **Function**: `log_prob_nan(params, data)`
  - *Description*: Test that the sampler handles NaN returning from log_prob_func.
- **Function**: `log_prob_simple(params, data)`
  - *Description*: Test with extreme parameter values.
- **Function**: `log_prob_extreme(params, data)`
  - *Description*: Test with extreme log-probability values.
- **Function**: `test_sampler_handles_inf()`
- **Function**: `test_sampler_handles_nan()`
- **Function**: `test_sampler_extreme_parameters()`
- **Function**: `test_sampler_extreme_log_probs()`
- **Function**: `log_prob_plus_inf(params, data)`
  - *Description*: Test that the sampler handles +inf log-probabilities.
- **Function**: `test_sampler_handles_plus_inf()`
- **Function**: `log_prob_small(params, data)`
  - *Description*: Test with very small parameter values.
- **Function**: `test_sampler_small_log_probs()`
- **Function**: `log_prob_high_dim(params, data)`
  - *Description*: Test with high dimensions.
- **Function**: `test_sampler_high_dim()`
### File: `test/test_scraper_clubelo.py`

### File: `test/test_scraper_fbref.py`

- **Function**: `test_fbref_wrong_league()`
- **Function**: `test_fbref_get_fixtures()`
- **Function**: `test_fbref_list_competitions()`
- **Function**: `test_fbref_team_mappings()`
- **Function**: `test_fbref_wrong_stat_type()`
- **Function**: `test_fbref_list_stat_types()`
- **Function**: `test_fbref_get_stats()`
### File: `test/test_scraper_footballdata.py`

- **Function**: `test_footballdata_wrong_league()`
- **Function**: `test_footballdata_get_fixtures()`
- **Function**: `test_footballdata_id()`
- **Function**: `test_footballdata_list_competitions()`
- **Function**: `test_footballdata_team_mappings()`
- **Function**: `test_footballdata_nat_error()`
  - *Description*: pandas was reading an extra blank row at end of csv that
### File: `test/test_scraper_understat.py`

- **Function**: `test_understat_wrong_league()`
- **Function**: `test_understat_get_fixtures()`
- **Function**: `test_understat_id()`
- **Function**: `test_understat_list_competitions()`
- **Function**: `test_understat_team_mappings()`
- **Function**: `test_understat_shots()`
- **Function**: `test_understat_fixture_info()`
- **Function**: `test_understat_player_season()`
- **Function**: `test_understat_player_shots()`
- **Function**: `test_map_season()`
### File: `test/test_value_bets.py`

- **Class**: `TestValueBetIdentification`
  - *Description*: Test the identify_value_bet function.
  - **Method**: `test_single_value_bet(self)`
    - *Description*: Test identification of a single value bet.
  - **Method**: `test_single_fair_bet(self)`
    - *Description*: Test a fair bet with no value.
  - **Method**: `test_single_negative_value_bet(self)`
    - *Description*: Test a bet with negative expected value.
  - **Method**: `test_multiple_value_bets(self)`
    - *Description*: Test identification of multiple value bets.
  - **Method**: `test_kelly_fraction_scaling(self)`
    - *Description*: Test that Kelly fraction parameter scales stakes correctly.
  - **Method**: `test_min_edge_threshold(self)`
    - *Description*: Test minimum edge threshold parameter.
  - **Method**: `test_numpy_array_inputs(self)`
    - *Description*: Test that numpy arrays work as inputs.
  - **Method**: `test_validation_errors(self)`
    - *Description*: Test validation errors for arbitrage function.
  - **Method**: `test_extreme_values(self)`
    - *Description*: Test extreme but valid values.
  - **Method**: `test_portfolio_metrics(self)`
    - *Description*: Test portfolio-level metrics are calculated correctly.
- **Class**: `TestCalculateBetValue`
  - *Description*: Test the calculate_bet_value utility function.
  - **Method**: `test_positive_value(self)`
    - *Description*: Test calculation of positive expected value.
  - **Method**: `test_zero_value(self)`
    - *Description*: Test calculation of zero expected value.
  - **Method**: `test_negative_value(self)`
    - *Description*: Test calculation of negative expected value.
  - **Method**: `test_validation_errors(self)`
    - *Description*: Test input validation for calculate_bet_value.
- **Class**: `TestArbitrageOpportunities`
  - *Description*: Test the find_arbitrage_opportunities function.
  - **Method**: `test_arbitrage_exists(self)`
    - *Description*: Test detection of arbitrage opportunity.
  - **Method**: `test_no_arbitrage(self)`
    - *Description*: Test when no arbitrage opportunity exists.
  - **Method**: `test_three_way_arbitrage(self)`
    - *Description*: Test arbitrage detection in three-way market.
  - **Method**: `test_validation_errors(self)`
    - *Description*: Test validation errors for arbitrage function.
  - **Method**: `test_outcome_labels(self)`
    - *Description*: Test outcome label handling.
- **Class**: `TestIntegrationScenarios`
  - *Description*: Test realistic value betting scenarios.
  - **Method**: `test_football_match_value_betting(self)`
    - *Description*: Test a realistic football match value betting scenario.
  - **Method**: `test_tennis_match_hedging_scenario(self)`
    - *Description*: Test value betting in the context of an existing position.
  - **Method**: `test_cross_bookmaker_arbitrage_scenario(self)`
    - *Description*: Test arbitrage detection across multiple bookmakers.
  - **Method**: `test_portfolio_optimization_scenario(self)`
    - *Description*: Test value bet identification for portfolio construction.

================================================================================
