{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81215b75-f5f8-4c17-9cd4-08b1b0ed4234",
   "metadata": {},
   "source": [
    "# Overview of the Different Models\n",
    "\n",
    "The `penaltyblog` package provides a suite of **robust, ready-to-use statistical models** for predicting football (soccer) match scores. All models are **highly optimised with Cython** for speed, making them fast, even for large-scale forecasting, betting analysis, and live in-play applications. Whether you want a quick baseline or an advanced model capturing complex goal-scoring patterns, `penaltyblog`'s models provide a consistent, user-friendly API.\n",
    "\n",
    "### 1. Poisson Goals Model\n",
    "\n",
    "The simplest and most widely used approach.  \n",
    "\n",
    "- **Idea**: Goals follow a Poisson distribution, with rates determined by attack strength, defense strength, and home advantage.  \n",
    "- **Strengths**: Easy to understand, quick to fit, good baseline accuracy.  \n",
    "- **Weaknesses**: Overpredicts high scores, struggles with low-score biases.  \n",
    "- **Best for**: General forecasting, fast model training.\n",
    "\n",
    "### 2. Dixon and Coles Goals Model\n",
    "\n",
    "A refinement of the Poisson model that corrects for the higher-than-expected frequency of low-score draws (e.g., 0-0, 1-0, 1-1).  \n",
    "\n",
    "- **Strengths**: More realistic score predictions in low-scoring leagues, improved match outcome accuracy.  \n",
    "- **Weaknesses**: Adds parameter tuning, assumes the same low-score adjustment for all matches.  \n",
    "- **Best for**: Leagues with many draws or defensive play styles.\n",
    "\n",
    "### 3. Bivariate Poisson Goals Model\n",
    "\n",
    "Extends the Poisson model by introducing correlation between teams’ goal counts.  \n",
    "\n",
    "- **Strengths**: Captures match dynamics affecting both teams, better for high-scoring matches.  \n",
    "- **Weaknesses**: More complex and harder to interpret, slower to fit.  \n",
    "- **Best for**: Leagues where team performances are strongly linked (e.g., end-to-end attacking games).\n",
    "\n",
    "### 4. Zero-Inflated Poisson Goals Model\n",
    "\n",
    "Adds an explicit mechanism for handling excess goalless matches.  \n",
    "\n",
    "- **Strengths**: Improves accuracy in ultra-defensive contexts.  \n",
    "- **Weaknesses**: Only adjusts for excess 0-0 games; doesn’t fix other Poisson issues.  \n",
    "- **Best for**: Competitions or teams with frequent goalless draws.\n",
    "\n",
    "### 5. Negative Binomial Goals Model\n",
    "\n",
    "Handles **overdispersion** - when goal count variance is greater than the mean.  \n",
    "\n",
    "- **Strengths**: More realistic for high-scoring or unpredictable leagues, better at extreme results.  \n",
    "- **Weaknesses**: Still assumes independence between team scores.  \n",
    "- **Best for**: High-variance, goal-heavy competitions.\n",
    "\n",
    "### 6. Weibull Count + Copula Goals Model\n",
    "\n",
    "A more flexible alternative to Poisson-based models, using a Weibull distribution for goals and a copula for score correlation. \n",
    "\n",
    "- **Strengths**: Handles complex goal patterns and diverse score dependencies.  \n",
    "- **Weaknesses**: Statistically and computationally intensive, not always worth the added complexity.  \n",
    "- **Best for**: Advanced modelling in leagues with unusual scoring patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "| Model                      | Strengths                                         | Weaknesses                                      | Best Used For |\n",
    "|----------------------------|---------------------------------------------------|-------------------------------------------------|---------------|\n",
    "| **Poisson**                | Simple, efficient, widely used                    | Overpredicts high scores, ignores low-score bias| General forecasting |\n",
    "| **Dixon & Coles**          | Corrects low-score bias, better match accuracy    | Fixed adjustment across matches, extra tuning  | Low-scoring leagues |\n",
    "| **Bivariate Poisson**      | Models score correlation, useful for high-scoring | Complex, harder to interpret                   | High-scoring leagues |\n",
    "| **Zero-Inflated Poisson**  | Better at goalless matches                         | Only fixes 0-0 bias                            | Defensive teams |\n",
    "| **Negative Binomial**      | Handles overdispersion, realistic extreme scores  | Still independent goal counts                   | High-scoring, volatile leagues |\n",
    "| **Weibull + Copula**       | Flexible distribution & correlation modelling     | Highly complex, slow to fit                    | Complex goal patterns |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c68c96",
   "metadata": {},
   "source": [
    "## Consistent API Across Models\n",
    "\n",
    "All goal models in `penaltyblog` share the **same interface**, making it simple to switch between them, run comparisons, or fine-tune parameters without rewriting your code.\n",
    "\n",
    "This design means you can:\n",
    "\n",
    "- Swap out a Poisson model for a Dixon & Coles model in one line.\n",
    "- Benchmark multiple models on the same dataset with minimal changes.\n",
    "- Apply optimisations (like lookback windows or time weighting) consistently across all models.\n",
    "\n",
    "### Common Methods\n",
    "\n",
    "Every model implements the following core methods:\n",
    "\n",
    "- `fit(minimizer_options)`: Train the model using your dataset.\n",
    "- `predict(home_team, away_team, max_goals, normalize)`: Predict scoreline probabilities for a given fixture.\n",
    "- `get_params()`: Retrieve the model's fited parameters.\n",
    "- `save(filepath)`: Save the model to disk as a pickled file.\n",
    "- `load(filepath)`: Load the saved model.\n",
    "\n",
    "\n",
    "### Example\n",
    "\n",
    "Switching from a Poisson model to a Dixon and Coles model is as simple as:\n",
    "\n",
    "```python\n",
    "from penaltyblog.models import PoissonGoalsModel, DixonColesGoalsModel\n",
    "\n",
    "# Train a Poisson model\n",
    "model = PoissonGoalsModel(\n",
    "    train[\"goals_home\"],\n",
    "    train[\"goals_away\"],\n",
    "    train[\"team_home\"],\n",
    "    train[\"team_away\"],\n",
    ")\n",
    "model.fit()\n",
    "\n",
    "# Swap to Dixon & Coles\n",
    "model = DixonColesGoalsModel(\n",
    "    train[\"goals_home\"],\n",
    "    train[\"goals_away\"],\n",
    "    train[\"team_home\"],\n",
    "    train[\"team_away\"],\n",
    ")\n",
    "model.fit()\n",
    "\n",
    "# Predict probabilities for a fixture\n",
    "prediction = model.predict(\"Arsenal\", \"Manchester City\")\n",
    "print(prediction.home_draw_away)\n",
    "```\n",
    "\n",
    "Because the API is consistent, you can automate model testing and tuning. For example, by looping through a list of model classes, fitting each one, and comparing metrics like Ranked Probability Score (RPS) without special-case code.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20757a77",
   "metadata": {},
   "source": [
    "## Time Weighting to Prioritise Recent Matches\n",
    "\n",
    "Football is dynamic - teams change managers, players, and tactics over time. Using too much historical data can let outdated results dilute your predictions.  \n",
    "\n",
    "To address this, all `penaltyblog` models support **time weighting**, allowing you to give recent fixtures more influence than older ones.\n",
    "\n",
    "The most common approach is the **Dixon and Coles exponential decay weighting**, where a decay factor `ξ` controls how quickly older matches lose importance:\n",
    "- `ξ = 0` → all matches are weighted equally.\n",
    "- Small `ξ` (e.g., 0.001) → older matches still contribute, but recent ones matter more.\n",
    "- Large `ξ` (e.g., 0.03) → the model focuses heavily on the most recent results.\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "from penaltyblog.models import PoissonGoalsModel, dixon_coles_weights\n",
    "\n",
    "# Generate weights with a decay factor of 0.001\n",
    "weights = dixon_coles_weights(train[\"date\"], xi=0.001)\n",
    "\n",
    "# Fit a Poisson model using time weighting\n",
    "model = PoissonGoalsModel(\n",
    "    train[\"goals_home\"],\n",
    "    train[\"goals_away\"],\n",
    "    train[\"team_home\"],\n",
    "    train[\"team_away\"],\n",
    "    weights=weights\n",
    ")\n",
    "model.fit()\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f718698",
   "metadata": {},
   "source": [
    "## Rich Probability Outputs for Betting and Analytics\n",
    "\n",
    "All goal models in `penaltyblog` return their predictions as a  `FootballProbabilityGrid` object. \n",
    "\n",
    "This class automatically gives you access to a wide range of **pre-calculated betting markets and metrics**, with no extra coding required.\n",
    "\n",
    "When you call `.predict(home_team, away_team)`, you receive:\n",
    "\n",
    "- The **full probability grid** for every possible scoreline (e.g., 0–0, 1–0, 2–3, …)\n",
    "- Expected goals for each team (`home_goal_expectation`, `away_goal_expectation`)\n",
    "- Ready-to-use probabilities for popular markets:\n",
    "  - **Match result** (`home_win`, `draw`, `away_win`, `home_draw_away`)\n",
    "  - **Both Teams to Score** (`both_teams_to_score`)\n",
    "  - **Over/Under Total Goals** (`total_goals(\"over\", strike)`)\n",
    "  - **Asian Handicap** (`asian_handicap(\"home\", strike)` / `asian_handicap(\"away\", strike)`)\n",
    "\n",
    "###\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "prediction = model.predict(\"Arsenal\", \"Manchester City\")\n",
    "\n",
    "# Expected goals\n",
    "print(prediction.home_goal_expectation)  # e.g. 1.45\n",
    "print(prediction.away_goal_expectation)  # e.g. 1.12\n",
    "\n",
    "# Match odds (1X2)\n",
    "print(prediction.home_draw_away)  # [P(Home), P(Draw), P(Away)]\n",
    "\n",
    "# Both teams to score\n",
    "print(prediction.both_teams_to_score)  # Probability both teams score\n",
    "\n",
    "# Over/Under 2.5 goals\n",
    "print(prediction.total_goals(\"over\", 2.5))\n",
    "\n",
    "# Asian handicap (home -0.5)\n",
    "print(prediction.asian_handicap(\"home\", -0.5))\n",
    "```\n",
    "\n",
    "Because the grid is generated directly from the underlying scoreline probabilities,\n",
    "**all these markets are perfectly internally consistent** - a crucial advantage for betting analytics and trading models.\n",
    "No more recalculating market probabilities from scratch; the `FootballProbabilityGrid` makes it instant.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e46605",
   "metadata": {},
   "source": [
    "## Faster Fitting with Gradients (Optional)\n",
    "\n",
    "All goals models now support **analytical gradients** during fitting to speed up convergence.  \n",
    "Gradients are **on by default** but can be **turned off** for backward compatibility or if they don’t suit your data.\n",
    "\n",
    "- **Why use gradients?** Faster, more stable optimisation and fewer iterations.\n",
    "- **When to turn them off?** If you’re experimenting, debugging, or working with unusual data where numerical optimisation behaves better.\n",
    "\n",
    "### Example\n",
    "```python\n",
    "# Gradients enabled (default)\n",
    "model.fit()\n",
    "\n",
    "# Turn gradients off (backward compatible behaviour)\n",
    "model.fit(use_gradient=False)\n",
    "```\n",
    "\n",
    "> Under the hood, when `use_gradient=True`, the model supplies a `jac` function to `scipy.optimize.minimize`. When `use_gradient=False`, it omits `jac`, falling back to numerical approximations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430250f7",
   "metadata": {},
   "source": [
    "## Passing Options to the Optimiser\n",
    "\n",
    "You can pass keyword options straight through to SciPy’s optimiser via the `minimizer_options` argument. Typical knobs include `maxiter`, `ftol`, `gtol`, etc. (the optimisation method is chosen per-model to suit its bounds/constraints).\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "# Increase iterations and tighten tolerances\n",
    "model.fit(\n",
    "    minimizer_options={\n",
    "        \"maxiter\": 5000,\n",
    "        \"gtol\": 1e-8,\n",
    "        \"ftol\": 1e-9,\n",
    "        \"disp\": False,  # silence SciPy output\n",
    "    }\n",
    ")\n",
    "\n",
    "# Combine with gradient toggle\n",
    "model.fit(\n",
    "    use_gradient=True,\n",
    "    minimizer_options={\"maxiter\": 3000, \"gtol\": 1e-8}\n",
    ")\n",
    "```\n",
    "\n",
    "> Note: Each model chooses an appropriate optimisation method internally based on bounds/constraints. The `minimizer_options` you provide are forwarded to `scipy.optimize.minimize(options=...)`.\n",
    "\n",
    "---\n",
    "\n",
    "## Inspecting Fit Results\n",
    "\n",
    "After fitting, models expose common diagnostics:\n",
    "\n",
    "- `model.fitted` – boolean flag\n",
    "- `model.loglikelihood` – maximised log-likelihood\n",
    "- `model.n_params` – number of fitted parameters\n",
    "- `model.aic` – Akaike Information Criterion\n",
    "- `model.params` / `model.get_params()` – dict of named parameters\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "model.fit()\n",
    "print(model.fitted, model.loglikelihood, model.aic)\n",
    "print(model.params)  \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Saving and Loading Models\n",
    "\n",
    "Use built-in persistence helpers to save a fitted model to disk and load it later without retraining\n",
    "\n",
    "```python\n",
    "model.fit()\n",
    "model.save(\"models/eredivisie_dc.pkl\")\n",
    "```\n",
    "\n",
    "```python\n",
    "from penaltyblog.models import DixonColesGoalModel  # or the relevant class\n",
    "\n",
    "loaded = DixonColesGoalModel.load(\"models/eredivisie_dc.pkl\")\n",
    "prediction = loaded.predict(\"Ajax\", \"PSV\")\n",
    "print(prediction.home_draw_away)\n",
    "```\n",
    "\n",
    "> Models are serialised with `pickle`. Ensure you import the same model class before loading.\n",
    "\n",
    "---\n",
    "\n",
    "## Minimal End-to-end Example\n",
    "\n",
    "```python\n",
    "import penaltyblog as pb\n",
    "\n",
    "# Prepare your training arrays (goals & teams) and optional weights\n",
    "gh, ga = train[\"goals_home\"], train[\"goals_away\"]\n",
    "th, ta = train[\"team_home\"], train[\"team_away\"]\n",
    "w = pb.models.dixon_coles_weights(train[\"date\"], xi=0.001)  # optional\n",
    "\n",
    "# Choose a model (swap freely thanks to the shared API)\n",
    "model = pb.models.DixonColesGoalsModel(gh, ga, th, ta, weights=w)\n",
    "\n",
    "# Fit fast with gradients and optional custom optimiser options\n",
    "model.fit(\n",
    "    use_gradient=True,\n",
    "    minimizer_options={\"maxiter\": 3000, \"gtol\": 1e-8}\n",
    ")\n",
    "\n",
    "# Predict and access rich markets\n",
    "pred = model.predict(\"Ajax\", \"PSV\")\n",
    "print(pred.home_draw_away)               # [P(Home), P(Draw), P(Away)]\n",
    "print(pred.totals(2.5))                  # (under, push, over)\n",
    "print(model.aic, model.loglikelihood)    # diagnostics\n",
    "\n",
    "# Save for later reuse\n",
    "model.save(\"models/eredivisie_dc.pkl\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
